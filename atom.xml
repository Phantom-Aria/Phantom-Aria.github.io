<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我的小破站</title>
  
  
  <link href="http://www.shelven.com/atom.xml" rel="self"/>
  
  <link href="http://www.shelven.com/"/>
  <updated>2023-07-11T10:08:40.000Z</updated>
  <id>http://www.shelven.com/</id>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hi-C染色体挂载（1）——juicer2处理Hi-C数据</title>
    <link href="http://www.shelven.com/2023/07/11/a.html"/>
    <id>http://www.shelven.com/2023/07/11/a.html</id>
    <published>2023-07-11T10:04:56.000Z</published>
    <updated>2023-07-11T10:08:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>前面经过三代数据结合二代数据的组装和polish，已经把基因组组装成了contigs的水平，下一步就是进一步提升到染色体水平。从实现的方式上来说有Bionano的光学图谱技术（作用是减少Scaffold数量，基因组纠错），Hi-C技术，遗传图谱以及依靠算法实现的基于近缘物种参考基因组的染色体水平组装（比如RagTag）。</p><span id="more"></span><p>对于一个没有遗传图谱，也没有近缘物种参考基因组的物种，考虑到光学图谱费用昂贵，一般最划算用的最多的是测一个Hi-C来进行基因组染色体级别组装。一些经典的Hi-C辅助组装的软件应运而生，比如<code>LACHESIS</code>、<code>3D-DNA</code>、<code>YaHS</code>等等。这篇笔记主要记录下软件<code>3D-DNA的</code>染色体挂载流程。</p><p>然而<code>3D-DNA</code>不能直接处理Hi-C下机数据，因此总的流程是用<code>juicer2</code>先处理Hi-C数据，再用<code>3D-DNA</code>进行染色体挂载，最后用<code>juicer box</code>进行手工纠错。</p><h2 id="juicer2"><a href="#juicer2" class="headerlink" title="juicer2"></a>juicer2</h2><div class="story post-story"><p>Juicer是一款非常经典的Hi-C数据处理软件，但是配置运行起来稍微有点麻烦，花了小半天时间踩坑记录一下。<strong>需要非常注意的一点</strong>，直接从github官网拉取的juicer仓库是<strong>juicer2</strong>，在release版本中有一个稳定版<strong>juicer1.6</strong>，两者的配置和产生的结果文件是不一样的！！！</p><p>秉着软件用新不用旧的原则，本篇笔记全程用的是<code>juicer2</code>，如果有软件运行问题可以在<a href="https://groups.google.com/g/3d-genomics">3D Genomics - Google 网上论坛</a>交流，或者在github官方提Issues（不建议）。</p><p>顺便提一下我使用<code>Juicer2</code>过程中碰到的版本问题：</p><ul><li><p><code>juicer2</code>配置的<code>juicer_tools</code>版本要在<strong>2.0</strong>以上，否则会报错<code>Exception in thread &quot;main&quot; java.lang.RuntimeException: Unknown command: statistics</code>，该报错会直接导致无法生成<code>inter.txt</code>、<code>inter_hists.m</code> 、<code>inter_30.txt</code>和<code>inter_30_hists.m</code>文件，也就是Hi-C互作的统计数据和矩阵。</p></li><li><p><code>juicer2</code>结果文件中<strong>不会自动产生merged_nodups.txt文件</strong>，该文件原本作为<code>3D-DNA</code>的输入文件，在<code>juicer2</code>中被同名的<code>merged_nodups.bam</code>文件和<code>merged*.txt</code>代替。如果想要<code>merged_nodups.txt</code>文件，<strong>需要加上参数–assembly</strong>。</p></li></ul><h3 id="1-下载和配置juice2"><a href="#1-下载和配置juice2" class="headerlink" title="1. 下载和配置juice2"></a>1. 下载和配置juice2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 拉取最新版本的juicer2仓库（这里用的github镜像，集群可能有dns污染无法直接访问github）</span><br><span class="line">git clone https://ghproxy.com/https://github.com/aidenlab/juicer.git</span><br><span class="line">cd juicer</span><br><span class="line"></span><br><span class="line"># juicer主目录下配置scripts（必需）</span><br><span class="line">## 个人电脑的是建立软链接到CPU文件夹下，其他如slurm、LSF、AWS和Univa等集群或者云端跑juicer是建立软链接或者复制到对应文件夹的scripts文件夹下</span><br><span class="line">ln -s CPU scripts</span><br><span class="line"></span><br><span class="line"># scripts/common文件夹中下载juicer_tools（必需）</span><br><span class="line">cd scripts/common</span><br><span class="line">wget -c https://ghproxy.com/https://github.com/aidenlab/Juicebox/releases/download/v2.20.00/juicer_tools.2.20.00.jar</span><br><span class="line"># 修改文件属性为可执行文件后，建立软链接</span><br><span class="line">ln -s juicer_tools.2.20.00.jar juicer_tools.jar</span><br></pre></td></tr></table></figure><p>本来想配置slurm跑的，因为塔大集群使用的是slurm作业调度系统。花了好大功夫配置环境发现运行<code>SLURM/scripts</code>底下的<code>juicer.sh</code>还需要配置CUDA，晕，学校的集群没有GPU（怨念 &#x3D; &#x3D;）……所以如果集群没有GPU的话就老老实实用<code>CPU</code>文件夹下的<code>juicer.sh</code>，按照CPU流程跑后面的程序，缺点是不能用集群提交多线程作业非常难受。</p><blockquote><p>官方也是推荐小的Hi-C实验可以用CPU版本，如果数据量比较大，还是推荐带有GPU加速的集群（最好是SLURM）或者云端跑。如下是官方推荐的两种方式：</p><p><a href="https://github.com/aidenlab/juicer/wiki/Running-Juicer-on-a-cluster">Running Juicer on a cluster · aidenlab&#x2F;juicer Wiki (github.com)</a></p><p><a href="https://github.com/ENCODE-DCC/hic-pipeline">ENCODE-DCC&#x2F;hic-pipeline: HiC uniform processing pipeline (github.com)</a></p></blockquote><p>juicer主目录下需要配置两个必需的文件夹<code>reference</code>和<code>restriction_sites</code>（第二个在juicer流程中非必须，但是做染色体挂载一定要）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># juicer目录下创建参考基因组文件夹，放入参考基因组（复制或者软链接）和构建参考基因组索引文件（必需用bwa）</span><br><span class="line">mkdir reference &amp;&amp; cd reference</span><br><span class="line">cp /path/to/your/reference/genome.fa ./</span><br><span class="line">bwa index genome.fa</span><br><span class="line"></span><br><span class="line"># juicer目录下创建限制性酶切位点文件夹，MboI酶酶切参考基因组（根据自己测hic用的限制酶）</span><br><span class="line">mkdir restriction_sites &amp;&amp; cd restriction_sites</span><br><span class="line">python ~/biosoft/juicer/misc/generate_site_positions.py MboI genome ~/biosoft/juicer/reference/genome.fa</span><br><span class="line">## 生成的酶切图谱文件名为genome_MboI.txt，同个文件夹下生成contig长度文件</span><br><span class="line">awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125;&#123;print $1, $NF&#125;&#x27; genome_MboI.txt &gt; genome.chrom.sizes</span><br></pre></td></tr></table></figure><p>官方的酶切参考基因组的脚本<code>generate_site_positions.py</code>支持<code>HindIII、DpnII、MboI、Sau3AI和Arima</code>4种限制性核酸内切酶，如果你Hi-C测序用的是其他酶，可以根据实际修改这个脚本中的字典类型数据patterns，根据实际情况加入键值对信息：</p><p><img src="https://www.shelven.com/tuchuang/20230710/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230710/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>稍微解释一下官网给的<code>awk &#39;BEGIN&#123;OFS=&quot;\t&quot;&#125;&#123;print $1, $NF&#125;&#39;</code>这个命令，这里awk的程序部分由两部分组成：</p><blockquote><ul><li><code>BEGIN&#123;OFS=&quot;\t&quot;&#125;</code>：BEGIN块是在处理文件之前执行的代码块。在这里，它设置输出字段分隔符（OFS）为制表符（<code>\t</code>）。这意味着输出的字段将使用制表符进行分隔。</li><li><code>&#123;print $1, $NF&#125;</code>：这是awk的主要部分，它定义了要执行的操作。在这里，它打印每行的第一个字段$1和最后一个字段（NF）。通过使用逗号分隔它们，它们将以制表符分隔的形式打印出来。</li></ul></blockquote><p><code>genome.chrom.sizes</code>文件如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230710/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230710/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>工作目录下必需配置一个文件夹<code>fastq</code>，其中存放Hi-C的双端测序数据，命名格式参考<code>juicer.sh</code>文件中的正则表达式<code>*_R*.fastq*</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 工作目录下创建存放hic测序数据的文件夹，我这里为了方便查看，工作目录就是juicer主目录，测序数据可以用软链接的形式存放</span><br><span class="line">mkdir fastq &amp;&amp; cd fastq</span><br><span class="line">ln -s ~/hi-c/BM_R1.fq.gz Av_R1.fastq.gz</span><br><span class="line">ln -s ~/hi-c/BM_R2.fq.gz Av_R2.fastq.gz</span><br></pre></td></tr></table></figure><h3 id="2-运行juicer2"><a href="#2-运行juicer2" class="headerlink" title="2. 运行juicer2"></a>2. 运行juicer2</h3><p>官网的<code>juicer.sh</code>参数非常之多，我这里只展示一些关键的，其他用默认参数即可。<code>1.x</code>版本可以参考<a href="https://github.com/aidenlab/juicer/wiki/Usage">Usage · aidenlab&#x2F;juicer Wiki (github.com)</a>，<code>2.0</code>版本具体可以用<code>bash juicer.sh -h</code>查看，两个版本指令稍有不同。CPU版本和其他集群版本也稍有不同，以CPU中的2.0版本为例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Usage: juicer.sh [-g genomeID] [-d topDir] [-s site]</span><br><span class="line">                 [-a about] [-S stage] [-p chrom.sizes path]</span><br><span class="line">                 [-y restriction site file] [-z reference genome file]</span><br><span class="line">                 [-D Juicer scripts parent dir] [-b ligation] [-t threads]</span><br><span class="line">                 [-T threadsHic] [-i sample] [-k library] [-w wobble]</span><br><span class="line">                 [-e] [-h] [-f] [-j] [-u] [-m] [--assembly] [--cleanup] [--qc]</span><br><span class="line">-g genomeID必需项，指定基因组和版本，比如人类的&quot;hg19&quot; 或者小鼠的&quot;mm10&quot;，如果没有，可以用-z命令替代，指定参考基因组文件</span><br><span class="line">-z reference genome file指定参考基因组文件，此文件中必需有BWA索引文件</span><br><span class="line">-d topDir指定输出目录，默认是当前目录。[topDir]/fastq必需包含fastq文件</span><br><span class="line">-s site必需项，指定限制性核酸内切酶。如果不做片段级别的分析可以写none</span><br><span class="line">-S stage指定运行pipeline的阶段，固定是&quot;chimeric&quot;, &quot;merge&quot;, &quot;dedup&quot;, &quot;final&quot;, &quot;postproc&quot;, &quot;early&quot;其中之一，报错调试用</span><br><span class="line">chimeric：alignment结束或者从aligned文件开始</span><br><span class="line">merge:alignment结束但是没有生成merged_sort文件</span><br><span class="line">dedup：文件已经merge结束，但是没有生成merged_nodups文件</span><br><span class="line">final：reads在merged_nodups文件中已经删除重复，但是尚未生成最终的state和hic文件</span><br><span class="line">postproc：hic文件已经生成，只有特征注释尚未完成</span><br><span class="line">early：在hic文件生成前提前结束程序</span><br><span class="line">-p chrom.sizes path指定染色体长度文件</span><br><span class="line">-y restriction site file指定参考基因组酶切文件</span><br><span class="line">-D Juicer scripts parent dir指定Juicer/scripts所在目录</span><br><span class="line">-t threads指定跑BWA的线程数</span><br><span class="line">-T threadsHic指定生成hic文件用的核数（2.0版本新增）</span><br><span class="line">--assembly接下游3D-DNA分析，会提前结束并生成老版本的merged_nodups文件（2.0新增）</span><br><span class="line">--cleanup如果pipeline成功运行，自动清除中间文件（2.0新增）</span><br><span class="line"></span><br><span class="line">如果是在集群中跑juicer，以下两个参数也是必需要改的，否则用默认分区名会直接报错：</span><br><span class="line">-q queue指定跑alignments的队列分区（默认commons），slurm中的分区也就是partition，可以理解为LSF、PBS等作业调度系统中的队列</span><br><span class="line">-l long queue指定跑需要时间更长的job，比如生成hic文件的队列分区（默认long）</span><br></pre></td></tr></table></figure><p>因为我不是做三维基因组，Hi-C只测了一个样（主要用于辅助基因组组装，染色体挂载），比如做三维基因组就会有大量的Hi-C数据，juicer也支持多个结果的合并（使用<code>mega.sh</code>），详细也可以参考上面的juicer Wiki。</p><p>上面的限速步骤主要是跑BWA，因为第一次跑juicer不知道要多久，就稍微申请多一点的核数<del>（虽然集群没有GPU，但是CPU资源很充足平常没人用）。</del></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个slurm作业</span><br><span class="line">vim juicer.slurm</span><br><span class="line"></span><br><span class="line"># 提交slurm作业</span><br><span class="line">sbatch juicer.slurm</span><br></pre></td></tr></table></figure><p><code>juicer.slurm</code>文件内容如下<strong>（再次提醒–assembly 参数非常重要）</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#SBATCH -N 1</span><br><span class="line">#SBATCH -n 30</span><br><span class="line">#SBATCH -t 7200</span><br><span class="line"></span><br><span class="line">/public/home/wlxie/biosoft/juicer/scripts/juicer.sh \</span><br><span class="line">-z /public/home/wlxie/biosoft/juicer/reference/genome.fa \</span><br><span class="line">-p /public/home/wlxie/biosoft/juicer/restriction_sites/genome.chrom.sizes \</span><br><span class="line">-y /public/home/wlxie/biosoft/juicer/restriction_sites/genome_MboI.txt \</span><br><span class="line">-s MboI \</span><br><span class="line">-D /public/home/wlxie/biosoft/juicer \</span><br><span class="line">-t 30 \</span><br><span class="line">--assembly</span><br></pre></td></tr></table></figure><p>运行时间可以参考一下我这里220 Mb的参考基因组，Hi-C测序数据39G（双端测序，gz文件），实际上运行了13小时才出结果。</p><p>运行pipeline成功后会在日志中提示<code>(-: Pipeline successfully completed (-:</code></p><h3 id="3-结果文件"><a href="#3-结果文件" class="headerlink" title="3. 结果文件"></a>3. 结果文件</h3><p>CPU模式下会在工作目录创建<code>aligned</code>和<code>splits</code>文件夹：</p><blockquote><ul><li>splits 文件夹存放整个pipeline的临时文件，跑完流程并且确认结果没问题后可以运行cleanup.sh或者直接删除（按照帮助文档的说法，–cleanup参数应该可以自动删除，我没有试过）</li><li>aligned 文件夹存放运行结果</li><li>如果你是用集群模式跑的，比如SLURM，还会生成一个<code>debug</code>文件夹（CPU模式下用SLURM跑的没有该文件夹），可以查看各个步骤的error报告和output报告</li></ul></blockquote><p>aligned文件夹有以下结果文件：</p><p><img src="https://www.shelven.com/tuchuang/20230710/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230710/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>我这里实际上是多了一些文件，因为一开始没有加上<code>--assembly</code>参数，所以一直运行到出hic结果文件，而且没有<code>merged_nodups.txt</code></p><p>我做染色体挂载<strong>只需要最后一个文件</strong>，所以加了上面的参数，并且添加<code>-S final</code>参数，这样就省去了前面比对和去重复的时间，半个小时可以重新跑完出结果。</p><p>顺便了解一下其他结果文件的用途：</p><blockquote><ul><li><strong>inter.hic &#x2F; inter_30.hic</strong>: The .hic files for Hi-C contacts at MAPQ &gt; 0 and at MAPQ &gt;&#x3D; 30, respectively</li><li><strong>merged_nodups.txt</strong>: The Hi-C contacts with duplicates removed. This file is also input to the assembly and diploid pipelines （后面跑3D-DNA的输入文件）</li><li><strong>inter.txt, inter_hists.m &#x2F; inter_30.txt, inter_30_hists.m</strong>: The statistics and graphs files for Hi-C contacts at MAPQ &gt; 0 and at MAPQ &gt;&#x3D; 30, respectively. These are also stored within the respective .hic files in the header. The .m files can be loaded into Matlab. The statistics and graphs are displayed under Dataset Metrics when loaded into Juicebox （可以后续导入juicer box）</li></ul></blockquote></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面经过三代数据结合二代数据的组装和polish，已经把基因组组装成了contigs的水平，下一步就是进一步提升到染色体水平。从实现的方式上来说有Bionano的光学图谱技术（作用是减少Scaffold数量，基因组纠错），Hi-C技术，遗传图谱以及依靠算法实现的基于近缘物种参考基因组的染色体水平组装（比如RagTag）。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="juicer2" scheme="http://www.shelven.com/tags/juicer2/"/>
    
    <category term="Hi-C染色体挂载" scheme="http://www.shelven.com/tags/Hi-C%E6%9F%93%E8%89%B2%E4%BD%93%E6%8C%82%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>python自学笔记（8）——10种排序方式的python实现</title>
    <link href="http://www.shelven.com/2023/07/04/a.html"/>
    <id>http://www.shelven.com/2023/07/04/a.html</id>
    <published>2023-07-04T15:14:44.000Z</published>
    <updated>2023-07-04T15:37:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近中期答辩结束，稍微有点空闲的时间捋一捋数据结构和算法方面的知识。虽然现在用python实现排序就一个sort()函数的事，但是还是想锻炼下自己的思维，从底层代码学习一下10种经典排序的实现方式。</p><span id="more"></span><p>对于时间复杂度和空间复杂度的计算，自己还是一知半解，每种排序方式后面放了自己的理解，有错误会继续修改，最后有一张菜鸟教程总结的图可以参考。</p><p>本篇笔记的内容主要是跟着b站up主做的，代码整理来自<a href="https://space.bilibili.com/319521269">英雄哪里出来的个人空间</a></p><p>我这里先定义一个生成随机整数序列的函数，后面都会调用，就不重复写了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成指定范围、长度的序列</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_random_sequence</span>(<span class="params"><span class="built_in">len</span>, <span class="built_in">min</span>, <span class="built_in">max</span></span>):</span><br><span class="line">    seq = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>):</span><br><span class="line">        seq.append(random.randint(<span class="built_in">min</span>, <span class="built_in">max</span>))</span><br><span class="line">    <span class="keyword">return</span> seq</span><br></pre></td></tr></table></figure><h2 id="1-选择排序"><a href="#1-选择排序" class="headerlink" title="1. 选择排序"></a>1. 选择排序</h2><div class="story post-story"><p>从第一个元素到最后一个元素中选择最小的元素，和第一个元素进行交换；然后从第二个元素到最后一个元素选择最小的元素，和第二个元素交换，依此类推。通过对未排序的元素比较和交换，选择出最小的，直到最后成为一个升序序列。</p><img src="https://www.shelven.com/tuchuang/20230704/SelectionSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/SelectionSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SelectionSort</span>(<span class="params">a</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>): <span class="comment"># 排完倒数第二个数之后就不用再排了，所以这里用n-1而不是n</span></span><br><span class="line">        <span class="built_in">min</span> = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> a[j] &lt; a[<span class="built_in">min</span>]:</span><br><span class="line">                <span class="built_in">min</span> = j</span><br><span class="line">        a[i], a[<span class="built_in">min</span>] = a[<span class="built_in">min</span>], a[i]</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">SelectionSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[77, 76, 21, 51, 29, 23, 19, 68, 53, 37]</span></span><br><span class="line"><span class="string">[19, 76, 21, 51, 29, 23, 77, 68, 53, 37]</span></span><br><span class="line"><span class="string">[19, 21, 76, 51, 29, 23, 77, 68, 53, 37]</span></span><br><span class="line"><span class="string">[19, 21, 23, 51, 29, 76, 77, 68, 53, 37]</span></span><br><span class="line"><span class="string">[19, 21, 23, 29, 51, 76, 77, 68, 53, 37]</span></span><br><span class="line"><span class="string">[19, 21, 23, 29, 37, 76, 77, 68, 53, 51]</span></span><br><span class="line"><span class="string">[19, 21, 23, 29, 37, 51, 77, 68, 53, 76]</span></span><br><span class="line"><span class="string">[19, 21, 23, 29, 37, 51, 53, 68, 77, 76]</span></span><br><span class="line"><span class="string">[19, 21, 23, 29, 37, 51, 53, 68, 77, 76]</span></span><br><span class="line"><span class="string">[19, 21, 23, 29, 37, 51, 53, 68, 76, 77]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>这个算法时间复杂度（算法中循环执行的次数，量级估算）为O(n^2)，其中n是输入序列的长度。空间复杂度（算法运行过程中临时占用存储大小，量级估算）为O(1)，因为它只需要使用常数级别的额外空间。</p></div><h2 id="2-冒泡排序"><a href="#2-冒泡排序" class="headerlink" title="2. 冒泡排序"></a>2. 冒泡排序</h2><div class="story post-story"><p>通过不断比较相邻元素，将数值大的元素往后排。第一个元素和第二个元素比较，如果第一个元素大，则进行交换，再比较第二个元素和第三个元素大小，以此类推，直到最大的元素移动到最后一个位置，然后进行第二轮比较。每一轮中数值较大的元素，不断到达数组的尾部。</p><img src="https://www.shelven.com/tuchuang/20230704/BubbleSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/BubbleSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">BubbleSort</span>(<span class="params">a</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):<span class="comment"># range()左闭右开，n-1可以取到右边界，逆序枚举</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">            <span class="keyword">if</span> a[j] &gt; a[j + <span class="number">1</span>]:</span><br><span class="line">                a[j], a[j + <span class="number">1</span>] = a[j + <span class="number">1</span>], a[j]</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">BubbleSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[57, 86, 40, 11, 38, 46, 21, 38, 18, 6]</span></span><br><span class="line"><span class="string">[57, 40, 11, 38, 46, 21, 38, 18, 6, 86]</span></span><br><span class="line"><span class="string">[40, 11, 38, 46, 21, 38, 18, 6, 57, 86]</span></span><br><span class="line"><span class="string">[11, 38, 40, 21, 38, 18, 6, 46, 57, 86]</span></span><br><span class="line"><span class="string">[11, 38, 21, 38, 18, 6, 40, 46, 57, 86]</span></span><br><span class="line"><span class="string">[11, 21, 38, 18, 6, 38, 40, 46, 57, 86]</span></span><br><span class="line"><span class="string">[11, 21, 18, 6, 38, 38, 40, 46, 57, 86]</span></span><br><span class="line"><span class="string">[11, 18, 6, 21, 38, 38, 40, 46, 57, 86]</span></span><br><span class="line"><span class="string">[11, 6, 18, 21, 38, 38, 40, 46, 57, 86]</span></span><br><span class="line"><span class="string">[6, 11, 18, 21, 38, 38, 40, 46, 57, 86]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>这个算法的时间复杂度为O(n^2)（最好的情况下数据本来有序，复杂度O(n)），其中n是待排序数组的长度。空间复杂度为O(1)，因为只使用了常数级别的额外空间。和选择排序算法是一样。</p></div><h2 id="3-插入排序"><a href="#3-插入排序" class="headerlink" title="3. 插入排序"></a>3. 插入排序</h2><div class="story post-story"><p>对前i-1个数已经有序的情况下，将第i个数插入到合适的位置。</p><p>将第二个元素和第一个元素比较，如果第二个元素小于等于第一个元素，则将第一个元素向后移动，并将第一个元素执行插入，这样前两个元素就是有序的。接着进行第二轮比较，也就是将第三个元素依次和第二元素和第一个元素比较，并插入到合适的位置，使前三个元素有序。以此类推，迭代执行n-1次插入，<strong>每次插入都是将元素插入到有序序列中。</strong></p><img src="https://www.shelven.com/tuchuang/20230704/InsertionSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/InsertionSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:67%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">InsertionSort</span>(<span class="params">a</span>):</span><br><span class="line">    n =<span class="built_in">len</span>(a)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        x = a[i]</span><br><span class="line">        j = i - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> j &gt;= <span class="number">0</span> <span class="keyword">and</span> x &lt;= a[j]:<span class="comment"># 若x&lt;=a[j]，则将a[j]往后移动，继续判断前一个数</span></span><br><span class="line">            a[j + <span class="number">1</span>] = a[j]</span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line">        a[j + <span class="number">1</span>] = x</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">InsertionSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[95, 69, 37, 81, 21, 11, 53, 12, 22, 16]</span></span><br><span class="line"><span class="string">[69, 95, 37, 81, 21, 11, 53, 12, 22, 16]</span></span><br><span class="line"><span class="string">[37, 69, 95, 81, 21, 11, 53, 12, 22, 16]</span></span><br><span class="line"><span class="string">[37, 69, 81, 95, 21, 11, 53, 12, 22, 16]</span></span><br><span class="line"><span class="string">[21, 37, 69, 81, 95, 11, 53, 12, 22, 16]</span></span><br><span class="line"><span class="string">[11, 21, 37, 69, 81, 95, 53, 12, 22, 16]</span></span><br><span class="line"><span class="string">[11, 21, 37, 53, 69, 81, 95, 12, 22, 16]</span></span><br><span class="line"><span class="string">[11, 12, 21, 37, 53, 69, 81, 95, 22, 16]</span></span><br><span class="line"><span class="string">[11, 12, 21, 22, 37, 53, 69, 81, 95, 16]</span></span><br><span class="line"><span class="string">[11, 12, 16, 21, 22, 37, 53, 69, 81, 95]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>这个算法的时间复杂度为O(n^2)，其中n是待排序数组的长度。空间复杂度为O(1)，因为只使用了常数级别的额外空间。</p><p>要改善选择排序的时间复杂度，可以考虑使用其他更高效的排序算法，例如快速排序（Quick Sort）或归并排序（Merge Sort）。这些算法的时间复杂度通常为O(nlogn)，比上面三个排序算法的O(n^2)更快。此外，还可以考虑使用内置的排序函数，如Python中的<code>sorted()</code>函数，它使用了优化的排序算法。如果待排序数组已经基本有序，可以通过引入一些优化措施来提高插入排序的性能，例如使用二分查找来确定插入位置，减少比较和交换的次数。</p></div><h2 id="4-归并排序"><a href="#4-归并排序" class="headerlink" title="4. 归并排序"></a>4. 归并排序</h2><div class="story post-story"><p>利用分治的思想，采用递归的形式，对元素进行排序。当有两个长度为n的有序数组时，可以通过两个指针的移动，在O(n)的时间复杂度内，快速合并成一个有序数组。而这两个长度为n的有序数组，也可以通过两个n&#x2F;2的有序数组合并而来。因此，只要不断对数组进行分治，就可以把一个无序数组变成有序。</p><p>对数组拆分的过程用到递归，对数组组合的过程用到了合并，故命名归并排序。</p><img src="https://www.shelven.com/tuchuang/20230704/MergeSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/MergeSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:67%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现一个合并函数(a列表start到mid的元素，以及mid+1到end的元素，需要分别按照递增顺序排列)，执行后a列表start到end的元素也按照递增顺序排序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Merge</span>(<span class="params">a, start, mid, end</span>):</span><br><span class="line">    tmp = []</span><br><span class="line">    l = start   <span class="comment"># l和r是两个区间的起点</span></span><br><span class="line">    r = mid + <span class="number">1</span></span><br><span class="line">    <span class="comment"># 当两个区间都未到达右端点，判断a[l]和a[r]，小的值放入临时列表，下标自增</span></span><br><span class="line">    <span class="keyword">while</span> l &lt;= mid <span class="keyword">and</span> r &lt;= end:    </span><br><span class="line">        <span class="keyword">if</span> a[l] &lt;= a[r]:</span><br><span class="line">            tmp.append(a[l])</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tmp.append(a[r])</span><br><span class="line">            r += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 跳出循环时，剩余部分全部放入临时列表（因为跳出循环表示一个列表已经排完了，另一个列表剩下的也是有序的）</span></span><br><span class="line">    tmp.extend(a[l : mid + <span class="number">1</span>])  </span><br><span class="line">    tmp.extend(a[r : end + <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 临时列表值拷贝回原列表a，完成一次合并</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, end + <span class="number">1</span>):</span><br><span class="line">        a[i] = tmp[i - start]</span><br><span class="line">    <span class="built_in">print</span>(start, end, tmp)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现一个递归函数（作用是拆分子数组）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MergeSort</span>(<span class="params">a, start, end</span>):</span><br><span class="line">    <span class="comment"># 待排序元素只有一个则返回</span></span><br><span class="line">    <span class="keyword">if</span> start == end:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 计算中点mid，整数除法，向下取整</span></span><br><span class="line">    mid = (start + end) // <span class="number">2</span></span><br><span class="line">    MergeSort(a, start, mid)</span><br><span class="line">    MergeSort(a, mid + <span class="number">1</span>, end)</span><br><span class="line">    <span class="comment"># 两次调用MergeSort()产生两个有序数组，之后对两个有序数组进行Merge()合并</span></span><br><span class="line">    Merge(a, start, mid, end)</span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">MergeSort(a, <span class="number">0</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[92, 87, 91, 24, 5, 36, 76, 62, 66, 89]</span></span><br><span class="line"><span class="string">0 1 [87, 92]</span></span><br><span class="line"><span class="string">0 2 [87, 91, 92]</span></span><br><span class="line"><span class="string">3 4 [5, 24]</span></span><br><span class="line"><span class="string">0 4 [5, 24, 87, 91, 92]</span></span><br><span class="line"><span class="string">5 6 [36, 76]</span></span><br><span class="line"><span class="string">5 7 [36, 62, 76]</span></span><br><span class="line"><span class="string">8 9 [66, 89]</span></span><br><span class="line"><span class="string">5 9 [36, 62, 66, 76, 89]</span></span><br><span class="line"><span class="string">0 9 [5, 24, 36, 62, 66, 76, 87, 89, 91, 92]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>其实也可以不用递归的方法，用迭代的方式来实现归并排序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现一个合并函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge</span>(<span class="params">arr, start, mid, end, temp</span>):</span><br><span class="line">    i = start</span><br><span class="line">    j = mid</span><br><span class="line">    k = start</span><br><span class="line">    <span class="keyword">while</span> i &lt; mid <span class="keyword">and</span> j &lt; end:</span><br><span class="line">        <span class="keyword">if</span> arr[i] &lt; arr[j]:</span><br><span class="line">            temp[k] = arr[i]</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            temp[k] = arr[j]</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; mid:</span><br><span class="line">        temp[k] = arr[i]</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &lt; end:</span><br><span class="line">        temp[k] = arr[j]</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># 实现一个拆分子数组和合并的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_sort</span>(<span class="params">arr</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    <span class="comment"># 创建一个临时数组用于存储排序结果</span></span><br><span class="line">    temp = [<span class="number">0</span>] * <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="comment"># 设置初始步长为1</span></span><br><span class="line">    step = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> step &lt; <span class="built_in">len</span>(arr):</span><br><span class="line">        <span class="comment"># 按照步长将数组分为多个子数组进行合并</span></span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(arr), <span class="number">2</span> * step):</span><br><span class="line">            <span class="comment"># 计算子数组的起始索引、中间索引和结束索引</span></span><br><span class="line">            mid = <span class="built_in">min</span>(start + step, <span class="built_in">len</span>(arr))</span><br><span class="line">            end = <span class="built_in">min</span>(start + <span class="number">2</span> * step, <span class="built_in">len</span>(arr))</span><br><span class="line">            <span class="comment"># 合并两个子数组</span></span><br><span class="line">            merge(arr, start, mid, end, temp)</span><br><span class="line">        <span class="comment"># 将临时数组的结果复制回原始数组</span></span><br><span class="line">        arr[:] = temp[:]</span><br><span class="line">        <span class="comment"># 增加步长</span></span><br><span class="line">        step *= <span class="number">2</span></span><br><span class="line">        <span class="built_in">print</span>(arr)</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line">arr = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line">sorted_arr = merge_sort(arr)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[65, 50, 64, 33, 58, 7, 97, 87, 92, 52]（原序列）</span></span><br><span class="line"><span class="string">[50, 65, 33, 64, 7, 58, 87, 97, 52, 92]（步长2）</span></span><br><span class="line"><span class="string">[33, 50, 64, 65, 7, 58, 87, 97, 52, 92]（步长4）</span></span><br><span class="line"><span class="string">[7, 33, 50, 58, 64, 65, 87, 97, 52, 92]（步长8）</span></span><br><span class="line"><span class="string">[7, 33, 50, 52, 58, 64, 65, 87, 92, 97]（最终序列）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>在这个实现中，使用了一个临时数组<code>temp</code>来存储排序的结果。首先，设置初始步长为1，然后在每一轮迭代中，按照步长将原始数组分为多个子数组，并调用<code>merge</code>函数将这些子数组进行合并。合并后的结果存储在临时数组<code>temp</code>中。最后，将临时数组的结果复制回原始数组。迭代的思想在于通过不断迭代地合并子数组，直到得到完整的有序数组。</p><p><strong>归并排序的时间复杂度是O(nlogn)，其中n是待排序数组的大小。空间复杂度是O(n)，因为在每次合并操作中需要创建一个临时列表来存储合并后的结果。</strong></p><p>时间复杂度的算法可以参考<a href="https://blog.csdn.net/qq_42511528/article/details/108081681">如何计算归并排序算法的时间复杂度？</a></p><p>空间复杂度的算法可以参考<a href="https://blog.csdn.net/u010711495/article/details/117378617">归并排序的空间复杂度</a></p></div><h2 id="5-桶排序"><a href="#5-桶排序" class="headerlink" title="5. 桶排序"></a>5. 桶排序</h2><div class="story post-story"><p>生成一些桶，让数字散列在不同桶中，对桶中元素分别执行排序，再将元素依次取出。</p><p>比如建立4个桶，遍历所有数字并依次分散到4个桶中，保证第2个桶所有数字都大于第1个桶，第3个桶所有数字都大于第2个桶。每个桶中分别进行选择排序，4个桶的元素都有序之后，再将元素依次取出。</p><p><img src="https://www.shelven.com/tuchuang/20230704/BucketSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/BucketSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确定桶内排序方法（这里用选择排序）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">SelectionSort</span>(<span class="params">a</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>): </span><br><span class="line">        <span class="built_in">min</span> = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> a[j] &lt; a[<span class="built_in">min</span>]:</span><br><span class="line">                <span class="built_in">min</span> = j</span><br><span class="line">        a[i], a[<span class="built_in">min</span>] = a[<span class="built_in">min</span>], a[i]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">BucketSort</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="comment"># 确定列表元素最小值和最大值，定义桶数量</span></span><br><span class="line">    minV = <span class="built_in">min</span>(a)</span><br><span class="line">    maxV = <span class="built_in">max</span>(a)</span><br><span class="line">    bucketCount = <span class="number">3</span><span class="comment"># 桶的数量</span></span><br><span class="line">    bucket = [[], [], []]</span><br><span class="line">    <span class="comment"># 计算每个桶的范围</span></span><br><span class="line">    perBucket = (maxV - minV + bucketCount) // bucketCount</span><br><span class="line"><span class="comment"># 遍历列表每个元素，计算该元素放入的桶的索引，并且放入相应桶中</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> a:</span><br><span class="line">        bucketIndex = (num - minV) // perBucket</span><br><span class="line">        bucket[bucketIndex].append(num)</span><br><span class="line">    <span class="comment"># 遍历每个桶，对每个桶的元素进行选择排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bucketCount):</span><br><span class="line">        SelectionSort(bucket[i])</span><br><span class="line">    </span><br><span class="line">    idx = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历每个桶，遍历桶中元素，将元素放回原列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bucketCount):</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> bucket[i]:</span><br><span class="line">            a[idx] = v</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(bucket)</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br><span class="line">    </span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">BucketSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[84, 66, 53, 83, 22, 15, 95, 6, 32, 70]</span></span><br><span class="line"><span class="string">[[6, 15, 22, 32], [53], [66, 70, 83, 84, 95]]</span></span><br><span class="line"><span class="string">[6, 15, 22, 32, 53, 66, 70, 83, 84, 95]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>桶的数量可以根据待排序元素的分布情况和排序的要求来决定，一般将待排序的元素均匀分配到桶中，桶内的排序算法可以是任意一种排序算法，取决于应用场景和性能要求。这个算法挺有意思的，可以看到每个桶的元素数量不一定一样，桶排序一般不会直接用，往往会做变形。</p><p>这个桶排序算法的时间复杂度为O(n + k^2)，其中n是待排序元素的数量，k是桶的数量。具体来说，遍历列表并将元素放入桶中的时间复杂度为O(n)，对每个桶进行选择排序的时间复杂度为O(k^2)，遍历每个桶并将元素放回原列表的时间复杂度为O(n)。因此，总的时间复杂度为O(n + k^2)，也就是O(n)。</p><p>空间复杂度方面，除了原始列表外，额外使用了一个大小为k的桶列表来存储元素。因此，空间复杂度为O(n + k)，也就是O(n)。</p></div><h2 id="6-计数排序"><a href="#6-计数排序" class="headerlink" title="6. 计数排序"></a>6. 计数排序</h2><div class="story post-story"><p>利用哈希表的思想，对数据类型和范围有要求。</p><p>首先生成一个计数器数组，并且一开始所有值的计数都为0，然后遍历枚举原数组的所有元素，在元素值对应的计数器上执行计数操作。最后遍历枚举计数器数组，按照数组中元素个数放回到原数组中，这样所有元素都是升序排列了。</p><img src="https://www.shelven.com/tuchuang/20230704/CountingSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/CountingSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 67%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">CountingSort</span>(<span class="params">a</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    <span class="comment"># 获取原数组中最大值，加1，作为计数器列表的实际长度</span></span><br><span class="line">    cntlen = <span class="built_in">max</span>(a) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># 生成一个值都为0的计数器列表</span></span><br><span class="line">    cnt = [<span class="number">0</span>] * cntlen</span><br><span class="line">    <span class="comment"># 遍历枚举原数组所有元素，在对应的计数器上加1</span></span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> a:</span><br><span class="line">        cnt[val] += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(cnt)</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历枚举计数器列表，cnt[val]代表val这个数有多少个，大于0，则将它的计数器减一，并放到原来的列表中。如果还有则继续迭代至计数为0</span></span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cntlen):</span><br><span class="line">        <span class="keyword">while</span> cnt[val] &gt; <span class="number">0</span>:</span><br><span class="line">            cnt[val] -= <span class="number">1</span></span><br><span class="line">            a[n] = val</span><br><span class="line">            n += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">CountingSort(a)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果</span></span><br><span class="line"><span class="string">[8, 14, 18, 13, 16, 17, 7, 10, 8, 15]（原列表）</span></span><br><span class="line"><span class="string">[0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]（计数器列表）</span></span><br><span class="line"><span class="string">[7, 8, 8, 10, 13, 14, 15, 16, 17, 18]（计数排序后的列表）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>很明显，这种排序方式对数据有较大的限制，适用于<strong>数据范围较小的非负整数，且数据分布较均匀</strong>的情况（并不是说负数就完全不能用）。这很好理解，数据范围太广，会导致计数数组很大，占用大量内存空间，如果数据分布不均匀，计数的效率也会降低。</p><p>本质上来说这种计数排序算法是一种简单的桶排序算法，一个计数器就是一个桶。计数排序算法**时间复杂度是O(n)，空间复杂度是O(n)**。</p></div><h2 id="7-基数排序"><a href="#7-基数排序" class="headerlink" title="7. 基数排序"></a>7. 基数排序</h2><div class="story post-story"><p>和上面的计数排序很像，本质上也是桶排序，只不过用<strong>数位</strong>来划分桶。</p><p>首先建立0-9的10个桶，对待排序的每个元素，按照<strong>个位数的值</strong>放入对应的桶中，按顺序遍历桶中元素，取出来放回原数组。对于待排序的每个数字，按照<strong>十位数的值</strong>放入对应桶中，按顺序遍历桶中元素，取出来放回原数组。以此类推，按照百位数、千位数的值放入桶中，遍历，取出，直到排序完成。</p><img src="https://www.shelven.com/tuchuang/20230704/RadixSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/RadixSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:67%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">RadixSort</span>(<span class="params">a</span>):</span><br><span class="line">    base = <span class="number">1</span><span class="comment"># base为取的数位</span></span><br><span class="line">    maxv = <span class="built_in">max</span>(a)</span><br><span class="line">    <span class="comment"># 从低到高遍历每个数位</span></span><br><span class="line">    <span class="keyword">while</span> base &lt; maxv:</span><br><span class="line">        bucket = []</span><br><span class="line">        <span class="comment"># 每次遍历定义10个桶</span></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            bucket.append([])</span><br><span class="line">        <span class="comment"># 每个原列表元素根据当前数位放入对应的桶中</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> a:</span><br><span class="line">            idx = num // base % <span class="number">10</span><span class="comment"># //向下取整，%除法取余</span></span><br><span class="line">            bucket[idx].append(num)</span><br><span class="line">        l = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 遍历每个桶，按顺序放回原列表</span></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> bucket[idx]:</span><br><span class="line">                a[l] = v</span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">        base *= <span class="number">10</span></span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">RadixSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[119, 13, 832, 247, 117, 126, 996, 904, 112, 396]（原序列）</span></span><br><span class="line"><span class="string">[832, 112, 13, 904, 126, 996, 396, 247, 117, 119]（按照个位数放入桶中，遍历取出）</span></span><br><span class="line"><span class="string">[904, 112, 13, 117, 119, 126, 832, 247, 996, 396]（按照十位数放入桶中，遍历取出）</span></span><br><span class="line"><span class="string">[13, 112, 117, 119, 126, 247, 396, 832, 904, 996]（按照百位数放入桶中，遍历取出）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>上面的代码只适用于正整数，我们通过循环遍历每个数位，所以外层循环的次数是位数d。内层循环中，我们遍历了待排序数组并将每个元素放入对应的桶中，所以内层循环的时间复杂度是O(n)。最后，我们遍历每个桶，按顺序将元素放回原列表，这也需要O(n)的时间复杂度。</p><p>总的来说，基数排序的时间复杂度为O(d * (n + k))，其中d表示位数，n表示待排序数组的长度，k表示桶的数量。空间复杂度为O(dk+n)。</p><p>如果有负整数，可以把原数组元素分为正整数和负整数，分别进行基数排序后合并：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">RadixSort</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="comment"># 分离正数和负数</span></span><br><span class="line">    positive_nums = [num <span class="keyword">for</span> num <span class="keyword">in</span> a <span class="keyword">if</span> num &gt;= <span class="number">0</span>]</span><br><span class="line">    negative_nums = [-num <span class="keyword">for</span> num <span class="keyword">in</span> a <span class="keyword">if</span> num &lt; <span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 对正数部分进行基数排序</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(positive_nums) &gt; <span class="number">0</span>:</span><br><span class="line">        base = <span class="number">1</span></span><br><span class="line">        maxv = <span class="built_in">max</span>(positive_nums)</span><br><span class="line">        <span class="keyword">while</span> base &lt; maxv:</span><br><span class="line">            bucket = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">            <span class="keyword">for</span> num <span class="keyword">in</span> positive_nums:</span><br><span class="line">                idx = num // base % <span class="number">10</span></span><br><span class="line">                bucket[idx].append(num)</span><br><span class="line">            positive_nums = [v <span class="keyword">for</span> bucket_list <span class="keyword">in</span> bucket <span class="keyword">for</span> v <span class="keyword">in</span> bucket_list]</span><br><span class="line">            <span class="built_in">print</span>(positive_nums)</span><br><span class="line">            base *= <span class="number">10</span></span><br><span class="line">    <span class="comment"># 对负数部分进行基数排序</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(negative_nums) &gt; <span class="number">0</span>:</span><br><span class="line">        base = <span class="number">1</span></span><br><span class="line">        maxv = <span class="built_in">max</span>(negative_nums)</span><br><span class="line">        <span class="keyword">while</span> base &lt; maxv:</span><br><span class="line">            bucket = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">            <span class="keyword">for</span> num <span class="keyword">in</span> negative_nums:</span><br><span class="line">                idx = num // base % <span class="number">10</span></span><br><span class="line">                bucket[idx].append(num)</span><br><span class="line">            negative_nums = [v <span class="keyword">for</span> bucket_list <span class="keyword">in</span> bucket <span class="keyword">for</span> v <span class="keyword">in</span> bucket_list]</span><br><span class="line">            <span class="built_in">print</span>(negative_nums)</span><br><span class="line">            base *= <span class="number">10</span></span><br><span class="line">    <span class="comment"># 将负数部分反转</span></span><br><span class="line">    negative_nums = [-num <span class="keyword">for</span> num <span class="keyword">in</span> negative_nums[::-<span class="number">1</span>]]</span><br><span class="line">    <span class="built_in">print</span>(negative_nums)</span><br><span class="line">    <span class="comment"># 合并正数和负数部分</span></span><br><span class="line">    sorted_a = negative_nums + positive_nums</span><br><span class="line">    <span class="keyword">return</span> sorted_a</span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, -<span class="number">1000</span>, <span class="number">1000</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">a = RadixSort(a)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[-918, -574, 385, -322, -164, 880, -158, -400, 607, -746](原序列)</span></span><br><span class="line"><span class="string">[880, 385, 607]</span></span><br><span class="line"><span class="string">[607, 880, 385]</span></span><br><span class="line"><span class="string">[385, 607, 880]（基数排序后的正数序列）</span></span><br><span class="line"><span class="string">[400, 322, 574, 164, 746, 918, 158]</span></span><br><span class="line"><span class="string">[400, 918, 322, 746, 158, 164, 574]</span></span><br><span class="line"><span class="string">[158, 164, 322, 400, 574, 746, 918]（基数排序后取反的负数序列）</span></span><br><span class="line"><span class="string">[-918, -746, -574, -400, -322, -164, -158]（反转的成原来的负数序列）</span></span><br><span class="line"><span class="string">[-918, -746, -574, -400, -322, -164, -158, 385, 607, 880]（整合排序后的结果）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><h2 id="8-快速排序"><a href="#8-快速排序" class="headerlink" title="8. 快速排序"></a>8. 快速排序</h2><div class="story post-story"><p>找到一个基准点，把小于它的和大于它的数分开，分别递归执行快速排序。也是用了分治的思想，属于冒泡排序的改进算法。</p><img src="https://www.shelven.com/tuchuang/20230704/QuickSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/QuickSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从a列表start到end之间寻找基准数下标，并且将所有小于等于它的数放在它左边，大于它的数放在右边</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">QuickSortPivot</span>(<span class="params">a, start, end</span>):</span><br><span class="line">    pivot = start   <span class="comment"># 最左边数为基准数</span></span><br><span class="line">    j = start + <span class="number">1</span>   <span class="comment"># j代表大于基准数的数的下标左边界</span></span><br><span class="line">    <span class="comment"># 遍历列表所有数，如果当前数小于等于基准数，则a[i]和a[j]交换，j自增；大于则不处理（保证j下标以前的数小于等于基准数）</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start + <span class="number">1</span>, end + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> a[i] &lt;= a[pivot]:</span><br><span class="line">            a[i], a[j] = a[j], a[i]</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 遍历之后，基准数与小于基准数的最后一个数交换（这样就可以让基准数左边和右边分开，且基准数位置就是正确的了）</span></span><br><span class="line">    a[pivot], a[j - <span class="number">1</span>] = a[j - <span class="number">1</span>], a[pivot]</span><br><span class="line">    <span class="comment"># 更新基准数下标</span></span><br><span class="line">    pivot = j - <span class="number">1</span> </span><br><span class="line">    <span class="built_in">print</span>(a[pivot], a[start : pivot], a[pivot + <span class="number">1</span> : end + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> pivot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 快速排序函数，用来对区间[start, end]的数递归执行快速排序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">QuickSort</span>(<span class="params">a, start, end</span>):</span><br><span class="line">    <span class="keyword">if</span> start &gt;= end:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 获得基准数下标，分别递归计算左边和右边部分</span></span><br><span class="line">    pivot = QuickSortPivot(a, start, end)</span><br><span class="line">    QuickSort(a, start, pivot - <span class="number">1</span>)</span><br><span class="line">    QuickSort(a, pivot + <span class="number">1</span>, end)</span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">QuickSort(a, <span class="number">0</span>, <span class="number">9</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[55, 100, 41, 99, 52, 90, 50, 71, 92, 44]# 原序列</span></span><br><span class="line"><span class="string">55 [44, 41, 52, 50] [90, 99, 71, 92, 100]# 基准数，基准数左边序列，基准数右边序列</span></span><br><span class="line"><span class="string">44 [41] [52, 50]</span></span><br><span class="line"><span class="string">52 [50] []</span></span><br><span class="line"><span class="string">90 [71] [99, 92, 100]</span></span><br><span class="line"><span class="string">99 [92] [100]</span></span><br><span class="line"><span class="string">[41, 44, 50, 52, 55, 71, 90, 92, 99, 100]# 快速排序后的序列</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>这种排序算法也有一个缺点，如果很不巧每次选取的基准点都是序列的最大值或者最小值，那么时间复杂度将会是最大值O(n^2)。</p><p><strong>时间复杂度：</strong></p><ul><li>在每一次划分操作中，需要遍历待排序数组的所有元素，这需要O(n)的时间。</li><li>在每一次划分操作中，将数组划分为两个子数组，每个子数组的长度大约是原数组的一半（最好的情况）。因此，划分操作的时间复杂度为O(n)。</li><li>快速排序的递归深度为logn，因为每次划分操作都将数组的规模减半。</li><li>因此，最好的情况下时间复杂度为O(nlogn)，最坏情况下时间复杂度为O(n^2)。</li></ul><p><strong>空间复杂度：</strong></p><ul><li>快速排序使用递归调用来对子数组进行排序，每次递归调用都需要保存当前的函数调用信息（包括参数、局部变量等）。</li><li>快速排序的递归深度通常为logn，因此需要的栈空间也是logn。</li><li>因此，总的空间复杂度为O(logn)。最坏的情况下是O(n)，随机化基准值pivot可以防止最坏情况发生。</li></ul><p>可以用随机快速排序，每次找基准点采用了一次随机，规避快速排序最坏的情况发生。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">QuickSortPivot</span>(<span class="params">a, start, end</span>):</span><br><span class="line">    <span class="comment"># 引入区间中随机一个元素的索引值，和最左边的数交换（本来是最左边的数作为下一轮的基准数）</span></span><br><span class="line">    randIdx = random.randint(start, end)</span><br><span class="line">    a[start], a[randIdx] = a[randIdx], a[start]</span><br><span class="line">    </span><br><span class="line">    pivot = start  </span><br><span class="line">    j = start + <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start + <span class="number">1</span>, end + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> a[i] &lt;= a[pivot]:</span><br><span class="line">            a[i], a[j] = a[j], a[i]</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">    a[pivot], a[j - <span class="number">1</span>] = a[j - <span class="number">1</span>], a[pivot]</span><br><span class="line">    pivot = j - <span class="number">1</span> </span><br><span class="line">    <span class="built_in">print</span>(a[pivot], a[start : pivot], a[pivot + <span class="number">1</span> : end + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> pivot</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">QuickSort</span>(<span class="params">a, start, end</span>):</span><br><span class="line">    <span class="keyword">if</span> start &gt;= end:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    pivot = QuickSortPivot(a, start, end)</span><br><span class="line">    QuickSort(a, start, pivot - <span class="number">1</span>)</span><br><span class="line">    QuickSort(a, pivot + <span class="number">1</span>, end)</span><br><span class="line">    </span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">QuickSort(a, <span class="number">0</span>, <span class="number">9</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[24, 2, 44, 75, 32, 32, 68, 36, 9, 79]</span></span><br><span class="line"><span class="string">68 [9, 2, 44, 32, 32, 24, 36] [75, 79]</span></span><br><span class="line"><span class="string">36 [9, 2, 32, 32, 24] [44]</span></span><br><span class="line"><span class="string">9 [2] [32, 32, 24]</span></span><br><span class="line"><span class="string">24 [] [32, 32]</span></span><br><span class="line"><span class="string">32 [32] []</span></span><br><span class="line"><span class="string">79 [75] []</span></span><br><span class="line"><span class="string">[2, 9, 24, 32, 32, 36, 44, 68, 75, 79]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><h2 id="9-希尔排序"><a href="#9-希尔排序" class="headerlink" title="9. 希尔排序"></a>9. 希尔排序</h2><div class="story post-story"><p>本质是一种改进后的插入排序，又称“缩小增量排序”，增量在这里是指<strong>按照一定规则选择的间隔值</strong>（这里也是分组数），通常设置为数组长度的一半，每次缩小增量直到增量为1，组内排序方法为插入排序。每轮希尔排序的分组数越来越小，也就是说组内元素越来越多，最后一组就是整个数组。</p><img src="https://www.shelven.com/tuchuang/20230704/ShellSort1.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/ShellSort1.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ShellSort</span>(<span class="params">a</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    <span class="comment"># gap为增量，每隔gap值执行插入排序</span></span><br><span class="line">    gap = n // <span class="number">2</span>    </span><br><span class="line">    <span class="keyword">while</span> gap &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gap, n):</span><br><span class="line">            x = a[i]</span><br><span class="line">            j =i</span><br><span class="line">            <span class="keyword">while</span> j &gt;= gap:</span><br><span class="line">                <span class="keyword">if</span> x &lt; a[j - gap]:</span><br><span class="line">                    a[j] = a[j - gap]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                j -= gap</span><br><span class="line">            a[j] = x</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">        <span class="comment"># 增量除2向下取整，继续迭代</span></span><br><span class="line">        gap = gap // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">ShellSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[20, 17, 75, 69, 34, 85, 38, 23, 57, 28]# 原序列</span></span><br><span class="line"><span class="string">[20, 17, 23, 57, 28, 85, 38, 75, 69, 34]# 第一次希尔排序，实际分了5组[20,85][17,38][75,23][69,57][34,28]并组内进行了插入排序</span></span><br><span class="line"><span class="string">[20, 17, 23, 34, 28, 57, 38, 75, 69, 85]# 第二次希尔排序，实际分了2组[20,23,28,38,69][17,57,85,75,34]并组内进行了插入排序</span></span><br><span class="line"><span class="string">[17, 20, 23, 28, 34, 38, 57, 69, 75, 85]# 第三次希尔排序，实际就是1组，所有组内元素插入排序</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>希尔排序的时间复杂度是根据增量序列的选择而变化的。在最坏情况下（原序列为逆序），时间复杂度是O(n^2)；最好的情况下（原序列本身有序），时间复杂度是O(n)。平均情况下，希尔排序的时间复杂度可以达到O(nlogn)。</p><p>希尔排序的空间复杂度是O(1)，即不需要额外的空间来存储数据。希尔排序是一种原地排序算法，它通过交换元素的位置来实现排序，不需要额外的辅助数组或链表。因此，希尔排序的空间复杂度是常数级别的。</p></div><h2 id="10-堆排序"><a href="#10-堆排序" class="headerlink" title="10. 堆排序"></a>10. 堆排序</h2><div class="story post-story"><p>堆是一颗完全二叉树，假设一个节点编号为<code>idx</code>，则左子树树根编号为<code>idx*2</code>，右子树树根编号为<code>idx*2+1</code>，把每个结点的编号和顺序表下标对应，就可以把这颗二叉树用顺序表形式存储起来。</p><p>对于一个给定的顺序表，首先构造成<strong>大顶堆</strong>（所有根结点大于左右子结点），方法是从顺序表的最后一个元素开始，自底向上构造堆。对于某个元素，取左右子树中的大者和该元素比较，如果比该元素大，则与之交换（该元素所在位置下沉）。由于每个堆左右子树都是满足堆的性质的，当枚举完根结点后大顶堆就构造完毕了。</p><p>这个时候堆顶的元素是最大的，把堆顶元素和顺序表最后一个元素进行交换（弹出），最大值就在最后一位了。继续利用堆的下沉操作，除了最后一位以外继续构造大顶堆，把次大元素交换到倒数第二位，依此类推，最终整个顺序表就是升序排列的有序顺序表了。</p><p><img src="https://www.shelven.com/tuchuang/20230704/HeapSort.gif" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/HeapSort.gif" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现大顶堆下沉操作，heap整个顺序表start到end之间组成合法的堆，start为根结点坐标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maxHeapify</span>(<span class="params">heap, start, end</span>):</span><br><span class="line">    son = start * <span class="number">2</span>     <span class="comment"># 左子树根</span></span><br><span class="line">    <span class="comment"># 左子树存在，则取左子树和右子树根中的大者的下标，存储到son中</span></span><br><span class="line">    <span class="keyword">while</span> son &lt;= end:</span><br><span class="line">        <span class="keyword">if</span> son + <span class="number">1</span> &lt;= end <span class="keyword">and</span> heap[son + <span class="number">1</span>] &gt; heap[son]:</span><br><span class="line">            son += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 如果结点点的值大于根结点的值，则将根结点和子结点交换（下沉），子结点迭代执行</span></span><br><span class="line">        <span class="keyword">if</span> heap[son] &gt; heap[start]:</span><br><span class="line">            heap[start], heap[son] = heap[son], heap[start]</span><br><span class="line">            start, son = son, son * <span class="number">2</span></span><br><span class="line">        <span class="comment"># 如果子结点的值小于等于根结点的值，说明堆构造没问题，跳出循环</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现堆排序操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">HeapSort</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="comment"># 堆下标从1开始，列表下标从0开始，所以在0的位置加上占位符None</span></span><br><span class="line">    heap = [<span class="literal">None</span>] + a</span><br><span class="line">    <span class="comment"># 定义堆顶元素下标root为1</span></span><br><span class="line">    root = <span class="number">1</span></span><br><span class="line">    l = <span class="built_in">len</span>(heap)</span><br><span class="line">    <span class="comment"># 从顺序表l//2个元素开始(因为堆的最后一层是没有子结点的)逆序枚举，自底向上构造堆</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l // <span class="number">2</span>, root - <span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        maxHeapify(heap, i, l - <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 堆顶和最后一个元素交换，除最后一个元素外，重构堆</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l - <span class="number">1</span>, root, -<span class="number">1</span>):</span><br><span class="line">        heap[i], heap[root] = heap[root], heap[i]</span><br><span class="line">        maxHeapify(heap, root, i - <span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(heap[root:])</span><br><span class="line"></span><br><span class="line">a = generate_random_sequence(<span class="number">10</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">HeapSort(a)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出结果：</span></span><br><span class="line"><span class="string">[3, 52, 44, 78, 60, 100, 54, 61, 38, 1]# 原数列</span></span><br><span class="line"><span class="string">[78, 61, 54, 52, 60, 44, 3, 1, 38, 100]# 最大数为100，1-9位重新构造大顶堆</span></span><br><span class="line"><span class="string">[61, 60, 54, 52, 38, 44, 3, 1, 78, 100]# 次大数为78，1-8位重新构造大顶堆</span></span><br><span class="line"><span class="string">[60, 52, 54, 1, 38, 44, 3, 61, 78, 100]# 第三大数为61，1-7重新构造大顶堆</span></span><br><span class="line"><span class="string">[54, 52, 44, 1, 38, 3, 60, 61, 78, 100].</span></span><br><span class="line"><span class="string">[52, 38, 44, 1, 3, 54, 60, 61, 78, 100].</span></span><br><span class="line"><span class="string">[44, 38, 3, 1, 52, 54, 60, 61, 78, 100].</span></span><br><span class="line"><span class="string">[38, 1, 3, 44, 52, 54, 60, 61, 78, 100].</span></span><br><span class="line"><span class="string">[3, 1, 38, 44, 52, 54, 60, 61, 78, 100].</span></span><br><span class="line"><span class="string">[1, 3, 38, 44, 52, 54, 60, 61, 78, 100]# 最后一次构造大顶堆，只有一个最小元素1，此时数列已经升序排好</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>堆排序的时间复杂度为O(nlogn)，n是待排序元素的数量，空间复杂度为O(1)，因为它是原地排序算法，不需要额外的空间来存储元素。</p><p>最后是一张来自菜鸟教程的排序算法总结图：</p><p><img src="https://www.shelven.com/tuchuang/20230704/1.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230704/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近中期答辩结束，稍微有点空闲的时间捋一捋数据结构和算法方面的知识。虽然现在用python实现排序就一个sort()函数的事，但是还是想锻炼下自己的思维，从底层代码学习一下10种经典排序的实现方式。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="编程自学" scheme="http://www.shelven.com/categories/%E7%BC%96%E7%A8%8B%E8%87%AA%E5%AD%A6/"/>
    
    
    <category term="python" scheme="http://www.shelven.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>群体基因组学——GWAS分析</title>
    <link href="http://www.shelven.com/2023/06/20/a.html"/>
    <id>http://www.shelven.com/2023/06/20/a.html</id>
    <published>2023-06-20T10:40:24.000Z</published>
    <updated>2023-06-24T07:28:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇笔记主要记录如何在linux命令行中用<code>TASSEL5</code>和<code>PLINK2</code>软件做GWAS分析，以及如何可视化GWAS结果（在R中绘制曼哈顿图和QQ图）。关于GWAS是做什么的，以及基本概念介绍可以看上一篇笔记介绍：<a href="https://www.shelven.com/2023/06/16/a.html">群体基因组学——概述和图表详解 - 我的小破站 (shelven.com)</a></p><span id="more"></span><p>PLINK和TASSEL都是做GWAS分析用的经典软件，两个软件都有linux版本和windows版本，我这里是在linux集群环境中跑的分析流程，所有软件下载linux版本，两款软件可以在下方官网中安装：</p><p><a href="https://www.cog-genomics.org/plink/2.0/">PLINK 2.0 (cog-genomics.org)</a>、<a href="https://tassel.bitbucket.io/">Tassel</a></p><p>TASSEL官网有tassel pipeline命令行的帮助文档，一些常用的参数可以参考<a href="https://bytebucket.org/tasseladmin/tassel-5-source/wiki/docs/Tassel5PipelineCLI.pdf">Tassel5PipelineCLI.pdf (bytebucket.org)</a></p><p>TASSEL中文文档可以参考本站<a href="https://www.shelven.com/tuchuang/20230619/Tassel5.pdf">Tassel5中文操作手册.pdf</a></p><h2 id="1-数据格式"><a href="#1-数据格式" class="headerlink" title="1. 数据格式"></a>1. 数据格式</h2><div class="story post-story"><p>plink的数据格式有两套，每套各自的前缀名称相同，一套后缀为<code>.bed</code>、<code>.bin</code>和<code>.fam</code>，另一套后缀为<code>.map</code>和<code>.ped</code>，后面的分析以第一套为例，读取速度比较快。</p><p>那么这三个是怎么来的呢？我们做群体重测序后，通过GATK等软件做变异检测最终会生成一个VCF文件，通过软件<code>plink</code>可以将VCF文件转化成上面的三个文件，分别展示一下三个文件的内容和结构：</p><p><img src="https://www.shelven.com/tuchuang/20230619/1.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>fam文件（家族信息文件）有6列，分别为家系编号、个体编号、父系编号（0表示信息缺失）、母系编号（0表示信息缺失）、性别编号（1表示男，2表示女，0表示未知性别）、表型值（1表示对照，2表示病例，0&#x2F;-9或者其他非数字表示信息缺失）</li><li>bim文件（个体信息文件）有6列，分别为染色体编号、SNP标识、以摩根或厘摩为单位的位置（可以用0）、碱基对坐标、Allele1和Allele2（通常是主效等位基因）</li><li>bed文件为二进制文件</li></ul></blockquote><p>转化成这三个文件主要是为了下一步更快过滤数据，因为bed是二进制文件，计算机处理起来更快。</p><p>以上数据来源是贺师兄做的棉花重测序样本的部分变异信息文件。</p></div><h2 id="2-基因型数据清洗（使用PLINK）"><a href="#2-基因型数据清洗（使用PLINK）" class="headerlink" title="2. 基因型数据清洗（使用PLINK）"></a>2. 基因型数据清洗（使用PLINK）</h2><div class="story post-story"><p>使用plink软件过滤掉最小等位基因频率（Minor Allele Frequency，MAF）小于0.05的变异位点，在关联分析中MAF值太小会造成假阳性。比如说，一个基因座上有两个等位基因A和B，A在群体中的频率为0.6，B在群体中的频率为0.4，那么MAF值就是0.4，可以想到一个基因座上MAF值越小，基因座上的等位基因越单一，MAF太低的位点贡献的信息很少，不与表型做关联分析。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 过滤MAF小于0.05的SNP，重新生成.bed、.bin和.fam文件</span><br><span class="line">## --make-bed 创建PLINK1二进制文件集</span><br><span class="line">plink --bfile Course_GWAS --maf 0.05 --make-bed --out Course_GWAS_maf0.05</span><br><span class="line"></span><br><span class="line"># 重新将三个过滤后的文件转化成vcf文件</span><br><span class="line">## --recode 创建新文件集，可选格式&#x27;vcf&#x27;，&#x27;vcf-fid&#x27;，和&#x27;vcf-iid&#x27;</span><br><span class="line">plink --bfile Course_GWAS_maf0.05 --recode vcf-iid --out GWAS_vcf</span><br></pre></td></tr></table></figure><p>可以通过查看过滤前后的bim文件，统计过滤了多少位点（plink软件在屏幕上的标准输出也会显示）：</p><p><img src="https://www.shelven.com/tuchuang/20230619/2.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># plink输出结果</span><br><span class="line">PLINK v2.00a5LM 64-bit Intel (7 Jun 2023)      www.cog-genomics.org/plink/2.0/</span><br><span class="line">(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3</span><br><span class="line">Logging to Course_GWAS_maf0.05.log.</span><br><span class="line">Options in effect:</span><br><span class="line">  --bfile Course_GWAS</span><br><span class="line">  --maf 0.05</span><br><span class="line">  --make-bed</span><br><span class="line">  --out Course_GWAS_maf0.05</span><br><span class="line"></span><br><span class="line">Start time: Tue Jun 20 14:38:58 2023</span><br><span class="line">1837 MiB RAM detected, ~914 available; reserving 850 MiB for main workspace.</span><br><span class="line">Using up to 2 compute threads.</span><br><span class="line">216 samples (0 females, 0 males, 216 ambiguous; 216 founders) loaded from</span><br><span class="line">Course_GWAS.fam.</span><br><span class="line">10000 variants loaded from Course_GWAS.bim.</span><br><span class="line">Note: No phenotype data present.</span><br><span class="line">Calculating allele frequencies... done.</span><br><span class="line">3030 variants removed due to allele frequency threshold(s)</span><br><span class="line">(--maf/--max-maf/--mac/--max-mac).</span><br><span class="line">6970 variants remaining after main filters.</span><br><span class="line">Writing Course_GWAS_maf0.05.fam ... done.</span><br><span class="line">Writing Course_GWAS_maf0.05.bim ... done.</span><br><span class="line">Writing Course_GWAS_maf0.05.bed ... done.</span><br></pre></td></tr></table></figure><p>需要注意下我这里使用的表型数据都是处理好的，所以只对基因型数据做过滤就行，如果自己有表型数据还要做一下表型数据清洗，比如删除异常值等等。</p><p>生成的<code>GWAS_vcf.vcf</code>用于下一步关联分析。</p></div><h2 id="3-关联分析（使用TASSEL5）"><a href="#3-关联分析（使用TASSEL5）" class="headerlink" title="3. 关联分析（使用TASSEL5）"></a>3. 关联分析（使用TASSEL5）</h2><div class="story post-story"><p>PLINK软件也可以做关联分析，网上也能找到一把教程，但是PLINK只能做GLM模型的关联分析，现在文献中用的比较多的软件是TASSEL5，接下来演示用命令行的Tassel Pipeline做关联分析。</p><h3 id="3-1-计算亲缘关系矩阵"><a href="#3-1-计算亲缘关系矩阵" class="headerlink" title="3.1 计算亲缘关系矩阵"></a>3.1 计算亲缘关系矩阵</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># -Xmx10G 控制最大堆（heap size）的大小为10G</span><br><span class="line"># -importGuess 使用Tassel的importGuess函数载入文件</span><br><span class="line"># -KinshipPlugin 调用亲缘关系矩阵插件，与 -endPlugin 联用</span><br><span class="line"># -method 这里指定计算IBS亲缘关系矩阵</span><br><span class="line"># -export 指定输出文件，输出文件类型与input数据有关，比如基因型表默认Hapmap格式，距离矩阵默认SqrMatrix</span><br><span class="line"># -exportType 指定输出文件类型，有Hapmap, HDF5, VCF, Plink, SqrMatrix等等</span><br><span class="line"></span><br><span class="line">perl /opt/TASSEL5/run_pipeline.pl -Xmx10G -importGuess GWAS_vcf.vcf -KinshipPlugin -method Centered_IBS -endPlugin -export kinship.txt -exportType SqrMatrix</span><br></pre></td></tr></table></figure><p>生成的216个样本的亲缘关系矩阵kinship.txt如下：</p><p><img src="https://www.shelven.com/tuchuang/20230619/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="3-2-主成分分析"><a href="#3-2-主成分分析" class="headerlink" title="3.2 主成分分析"></a>3.2 主成分分析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># -fork&lt;id&gt; 用于区分不同的pipeline，代表一个pipeline的起始，后面可以是数字或者字符（非空格）</span><br><span class="line"># -PrincipalComponentsPlugin 调用主成分分析插件，同样和 -endPlugin 联用</span><br><span class="line"># -covariance true 计算协方差矩阵（用来识别主成分），两种方法，相关系数(correlation)或者协方差(covariance)</span><br><span class="line"># -runfork&lt;id&gt; 这个参数已经可以不需要了，pipeline会自动执行需要的fork</span><br><span class="line"></span><br><span class="line">perl /opt/TASSEL5/run_pipeline.pl -fork1 -importGuess GWAS_vcf.vcf -PrincipalComponentsPlugin -covariance true -endPlugin -export pca -runfork1</span><br></pre></td></tr></table></figure><p>默认情况下会生成的PCA结果主要展示前5个主成分，且这一步会生成三个txt文件，PCA结果展示在第一个文件<code>pca1.txt</code>：</p><p><img src="https://www.shelven.com/tuchuang/20230619/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="3-3-可视化亲缘关系矩阵和PCA结果（群体结构分析）"><a href="#3-3-可视化亲缘关系矩阵和PCA结果（群体结构分析）" class="headerlink" title="3.3 可视化亲缘关系矩阵和PCA结果（群体结构分析）"></a>3.3 可视化亲缘关系矩阵和PCA结果（群体结构分析）</h3><p>在拿到这两个矩阵之后就可以通过R可视化结果，首先是亲缘关系矩阵热图：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>data.table<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">kinship <span class="operator">=</span> fread<span class="punctuation">(</span><span class="string">&quot;kinship.txt&quot;</span><span class="punctuation">,</span>skip <span class="operator">=</span> <span class="number">3</span><span class="punctuation">)</span>     <span class="comment"># 前3行不用读入</span></span><br><span class="line">setDF<span class="punctuation">(</span>kinship<span class="punctuation">)</span>      <span class="comment"># 将data.table格式转化成data.frame格式</span></span><br><span class="line">row.names<span class="punctuation">(</span>kinship<span class="punctuation">)</span> <span class="operator">=</span> kinship<span class="operator">$</span>V1</span><br><span class="line">kinship<span class="operator">$</span>V1 <span class="operator">=</span> <span class="literal">NULL</span>       </span><br><span class="line">colnames<span class="punctuation">(</span>kinship<span class="punctuation">)</span> <span class="operator">=</span> row.names<span class="punctuation">(</span>kinship<span class="punctuation">)</span>      <span class="comment"># 第一列做行名，删除第一列，行名设置为列名  </span></span><br><span class="line">kinship <span class="operator">=</span> as.matrix<span class="punctuation">(</span>kinship<span class="punctuation">)</span>        <span class="comment"># 转成矩阵格式</span></span><br><span class="line">pdf<span class="punctuation">(</span><span class="string">&quot;kinship.pdf&quot;</span><span class="punctuation">)</span></span><br><span class="line">heatmap<span class="punctuation">(</span>kinship<span class="punctuation">,</span>labRow<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">,</span>labCol<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">)</span>      <span class="comment"># 绘制热图，不在行和列上显示标签</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230619/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>用颜色深浅不同表示每个样本之间的亲缘关系远近，颜色越深亲缘关系越近。</p><p>PCA结果作图：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>data.table<span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>ggplot2<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">pca_re <span class="operator">=</span> fread<span class="punctuation">(</span><span class="string">&quot;pca1.txt&quot;</span><span class="punctuation">,</span>skip <span class="operator">=</span> <span class="number">2</span><span class="punctuation">)</span></span><br><span class="line">plot <span class="operator">=</span> ggplot<span class="punctuation">(</span>pca_re<span class="punctuation">,</span> aes<span class="punctuation">(</span>x<span class="operator">=</span>PC1<span class="punctuation">,</span> y<span class="operator">=</span>PC2<span class="punctuation">)</span><span class="punctuation">)</span>  <span class="operator">+</span> geom_point<span class="punctuation">(</span>size<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line">  geom_hline<span class="punctuation">(</span>yintercept <span class="operator">=</span> <span class="number">0</span><span class="punctuation">)</span>  <span class="operator">+</span> <span class="comment"># 添加x坐标</span></span><br><span class="line">  geom_vline<span class="punctuation">(</span>xintercept <span class="operator">=</span> <span class="number">0</span><span class="punctuation">)</span> <span class="operator">+</span> <span class="comment"># 添加y坐标</span></span><br><span class="line">  theme_bw<span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line">ggsave<span class="punctuation">(</span>plot <span class="operator">=</span>plot<span class="punctuation">,</span> filename<span class="operator">=</span><span class="string">&quot;2D-PCA.pdf&quot;</span><span class="punctuation">)</span>   <span class="comment"># 以第一主成分为X轴，第二主成分为y轴作图即可</span></span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230619/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这里的群体结构差异有但不能很好分类。如果做群体结构分析的时候可以分成明显的几个不同的部分，那就要考虑后续做GWAS分析过程中要考虑群体结构的分层问题了。这里我们只是拿部分数据跑个简单的流程，继续往下。</p><h3 id="3-4-基于GLM模型进行GWAS分析"><a href="#3-4-基于GLM模型进行GWAS分析" class="headerlink" title="3.4 基于GLM模型进行GWAS分析"></a>3.4 基于GLM模型进行GWAS分析</h3><p>现在分别有了如下的基因型数据（GWAS_vcf.vcf）、表型数据（phenotype.tassel.txt），就可以以PCA结果作为协变量，基于GLM模型进行GWAS分析：</p><p><img src="https://www.shelven.com/tuchuang/20230619/7.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/7.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># -excludeLastTrait 移除表型数据的最后一列（不太明白什么意思？官网说可用于删除的最后一列用于MLM或GLM的群体结构）</span><br><span class="line"># -combine&lt;id&gt; 用在新的pipneline开头，将多个来自不同pipeline的数据集组合到一起，后面使用 -input&lt;id&gt; 指定，以 -intersect 结尾</span><br><span class="line"># -FixedEffectLMPlugin 使用GLM模型</span><br><span class="line"></span><br><span class="line">perl /opt/TASSEL5/run_pipeline.pl -fork1 -importGuess GWAS_vcf.vcf -fork2 -importGuess phenotype.tassel.txt  -fork3 -importGuess pca1.txt -excludeLastTrait -combine5 -input1 -input2 -input3 -intersect -FixedEffectLMPlugin -endPlugin -export glm</span><br></pre></td></tr></table></figure><p>主要结果为<code>glm1.txt</code>，结果如下：</p><p><img src="https://www.shelven.com/tuchuang/20230619/8.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/8.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>我们主要用到的数据是：</p><ul><li>第一列：表型</li><li>第二列：SNP名称</li><li>第三列：染色体编号</li><li>第四列：处于染色体的位置</li><li>第六列：p值</li></ul><h3 id="3-5-基于MLM模型进行GWAS分析"><a href="#3-5-基于MLM模型进行GWAS分析" class="headerlink" title="3.5 基于MLM模型进行GWAS分析"></a>3.5 基于MLM模型进行GWAS分析</h3><p>在tassel中运行MLM模型和GLM模型相似，MLM模型需要亲缘关系矩阵来定义个体之间的关系，以PCA和kinship作为协变量，基于MLM模型进行GWAS分析：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># -mlm -mlmVarCompEst P3D -mlmCompressionLevel Optimum 使用P3D和最优水平压缩</span><br><span class="line"></span><br><span class="line">perl /opt/TASSEL5/run_pipeline.pl -fork1 -importGuess GWAS_vcf.vcf -fork2 -importGuess phenotype.tassel.txt -fork3 -importGuess pca1.txt -fork4 -importGuess kinship.txt -combine5 -input1 -input2 -input3 -intersect -combine6 -input5 -input4 -mlm -mlmVarCompEst P3D -mlmCompressionLevel Optimum -export mlm</span><br></pre></td></tr></table></figure><p>主要结果为<code>mlm6.txt</code>（前5个是5个表型的分析数据），结果如下：</p><p><img src="https://www.shelven.com/tuchuang/20230619/9.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/9.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>我们主要用到的数据是：</p><ul><li>第一列：表型</li><li>第二列：SNP名称</li><li>第三列：染色体编号</li><li>第四列：处于染色体的位置</li><li>第七列：p值</li></ul><h3 id="3-6-计算核酸多态性值"><a href="#3-6-计算核酸多态性值" class="headerlink" title="3.6 计算核酸多态性值"></a>3.6 计算核酸多态性值</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vcftools --vcf GWAS_vcf.vcf --site-pi --out pi</span><br></pre></td></tr></table></figure><p>用vcftools就可以根据vcf文件统计平均每个位点的π值。</p><p><img src="https://www.shelven.com/tuchuang/20230619/10.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/10.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div><h2 id="4-GWAS结果可视化"><a href="#4-GWAS结果可视化" class="headerlink" title="4. GWAS结果可视化"></a>4. GWAS结果可视化</h2><div class="story post-story"><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># qqman包绘制曼哈顿图和qq图</span></span><br><span class="line">library<span class="punctuation">(</span>qqman<span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>data.table<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">glm <span class="operator">&lt;-</span> fread<span class="punctuation">(</span><span class="string">&quot;glm1.txt&quot;</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="punctuation">,</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;Trait&quot;</span><span class="punctuation">,</span><span class="string">&quot;Marker&quot;</span><span class="punctuation">,</span><span class="string">&quot;Chr&quot;</span><span class="punctuation">,</span><span class="string">&quot;Pos&quot;</span><span class="punctuation">,</span><span class="string">&quot;p&quot;</span><span class="punctuation">)</span><span class="punctuation">]</span></span><br><span class="line"><span class="built_in">names</span><span class="punctuation">(</span>glm<span class="punctuation">)</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;Trait&quot;</span><span class="punctuation">,</span><span class="string">&quot;SNP&quot;</span><span class="punctuation">,</span><span class="string">&quot;CHR&quot;</span><span class="punctuation">,</span><span class="string">&quot;BP&quot;</span><span class="punctuation">,</span><span class="string">&quot;P&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">mlm <span class="operator">&lt;-</span> fread<span class="punctuation">(</span><span class="string">&quot;mlm6.txt&quot;</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="punctuation">,</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;Trait&quot;</span><span class="punctuation">,</span><span class="string">&quot;Marker&quot;</span><span class="punctuation">,</span><span class="string">&quot;Chr&quot;</span><span class="punctuation">,</span><span class="string">&quot;Pos&quot;</span><span class="punctuation">,</span><span class="string">&quot;p&quot;</span><span class="punctuation">)</span><span class="punctuation">]</span></span><br><span class="line">mlm <span class="operator">&lt;-</span> na.omit<span class="punctuation">(</span>mlm<span class="punctuation">)</span>     <span class="comment"># 需要注意mlm结果文件有一行是NaN值，去除</span></span><br><span class="line"><span class="built_in">names</span><span class="punctuation">(</span>mlm<span class="punctuation">)</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;Trait&quot;</span><span class="punctuation">,</span><span class="string">&quot;SNP&quot;</span><span class="punctuation">,</span><span class="string">&quot;CHR&quot;</span><span class="punctuation">,</span><span class="string">&quot;BP&quot;</span><span class="punctuation">,</span><span class="string">&quot;P&quot;</span><span class="punctuation">)</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义作图函数</span></span><br><span class="line">plot_func <span class="operator">&lt;-</span> <span class="keyword">function</span><span class="punctuation">(</span>data<span class="punctuation">,</span>trait<span class="punctuation">,</span>model<span class="punctuation">)</span><span class="punctuation">&#123;</span></span><br><span class="line">  pdf<span class="punctuation">(</span>paste<span class="punctuation">(</span>model<span class="punctuation">,</span><span class="string">&quot;_&quot;</span><span class="punctuation">,</span>trait<span class="punctuation">,</span><span class="string">&quot;.manhttan.pdf&quot;</span><span class="punctuation">,</span>sep <span class="operator">=</span> <span class="string">&quot;&quot;</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">      width <span class="operator">=</span> <span class="number">11</span><span class="punctuation">,</span>height <span class="operator">=</span> <span class="number">6</span><span class="punctuation">)</span></span><br><span class="line">  manhattan<span class="punctuation">(</span>data<span class="punctuation">[</span>Trait<span class="operator">==</span>trait<span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">5</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="comment"># 曼哈顿图需要的是&quot;SNP&quot;,&quot;CHR&quot;,&quot;BP&quot;,&quot;P&quot;这几列信息</span></span><br><span class="line">            suggestiveline <span class="operator">=</span> <span class="built_in">F</span><span class="punctuation">,</span></span><br><span class="line">            genomewideline <span class="operator">=</span> <span class="built_in">F</span><span class="punctuation">)</span> <span class="comment"># remove the suggestive(Default -log10(1e-5)) and genome-wide(Default -log10(5e-8)) significance lines，也就是去掉两条阈值线</span></span><br><span class="line">  dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">  pdf<span class="punctuation">(</span>paste<span class="punctuation">(</span>model<span class="punctuation">,</span><span class="string">&quot;_&quot;</span><span class="punctuation">,</span>trait<span class="punctuation">,</span><span class="string">&quot;.qq.pdf&quot;</span><span class="punctuation">,</span>sep <span class="operator">=</span> <span class="string">&quot;&quot;</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">  qqman<span class="operator">::</span>qq<span class="punctuation">(</span>data<span class="punctuation">[</span>Trait<span class="operator">==</span>trait<span class="punctuation">,</span><span class="punctuation">]</span><span class="operator">$</span>P<span class="punctuation">)</span>  <span class="comment"># qq图只要获得每个SNP位点的p值就可以作图</span></span><br><span class="line">  dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分下不同表型</span></span><br><span class="line"><span class="keyword">for</span> <span class="punctuation">(</span>trait <span class="keyword">in</span> unique<span class="punctuation">(</span>glm<span class="operator">$</span>Trait<span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">&#123;</span></span><br><span class="line">  plot_func<span class="punctuation">(</span>glm<span class="punctuation">,</span>trait<span class="punctuation">,</span><span class="string">&quot;glm&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"><span class="keyword">for</span> <span class="punctuation">(</span>trait <span class="keyword">in</span> unique<span class="punctuation">(</span>mlm<span class="operator">$</span>Trait<span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">&#123;</span></span><br><span class="line">  plot_func<span class="punctuation">(</span>mlm<span class="punctuation">,</span>trait<span class="punctuation">,</span><span class="string">&quot;mlm&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>生成各个表型GWAS分析的曼哈顿图和qq图：</p><p><img src="https://www.shelven.com/tuchuang/20230619/11.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/11.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>随便查看一个MLM模型的GWAS曼哈顿图和qq图结果：</p><p><img src="https://www.shelven.com/tuchuang/20230619/13.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/13.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://www.shelven.com/tuchuang/20230619/12.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230619/12.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;本篇笔记主要记录如何在linux命令行中用&lt;code&gt;TASSEL5&lt;/code&gt;和&lt;code&gt;PLINK2&lt;/code&gt;软件做GWAS分析，以及如何可视化GWAS结果（在R中绘制曼哈顿图和QQ图）。关于GWAS是做什么的，以及基本概念介绍可以看上一篇笔记介绍：&lt;a href=&quot;https://www.shelven.com/2023/06/16/a.html&quot;&gt;群体基因组学——概述和图表详解 - 我的小破站 (shelven.com)&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="群体基因组学" scheme="http://www.shelven.com/categories/%E7%BE%A4%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
    
    
    <category term="群体基因组学" scheme="http://www.shelven.com/tags/%E7%BE%A4%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
    
    <category term="Tassel5" scheme="http://www.shelven.com/tags/Tassel5/"/>
    
    <category term="Plink" scheme="http://www.shelven.com/tags/Plink/"/>
    
  </entry>
  
  <entry>
    <title>群体基因组学——概述和图表详解</title>
    <link href="http://www.shelven.com/2023/06/16/a.html"/>
    <id>http://www.shelven.com/2023/06/16/a.html</id>
    <published>2023-06-16T08:47:16.000Z</published>
    <updated>2023-06-16T08:57:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近看群体遗传学的文章，苦于不能理解研究者做的另人眼花缭乱的图表……哎，该补补基础了。这篇笔记先从樊龙江主编的《植物基因组学》教材开始学习基础概念，有部分摘自知乎和一些文献，加上这个领域论文图表的解读和自己的理解做汇总整理。下一篇笔记自己实操跑一下GWAS流程。</p><span id="more"></span><h2 id="1-群体基因组学概述"><a href="#1-群体基因组学概述" class="headerlink" title="1. 群体基因组学概述"></a>1. 群体基因组学概述</h2><div class="story post-story"><p>群体基因组学，将基因组数据和技术与群体遗传学理论体系结合，<strong>通过覆盖全基因组范围的多态性推测全基因组效应和位点特异性效应</strong>。说人话，这门学科的作用就是通过检测SNP等的信息来回答关于物种起源、进化以及环境适应的分子机制。</p><p>群体基因组研究的基础是高质量的群体基因型数据，在获得群体原始测序数据后，<strong>如何高效准确的进行变异检测和群体基因分型是后续研究的关键</strong>（因为要用到大量的测序数据，所以也很烧钱）。</p><img src="https://www.shelven.com/tuchuang/20230615/1.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 50%;" /><p>变异检测的流程可分为<strong>数据质控——读序联配——变异检测——基因分型</strong></p><p>上图的bam文件通过软件GATK检测结构变异或者SNP就是变异检测，这部分内容我前面组装三代基因组测序数据中使用过，因为我只有一个二倍体基因组，所以当时也没用到基因分型，GATK用法可以看我的这篇笔记：</p><p><a href="https://www.shelven.com/2023/03/07/a.html">0基础学习三代基因组测序组装（9）——GATK检测植物基因组SNP和INDEL变异 - 我的小破站 (shelven.com)</a></p></div><h2 id="2-群体基因组进化分析方法"><a href="#2-群体基因组进化分析方法" class="headerlink" title="2. 群体基因组进化分析方法"></a>2. 群体基因组进化分析方法</h2><div class="story post-story"><h3 id="2-1-群体系统发生树和群体结构"><a href="#2-1-群体系统发生树和群体结构" class="headerlink" title="2.1 群体系统发生树和群体结构"></a>2.1 群体系统发生树和群体结构</h3><p><strong>群体发生树</strong>反映特定群体中个体间亲缘关系。一般我们做进化树都是用单拷贝基因，而做群体研究构建进化树用了整个基因组数据信息（比如全基因组SNP、Indel、SV等），能一定程度抵消横向基因转移和单个基因速率差异带来的分析误差，<strong>比单基因构建的结果更接近真实进化关系</strong>。全基因组SNP构建进化树（一般是把SNP merge到一起），个体间两两比较，根据SNP差异计算个体差异距离，构建群体差异矩阵。软件有<code>MEGA</code>、<code>PHYLIP</code>、<code>FastTree</code>等。</p><p>还有一个非常重要的概念：<strong>群体遗传结构，</strong>指基因型或者基因在空间和时间上的分布模式，包括<strong>种群内的遗传变异</strong>和<strong>种群间的遗传分化</strong>。<strong>种群遗传结构反映物种进化历史中的一些特殊进化事件</strong>，软件有Structure、Frappe等。总体流程确定亚群数（K），然后计算各个体归属第K亚群的概率Q值。以及主成分分析（PCA）也常用于群体结构划分。</p><img src="https://www.shelven.com/tuchuang/20230615/2.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 80%;" /><p>上图是华农王茂军老师课题组做的不同二倍体棉花的物种发生树和群体结构。</p><h3 id="2-2-群体遗传分化"><a href="#2-2-群体遗传分化" class="headerlink" title="2.2 群体遗传分化"></a>2.2 群体遗传分化</h3><h4 id="2-2-1-固定系数-Fst"><a href="#2-2-1-固定系数-Fst" class="headerlink" title="2.2.1 固定系数 Fst"></a>2.2.1 固定系数 Fst</h4><p>在明确一个物种存在群体结构后，通产需要量化该物种亚群间的分化程度。<strong>固定系数（Fst）反映群体等位基因杂合性水平，Fst越大，种群间遗传分化程度越大</strong>。</p><ul><li><strong>Fst&#x3D; (Ht-Hs）&#x2F;Ht</strong><br>Hs:亚群体中的平均杂合度<br>Ht:复合群体中的平均杂合度</li></ul><h4 id="2-2-2-核酸多态性-𝝅"><a href="#2-2-2-核酸多态性-𝝅" class="headerlink" title="2.2.2 核酸多态性 𝝅"></a>2.2.2 核酸多态性 𝝅</h4><p>做群体的文献中经常出现这个指标类似<code>𝝅野生/𝝅栽培</code>这样的系数，核酸多态性（Nucleotide diversity）是用于衡量群体的多态性的，为群体内平均每两个样本每个位点的差异核苷酸数量。一般称为𝝅，<strong>自然群体多态性一般高于栽培群体</strong>。</p><p>需要注意下这个𝝅的单位，一般都在 <strong>10^(-3)</strong> 这个数量级。</p><p>这些群体分化的相关系数计算可以用软件<code>Arlequin</code>、<code>FSTAT</code>、<code>VCFtools</code>等。</p><h3 id="2-3-基因流（渐渗）"><a href="#2-3-基因流（渐渗）" class="headerlink" title="2.3 基因流（渐渗）"></a>2.3 基因流（<strong>渐渗</strong>）</h3><p>基因流（也称为基因迁移）指从一个物种的一个种群向另一个种群引入遗传物质，从而改变群体的遗传组成。</p><p>当一个种群中的一个个体迁移到另一个群体，就会把基因带到新的群体，也就是产生“基因的流动”。基因流越大，群体间的相似性越大，会导致群体间基因频率和基因型频率呈现<strong>哈迪-温伯格平衡</strong>（在一个随机交配的大群体中，没有突变、选择等外界环境因素的影响，基因频率和基因型频率世代恒定）。</p><p>自然选择和遗传漂变会使群体之间的差异增加，而基因流的作用是“弱化”群体间的遗传差异，群体之间趋于一致。在植物中，种子扩散和花粉传播是植物基因流的最主要方式。从上面的描述也能看出，基因流与Fst成反比；与种群间地理距离成反比。检测方法主要有D-统计（ABBA-BABA）、Treemix、Migrate-N等。</p><h3 id="2-4-种群动态和进化历史"><a href="#2-4-种群动态和进化历史" class="headerlink" title="2.4 种群动态和进化历史"></a>2.4 种群动态和进化历史</h3><p><strong>种群动态</strong>指种群大小或密度随时间或空间的变化。</p><p><strong>有效群体大小（Ne）</strong>指与实际群体有相同基因频率方差或者相同杂合度衰减率的理想群体含量，通常小于绝对群体大小，决定群体平均近郊系数增量大小，<strong>反映群体遗传结构中基因的平均纯和速度</strong>。种群动态理论与方法主要包括种群大小及其变化、种群生长模式的量化描述，以及引起种群变化的外在环境因素。基于全基因组的种群历史动态分析方法主要有PSMC、MSMC等。</p><p><img src="https://www.shelven.com/tuchuang/20230615/3.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/3.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上图展示了不同地理来源的拟南芥的有效群体大小变化。可以看到拟南芥在9万～12万年前，由祖先群体在非洲开始分离形成亚群。欧亚祖先群体在 8 万年前从非洲分化形成，然后欧亚拟南芥群体在4万年前进一步分化。这一模式与包括人类在内的多种物种分化时间模式非常相似，这意味着间冰期和洪积世时期（即9万～12万年前）的气候事件对物种分布十分重要。</p></div><h2 id="3-基因组选择信号"><a href="#3-基因组选择信号" class="headerlink" title="3. 基因组选择信号"></a>3. 基因组选择信号</h2><div class="story post-story"><p>自然群体区别于栽培群体的最大特征是丰富的遗传多样性。草本作物祖先自然群体多态性（𝝅）一般在 0.003~0.008，高于相应的驯化作物遗传多态性。</p><ul><li><p>遗传瓶颈效应：由于环境骤变或人类活动，某一生物种群的规模迅速减少，仅有少部分个体能够顺利通过瓶颈事件，之后可能经历一段恢复期并产生大量后代。由于连锁不平衡（LD）的作用，不仅仅是驯化基因的多态性降低，其侧翼区域遗传多样性也会降低。</p></li><li><p>有害性突变（deleterious SNP，dSNP）指导致生物个体的整体适合度（fitness）减低的突变。植物被驯化的过程中，基因组上有害突变的数量、频率会不断增加和累积，导致驯化后的作物在原本自然环境中适合度降低，称为作物的“驯化成本”。</p></li><li><p>在作物群体基因组中，一个明显的特征是存<strong>在大量来自野生祖先种的遗传渐渗</strong>。来自野生群体的基因渗入可以有效增加栽培种的环境适应性。</p></li></ul><p>选择分析可以在宏观和微观两个尺度下进行选择基因和信号鉴定。</p><h3 id="3-1-宏观进化尺度"><a href="#3-1-宏观进化尺度" class="headerlink" title="3.1 宏观进化尺度"></a>3.1 宏观进化尺度</h3><blockquote><p><strong>宏观进化尺度</strong></p><ul><li>基于基因：Ka&#x2F;Ks（非同义替换比同义替换）、MKT检验（比较物种内和物种间的Ka&#x2F;Ks值）</li><li>基于进化速率：HKA</li></ul></blockquote><p>宏观尺度检测选择信号的方法，<strong>通常在亲缘关系相近的物种之间进行同源基因序列的比较</strong>，判断基因是否在某一物种或进化分支上存在加速进化的情况。</p><p>判断加速进化的<strong>背景指标是Ka&#x2F;Ks</strong>，比较每个位点区域中非同义替换率与每个位点的同义替换率。同义突变总体是<strong>中性进化</strong>的（中性基准），如果存在过多的非同义突变意味着存在倾向于蛋白序列改变的正向选择（<strong>正选择表现为固定某种有利等位基因，负选择表现为清除不利的等位基因</strong>）。MKT检验本质是比较物种内和物种间的Ka&#x2F;Ks值，中性情况下相等，如果物种间的比值显著高于物种内比值，意味着物种中存在正向选择信号，如果是在作物驯化中，可能是人工选择的信号。</p><h3 id="3-2-微观进化尺度"><a href="#3-2-微观进化尺度" class="headerlink" title="3.2 微观进化尺度"></a>3.2 微观进化尺度</h3><blockquote><p><strong>微观进化尺度</strong></p><ul><li>基于等位基因频谱：Tajima’s D, Fu andLi’sD, Fay and Wu’sH, CLR, Hp</li><li>基于连锁不平衡：LRH、iHS、连锁不平衡衰减（LDD）、IBD分析</li><li>基于群体分化：LKT、LSBL</li><li>组合方法：CLR、XP-CLR（适合SNP大数据集）、DH检验、CMS</li></ul></blockquote><p>微观尺度鉴定方法，在正向选择的作用下，有利等位基因在群体中频率会变高甚至固定。当有利等位基因和周围变异达到较高频率的时候，这段区间在群体水品就会呈现遗传多态性降低的现象，也就是<strong>选择性清除</strong>（selective sweep）。</p><p>比如，栽培物种在选择性清除区域的遗传多样性显著降低，就是驯化区域的典型特征。选择性清除还会使<strong>连锁不平衡区块延长、群体间固定指数增大、Tajima‘s D值为负且显著偏离零</strong>。中性模型为基础的检测方法很多，Tajima‘s D检验是最经典的。</p><p>总体来说，选择信号检测原理和方法可以分为以下5类：</p><ul><li><p>A 基于群体多态性。原理：受选择位点两侧序列多态性因连带效应保持很低水平。在驯化选择区间内，𝝅野生&#x2F;𝝅栽培的值变高。</p></li><li><p>B 基于等位基因频谱。原理：有利突变不断在群体中固定，当完全固定时，周围可能由于随机突变出现稀有等位基因</p></li><li><p>C 基于连锁不平衡。原理：选择性清除会引起包含等位基因的单倍体纯和性提高，与周围变异的连锁不平衡程度变高。当群体处于正向选择作用下时，基因突变及其连锁位点在正选择的作用下，在短时间内会达到较高频率，形成大片段的纯合单倍型。</p></li><li><p>D 基于群体分化。随着受选择的等位基因频率上升，导致与原群体的Fst变大。Fst的取值范围为0-1，1表示群体间完全分化的位点，0表示在群体间完全没有分化的位点。</p></li><li><p>E 组合方法。</p></li></ul><p><img src="https://www.shelven.com/tuchuang/20230615/4.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/4.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>在检测选择信号时，需要考虑遗传漂移（genetic drift）对选择信号的影响，为了降低该影响，通常在全基因组扫描窗口的基础上，仅考虑极端值（前5%）区域作为选择位点（这点很重要，后面实操的时候会说）。</strong></p><p>选择信号检测方法都是基于<strong>自下而上</strong>的，通过群体基因组扫描鉴定具有选择信号的基因组区域，从而挖掘可能与某种表型或者适应性相关联的基因，假阳性高。</p><p>也可以用<strong>自上而下</strong>的方法进行佐证，比如获得该物种多个时间点或者多个世代的群体基因组数据，就可以直接检测该位点等位基因频率变化加以验证，比如用QTL、GWAS等传统定位方法。</p></div><h2 id="4-连锁不平衡（LD）"><a href="#4-连锁不平衡（LD）" class="headerlink" title="4. 连锁不平衡（LD）"></a>4. 连锁不平衡（LD）</h2><div class="story post-story"><p>连锁不平衡理论对群体研究非常重要，前面说到基于连锁不平衡的原理检测选择信号，这里再加深一下理解。</p><p><strong>连锁不平衡（linkage disequilibrium，LD）：在某一群体中，两个基因同时遗传的频率大于随机组合的频率。</strong></p><p>连锁不平衡的三个衡量指标：</p><ul><li>D值：D &#x3D; P(AB) - P(A) X P(B)，也就是实际概率减去独立遗传的理论概率，D值绝对值越大，连锁程度越大。</li><li>D‘值：理解维归一化之后的D值，归一化之的值可以用于比较不同基因连锁程度的大小。0表示完全连锁平衡，独立遗传；1表示完全连锁不平衡。</li><li>r平方</li></ul><p>r值定义如下：</p><p><img src="https://www.shelven.com/tuchuang/20230615/5.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/5.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>通常文献里也是用r平方来表征连锁不平衡程度，<strong>r平方等于0时，表示完全连锁平衡，独立遗传；r平方等于1时, 表示完全连锁不平衡。</strong></p><p>这里就要引出另一个很重要的概念——LD衰减，也是做GWAS出现最多的图。</p><h3 id="4-1-LD衰减曲线"><a href="#4-1-LD衰减曲线" class="headerlink" title="4.1 LD衰减曲线"></a>4.1 LD衰减曲线</h3><p><strong>LD衰减指位点间由连锁不平衡到连锁平衡的演变过程</strong>；LD衰减的速度在不同物种间或同物种的不同亚群间差异非常大。所以，通常会使用“<strong>LD衰减距离</strong>”来描述LD衰减速度的快慢。</p><p><strong>衰减距离</strong>，是当平均LD系数衰减到一定大小的时候，对应的物理距离。（这个一定大小是没有特别规定的，比如可以到一半大小，可以到0.5，可以到0.1）</p><p><img src="https://www.shelven.com/tuchuang/20230615/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上面的图描绘了不同水稻群体的LD衰减曲线，横坐标是物理距离（kb），纵坐标是LD系数（r^2）。</p><p>LD衰减曲线就是利用曲线图来呈现基因组上分子标记间的平均LD系数随着标记间距离增加而降低的过程。大概的计算原理就是先统计基因组上两两标记间的LD系数大小，再按照标记间的距离对LD系数进行分类，最终计算出一定距离的分子标记间的平均LD系数大小。</p><p>我们看左边的图，Japonic这个亚群（红色的线）在基因组100Kb距离的平均LD系数大小为0.35，到了200kb距离，对应的LD系数降低到了不到0.3。LD衰减速度在不同亚群是不一样，Japonica衰减速度最慢（其他亚群在物理距离很小的时候LD系数降就从0.35衰减到了0.3），衰减距离最大。</p><p>知道这个衰减速度快慢和衰减距离有什么用呢？</p><blockquote><p>LD衰减速度越慢，形成的单体型区块越大，关联分析中需要的群体和标记数目越少，但定位越不精准。此外，同一个连锁群上，LD衰减地慢说明该群体受到选择，一般来说，野生群体比驯化改良群体LD衰减快，遗传多样性高。而驯化选择会导致群体遗传多样性下降，位点间的相关性（连锁程度）加强。所以，<strong>驯化程度越高，选择强度越大的群体，LD衰减速度越慢</strong>。</p></blockquote><p>也就是说左边这个图的4个水稻品种中，Japonic是驯化程度最高的。</p><p><strong>LD衰减距离应用：</strong></p><ul><li>辅助分析进化和选择，同一个连锁群上，LD衰减地慢说明该群体受到选择。</li><li>一般而言，两个位点在基因组上离得<strong>越近</strong>，相关性就<strong>越强</strong>，LD系数就<strong>越大</strong>。反之，LD系数越小。也就是说，<strong>随着位点间的距离不断增加，LD系数通常情况下会慢慢下降</strong>。</li><li>一般而言，LD系数大于0.8就是强相关。如果LD系数小于0.1，则可以认为没有相关性。如果LD衰减到0.1这么大的区间内都没有标记覆盖的话，即使这个区间有一个效应很强的功能突变，也是检测不到关联信号的。所以，通常可以通过比较LD衰减（到0.1）距离和标记间的平均距离，来判断标记是否对全基因组有足够的覆盖度。</li><li>如果GWAS检测到显著关联的区间后，则可以通过进一步绘制局部的LD单倍型块图（这个后面讲），来进一步判断显著相关的SNP和目标基因间是否存在强LD关系。</li><li>基因组上那些受选择的区域相比普通的区域，LD衰减速度也是更慢的。</li><li>判断GWAS所需标记量，决定GWAS的检测效力以及精度； <strong>GWAS标记量 &#x3D; 基因组大小 &#x2F; LD衰减距离</strong>。</li></ul><h3 id="4-2-单倍型块（Haplotype-Block）"><a href="#4-2-单倍型块（Haplotype-Block）" class="headerlink" title="4.2 单倍型块（Haplotype Block）"></a>4.2 单倍型块（Haplotype Block）</h3><p>描述LD不平衡的另一个常用的图就是LD单倍型块图。</p><p><strong>单倍型块，即连锁不平衡区域，是指同一条染色体上处于连锁不平衡状态的一段连续的区域</strong>。单倍型块分析可以用于筛选tag SNP、确定候选基因的范围等。</p><p><img src="https://www.shelven.com/tuchuang/20230615/7.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/7.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>颜色从白色到红色，代表连锁程度从低到高，方框中的数值为LD系数r^2，为了美观，这里将 r2^2乘以了100。</p><p>上面的图中每个正方形是两个相邻SNP的LD值计算结果，如果大于设定的阈值（这里估计是大于94），那么就构成一个block，图中黑框为一个block，共有三个。可以从三个block中分别选择一个SNP作为Tag SNP来分别代表这三个block。</p></div><h2 id="5-全基因组关联分析（GWAS）"><a href="#5-全基因组关联分析（GWAS）" class="headerlink" title="5. 全基因组关联分析（GWAS）"></a>5. 全基因组关联分析（GWAS）</h2><div class="story post-story"><p>全基因组关联分析（Genome-Wide Association Study, GWAS），以连锁不平衡（linkage disequilibrium, LD）为基础，通过分析<strong>数百个或者数千个个体</strong>的高密度分子标记的分离特征（一般是上万个或者上百万个SNP标记），筛选与复杂性状表现型变异相关联的分子标记，进而分析分子标记对表现型的遗传效应。</p><p>插一句题外话，GWAS中最后一个字母已经是study，在写英文文章的时候不要写成GWAS study……</p><p>传统的<strong>QTL定位研究通常以2个亲本杂交群体为研究对象, 通过连锁作图定位目标性状位点</strong>。局限性是投入大量资源构建数量庞大的重组群体。而关联分析则可以利用个体在全基因组范围的遗传变异标记进行多态性检测，获得更高分辨率的定位结果（单碱基水平）, 遗传变异来源也更为广泛，根据统计量或者显著性P值筛选最有可能影响该性状的遗传变异，往往能定位到比双亲本作图群体中更多的性状关联位点（这可节省太多时间了）。</p><p>GWAS的局限性在于可以确定相关位点但不能直接确定基因本身，假阳性也比较高。解决这一局限性有两种策略，一是算法，二是群体的选取。</p><h3 id="5-1-GWAS算法模型"><a href="#5-1-GWAS算法模型" class="headerlink" title="5.1 GWAS算法模型"></a>5.1 GWAS算法模型</h3><p>目前用的算法模型有以下几种：</p><ul><li><p><strong>1.GLM （Generalized linear model；一般线性模型）</strong></p></li><li><p><strong>2.MLM （Mixed linear model；混合线性模型）</strong></p></li><li><p>3.GEMMA、CMLM、SUPER、FarmCPU、Blink</p></li></ul><p>主要介绍前两个，GLM模型以<strong>群体结构矩阵 Q或主成分分析矩阵PCs为协变量</strong>做回归拟合。</p><img src="https://www.shelven.com/tuchuang/20230615/8.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/8.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:50%;" /><p>如果两个表型差异很大，但群体本身还含有其他的遗传差异（如地域等），则<strong>那些与该表型无关的遗传差异也会影响到相关性</strong>。<strong>MLM模型可以把群体结构矩阵 Q、亲缘关系矩阵（kinship）或联合利用主成分分析矩阵PCs和亲缘关系矩阵为协变量</strong>，把这种位点校正掉（也就是抑制假关联）。</p><img src="https://www.shelven.com/tuchuang/20230615/9.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/9.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 67%;" /><p>其他模型大多是基于GLM和MLM进行优化，比如GEMMA 计算个体基因型相似性矩阵，排除了LD的干扰。其他暂时就不多说了，感兴趣再深入研究研究。</p><h3 id="5-2-GWAS群体选取"><a href="#5-2-GWAS群体选取" class="headerlink" title="5.2 GWAS群体选取"></a>5.2 GWAS群体选取</h3><p>群体中丰富的表型变异和充分的遗传重组是GWAS 成功的关键条件，有以下选取策略：</p><ul><li>(1) 群体内没有明显的群体结构，样本间没有过近的亲缘关系，同时具有丰富的表型变异</li><li>(2) 群体来自具有一定水平遗传分化的不同类群(如不同亚种与亚群)，具有丰富的遗传和表型变异，但同时不同类群之间存在频繁的遗传交流，保证目标性状在不同类群内部也存在一定水平的变异</li><li>目前GWAS样本量普遍大于100份</li></ul><p>前面也说过，同时要考虑GWAS标记量，计算公式<strong>GWAS标记量 &#x3D; 基因组大小 &#x2F; LD衰减距离</strong>。</p><p>在用GATK做基因分型的时候也要注意，<strong>结果一般保留maf值大于0.05的 SNP</strong>，通常认为这是在驯化选择区间内。</p><h3 id="5-3-GWAS结果图解"><a href="#5-3-GWAS结果图解" class="headerlink" title="5.3 GWAS结果图解"></a>5.3 GWAS结果图解</h3><p>还是先说明一下，做GWAS需要有三类数据：<strong>SNP数据、表型数据和群体结构</strong>。这些数据在实操会再次提到。</p><p>GWAS的结果通常以<strong>曼哈顿图</strong>和<strong>QQ图</strong>来展示。曼哈顿图显示每个SNP在关联分析中的显著性水平; QQ 图反映关联分析的效果。</p><p>以下图721份水稻GWAS结果图为例：</p><p><img src="https://www.shelven.com/tuchuang/20230615/10.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/10.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="5-3-1-曼哈顿图（Manhattan-Plot）"><a href="#5-3-1-曼哈顿图（Manhattan-Plot）" class="headerlink" title="5.3.1 曼哈顿图（Manhattan Plot）"></a>5.3.1 曼哈顿图（Manhattan Plot）</h4><p>图4（A）就是一个曼哈顿图，每个点代表一个SNP，x轴代表SNP在基因组上的遗传位置，y轴为–log10  (P-value)，显著性水平线有红蓝两条（P &#x3D; 0.01和P&#x3D; 0.05）。y轴值越大，说明该位点表型的关联程度越大，受到连锁不平衡（LD）的影响，<strong>基因组上强关联位点周围的SNP也会呈现出关联性由高到低连续变化的信号强度，从而在P值小的地方出现尖峰（peak）</strong>。</p><p>上面文章深入分析水稻6号染色体上与抽穗期相关的一个尖峰，将其定位在Hd3a附近, 估计候选区间大概在 2.68–4.62 Mb (图4C)。这个候选区间是如何确定的呢？</p><p>我们通常将显著关联SNP在<strong>N</strong> kb以内的位置确认为相关区间，这个N就是对应的<strong>LD衰减距离</strong>。确定GWAS鉴定的候选区间后，就可以在候选区间内找到基因功能注释和表型相关的基因，或者有其他组学或者功能研究支持的基因进行验证和深入研究。</p><h4 id="5-3-2-QQ图（QQ-Plot）"><a href="#5-3-2-QQ图（QQ-Plot）" class="headerlink" title="5.3.2 QQ图（QQ Plot）"></a>5.3.2 QQ图（QQ Plot）</h4><p>图4（B）是QQ图，<strong>本质上就是做两组数据的比较，判断是否一致</strong>。每个点代表一个SNP，横坐标是期望的P-value，纵坐标为实际观测到的P-value，虚线代表实际观测和期望的P-value值一致的情况。</p><p>我们做关联分析，当然是希望大部分的位点观测值和期望值一样（在对角线，也就是这里的虚线上），也就是这部分位点确定是与性状不关联的。一部分位点在虚线的上方，也就是观测值超过期望值，说明这些位点的效应超过随机效应，也就是这些位点是与性状显著相关的。也就是出现4（B）这个图才是理想的结果。</p><p>还有以下三种其他情况：</p><p><img src="https://www.shelven.com/tuchuang/20230615/11.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/11.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>1 观察值低于期望值（点在对角线下方），可能是模型不合理，P-value被过度矫正。或者是群体中大量SNP位点间存在连锁不平衡，有效位点数（相互间不存在连锁不平衡的位点）明显低于实际位点数，所以P-value的期望值被低估了。</li><li>2 观察值和期望值相同，说明没有找到与性状显著关联的位点。</li><li>3 观察值显著高于期望值（点全都在对角线上方），也就是所有位点都与某个性状显著相关，说明分析模型不合理，假阳性太多了。</li></ul><p>现在基于GWAS分析还衍生出其他诸如TWAS（基因表达量做标记）、PWAS（蛋白做标记）、EWAS（甲基化表观信息做标记）等关联分析方法，做标记的信息不同，本质上也都是和表型做关联分析。</p></div><h2 id="6-泛基因组（Pan-Genome）"><a href="#6-泛基因组（Pan-Genome）" class="headerlink" title="6. 泛基因组（Pan-Genome）"></a>6. 泛基因组（Pan-Genome）</h2><div class="story post-story"><p>想了想还是把泛基因组也放了进来，虽然泛基因组研究方法和上面的研究方法不一样，但也是群体基因组学的一个重要分支，主要是开展群体基因组重测序和遗传变异的分析工作。</p><p>我们知道<strong>单一的参考基因组仅能代表物种基因组空间范围的一小部分</strong>（同一个物种不同亚群基因组存在差异），以线性参考基因组进行群体变异的分析就会错失一些变异位点（SV&amp;CNV&amp;PAV）。所以这个时候我们就需要获取一个物种的全部遗传信息（只能说是相对的全部），并解析每个个体间的遗传变异，这就诞生了泛基因组（Pan-Genome）研究。</p><h3 id="6-1-核心基因-x2F-非核心基因"><a href="#6-1-核心基因-x2F-非核心基因" class="headerlink" title="6.1 核心基因&#x2F;非核心基因"></a>6.1 核心基因&#x2F;非核心基因</h3><p>在泛基因组中有两个非常重要的概念：</p><ul><li>1 <strong>核心基因（core genome）</strong>：在物种所有个体内都存在的，保持生命体基本功能，代表物种基本表型特征。</li><li>2 <strong>非必需基因（dispensable genome）</strong>：使不同个体在表型，生活方式、代谢等多方面发生明显的分化，最终表现为丰富的遗传多样性。</li></ul><p><img src="https://www.shelven.com/tuchuang/20230615/12.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/12.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上图可以看出核心基因和非必需基因的区别，以及最后融合成pan-genome。主要注意一点，<strong>核心基因是这个物种中所有个体都存在的，但不一定是必须基因</strong>，必须基因的概念比核心基因窄，核心基因包含了必须基因。</p><p>现在的pan-genome分析的文章一般还会对基因集做更进一步的细分：</p><ul><li><strong>core</strong> 核心基因，所有样本共享</li><li><strong>softcore</strong> 次核心基因，90%样本共享</li><li><strong>dispensable</strong> 非必需基因，多个样本共享但 &lt; 90%</li><li><strong>private</strong> 特有基因，1%，或者仅存在于一个样本中</li></ul><p><img src="https://www.shelven.com/tuchuang/20230615/13.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/13.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>对不类型基因集进行<strong>保守性分析</strong>，有助于挖掘适应性进化或驯化中发挥关键作用的基因。文章中用的比较多的还有核心基因&#x2F;非必需基因与<strong>重复序列相关性分析</strong>、<strong>表达水平分析</strong>等等，这些展开来说太多了，具体文章具体分析。</p><h3 id="6-2-泛基因组组装"><a href="#6-2-泛基因组组装" class="headerlink" title="6.2 泛基因组组装"></a>6.2 泛基因组组装</h3><p>泛基因组组装方式现在见的比较多的是两种：</p><h4 id="6-2-1-基于二代测序（迭代组装）"><a href="#6-2-1-基于二代测序（迭代组装）" class="headerlink" title="6.2.1 基于二代测序（迭代组装）"></a>6.2.1 基于二代测序（迭代组装）</h4><img src="https://www.shelven.com/tuchuang/20230615/14.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/14.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:67%;" /><p><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02224-8">How the pan-genome is changing crop genomics and improvement | Genome Biology | Full Text (biomedcentral.com)</a></p><p>将多个样本二代下机数据与参考基因组比对，<strong>未比对上的reads组装成新的contigs</strong>，将这些contigs添加到原始参考序列中（一般直接放在最后），最终获的物种的泛基因图谱。</p><p>看得出来这种方式简单粗暴，可以快速得到泛基因组信息（也省钱），但是有二代数据的通病——<strong>如果物种的基因组比较大，或者测序深度不够深的话，组装的contigs连续性会比较差。</strong></p><h4 id="6-2-2-基于三代测序（从头组装-amp-图形泛基因组）"><a href="#6-2-2-基于三代测序（从头组装-amp-图形泛基因组）" class="headerlink" title="6.2.2 基于三代测序（从头组装&amp;图形泛基因组）"></a>6.2.2 基于三代测序（从头组装&amp;图形泛基因组）</h4><img src="https://www.shelven.com/tuchuang/20230615/15.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/15.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:67%;" /><p><a href="https://www.nature.com/articles/s41477-020-0733-0">Plant pan-genomes are the new reference | Nature Plants</a></p><p>对多个个体进行从头组装、注释，从全基因组层面识别变异信息，也是现在用的最广泛的方法。不依赖参考基因组，但是需要较高的测序深度（保证准确性），组装到染色体水平。图形泛基因组是在从头组装的基础上，<strong>基于图论的组装方法</strong>，利用有向图将物种基因组分为核心基因组和非必需基因组。</p><h3 id="6-3-泛基因组分析"><a href="#6-3-泛基因组分析" class="headerlink" title="6.3 泛基因组分析"></a>6.3 泛基因组分析</h3><p>主要可以分以下两部分：</p><p><img src="https://www.shelven.com/tuchuang/20230615/16.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230615/16.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这部分内容留到以后我做泛基因组组装实操再做详细解释和补充（先挖个坑）。</p><p>下篇笔记将简单实操一下GWAS分析，使用软件为<code>TASSEL</code>。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近看群体遗传学的文章，苦于不能理解研究者做的另人眼花缭乱的图表……哎，该补补基础了。这篇笔记先从樊龙江主编的《植物基因组学》教材开始学习基础概念，有部分摘自知乎和一些文献，加上这个领域论文图表的解读和自己的理解做汇总整理。下一篇笔记自己实操跑一下GWAS流程。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="群体基因组学" scheme="http://www.shelven.com/categories/%E7%BE%A4%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
    
    
    <category term="群体基因组学" scheme="http://www.shelven.com/tags/%E7%BE%A4%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>三维基因组学——如何用Hi-C数据分析拓扑关联结构域</title>
    <link href="http://www.shelven.com/2023/06/15/a.html"/>
    <id>http://www.shelven.com/2023/06/15/a.html</id>
    <published>2023-06-14T16:24:17.000Z</published>
    <updated>2023-06-16T08:49:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇笔记主要记录三维基因组学的学习，以及演示如何利用Hi-C数据分析Compartment和拓扑关联结构域（TAD），所使用的分析Hi-C数据的软件为HiC-Pro，可视化软件为HiCPlotter和R包HiTC。</p><span id="more"></span><h2 id="1-三维基因组简介"><a href="#1-三维基因组简介" class="headerlink" title="1. 三维基因组简介"></a>1. 三维基因组简介</h2><div class="story post-story"><p>首先什么是三维基因组学？三维基因组学(Three-Dimensional Genomics, 3D Genomics)，是指在考虑基因组序列、基因结构及其调控元件的同时，对基因组序列在细胞核内的三维空间结构，及其对基因转录、复制、修复和调控等生物过程中功能的研究。</p><p>随着基因组学和表观基因组学的发展，基因组学研究的维度经历了从一维到三维的转变：</p><ul><li><strong>一维：</strong>基因组序列的测定与组装</li><li><strong>二维：</strong>调控序列&#x2F;转录因子—基因互作网络、染色质状态、表观修饰</li><li><strong>三维：</strong>基因组的三维空间结构</li></ul><p><img src="https://www.shelven.com/tuchuang/20230614/2.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>基因组不是简单的线性序列，是有三维空间结构的，而且这种三维空间结构可以对DNA辅助、基因转录调控、染色质浓缩分离等生物学过程产生重要的影响。</p><p>我们知道，真核生物的染色质结构由低级到高级可以分为4种：</p><ul><li><p><strong>一级结构：</strong>一系列核小体相互连接成的<strong>念珠状结构</strong></p></li><li><p><strong>二级结构：</strong>由核小体连接起来的纤维状结构经螺旋化形成中空的<strong>螺线管</strong></p></li><li><p><strong>三级结构：</strong>由螺线管螺旋化形成的筒状结构，称为<strong>超螺线管</strong></p></li><li><p><strong>四级结构：</strong>超螺线管进一步螺旋折叠形成<strong>染色单体</strong></p></li></ul><p><img src="https://www.shelven.com/tuchuang/20230614/1.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>三维基因组的层级结构类似于真核生物的染色质结构，在不同的分辨率下也可以划分为4个层级结构：</p><ul><li><p><strong>染色质环（Chromatin loops），分辨率：&lt;1 Kb - few Mb</strong>：染色质在空间中形成的环状结构，使相距很远的染色质区域在三维空间中可以聚集在一起。</p></li><li><p><strong>拓扑关联结构域（Topologically associating Domains, TAD），分辨率：40 Kb - 3 Mb</strong>：相互作用相对频繁的染色质区域。</p></li><li><p><strong>染色质区室（A&#x2F;B compartments），分辨率：1 - 100 Mb</strong>：A compartments：<strong>开放的染色质</strong>、表达活跃、基因丰富、较高的GC含量、激活型的组蛋白标记，通常位于细胞核内部；B compartments：<strong>关闭的染色质</strong>、表达不活跃、基因缺乏、结构紧凑、沉默基因的组蛋白标记，通常位于细胞核外围。</p></li><li><p><strong>染色质疆域（Chromosome Territory, CT），分辨率：~100 Mb</strong>：在真核生物中，细胞核内染色质分布并不是随机的，为了跨越较大距离实现相互作用，这些染色质会在三维空间中靠的更近，这就是染色质疆域。</p></li></ul><p><img src="https://www.shelven.com/tuchuang/20230614/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>不同层次分辨率下的研究重点不同，比如最小的loop层次对应的是基因级别甚至更小的元件互作；10kb级别一般就可以鉴定TAD之间的互作关系（也是研究比较多的）；更大一些的染色质区室也是研究比较多的内容；在染色质疆域这个层次主要就是研究染色体之间的互作关系了。相应的，分辨率越高，需要的有效互作数据量也越大。</p></div><h2 id="2-三维基因组技术"><a href="#2-三维基因组技术" class="headerlink" title="2. 三维基因组技术"></a>2. 三维基因组技术</h2><div class="story post-story"><p>目前三维基因组结构的检测时基于染色体构象捕获技术，也就是<strong>3C（chromosome conformation capture）技术</strong>，3C是所有染色体构象捕获技术的基础。根据染色质的互作类型，3C技术又可以大致分为5种方法：</p><ul><li><strong>1 versus 1</strong>：3C的由来，经过酶切、DNA片段绑定、反向交联后，通过qPCR确认互作位点。</li><li><strong>1 versus Many&#x2F;All</strong>：4C技术，3C技术的升级版。反向交联前和3C一样，经过了第二轮消化和绑定，通过特定位点的反向PCR检测特定位点与全基因组潜在位点互作情况。</li><li><strong>Many versus Many</strong>：5C技术，基于3C的另一升级版。5C技术的通量增大。</li><li><strong>Many versus All</strong>：Capture-C技术，最大不同是在互作片段对的捕捉技术上，它是利用<strong>生物素标记</strong>反向互补到限制酶酶切位点，从而进行对所有感兴趣的互作位点和全基因组位点之间互作对之间的捕捉。 </li><li><strong>All</strong> <strong>versus All</strong></li></ul><p>其中“1”“Many”以及“All”代表的是在一次实验中所涉及的位点，比如说 “1 versus All” 的意义就是该次实验调查的是一个位点和全基因组中所有可能潜在互作位点之间的互作情况。</p><blockquote><p>近年来all versus All也就是检测全局的互作技术发展比较快，有以下一些技术应用：</p><ol><li>Hi-C技术。近年最火的全基因组 3D 基因组测序技术，不仅可以用于检测全基因组的三维基因组结构和染色质互作，同时还可以用于辅助基因组组装（同样用的很多，现在组参考基因组都要测HiC，以组装到染色体水平）等。</li><li>ChIA-PET技术（ chromatin interaction analysis paired-end tag sequencing）：与3C基础上发展的其他技术不同，区别在于第一步对于互作位点的 DNA 破碎不是通过限制酶进行消化，而是利用超声波击碎。然后应用抗体对特定蛋白参与的互作区段进行富集，并对这些互作区段进行消化连接，提取含有接头的双端序列（ paired end tag， PET）进行互作检测。</li><li>DLO Hi-C技术（ digestion-ligation-only Hi-C）：该技术相对于传统的全基因组染色体构象捕获技术 Hi-C 而言更加高效简单，仅需要两轮的消化连接过程，无须生物素标记，未连接的 DNA 也可以被有效地去除，极大地提高了染色体构想捕获效率。 DLO Hi-C 技术更像是 Hi-C 技术的一个升级优化。 </li><li>原位Hi-C (<em>in situ</em> Hi-C)：使用完整的细胞核进行后续反应，减少了Hi-C中随机连接造成的背景噪音。使用四碱基酶Mbol进行酶切，提高了分辨率，实验时间由Hi-C的7天缩短至3天。</li><li>HiChIP (<em>in situ</em> Hi-C followed by chromatin immunoprecipitation)：该技术是一种利用原位Hi-C原理和转座酶介导构建文库来解析染色质构象的方法。</li></ol></blockquote><img src="https://www.shelven.com/tuchuang/20230614/4.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/4.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /></div><h2 id="3-利用Hi-C数据分析拓扑关联结构域（TAD）"><a href="#3-利用Hi-C数据分析拓扑关联结构域（TAD）" class="headerlink" title="3. 利用Hi-C数据分析拓扑关联结构域（TAD）"></a>3. 利用Hi-C数据分析拓扑关联结构域（TAD）</h2><div class="story post-story"><p>现在Hi-C测序是应用最广泛的三维基因组学技术，对Hi-C数据的处理，构建Hi-C互作图谱和鉴定TAD结构域是最关键的问题，也发展了一大批专门的生物信息学算法软件，我这里用经典的软件<code>HiC-Pro</code>、<code>HiCPlotter</code>和<code>R包HiTC</code>跑一遍Hi-C数据分析的流程。</p><p>为了快速得到结果，这里选择了<strong>Gossypium hirsutum</strong>四倍体陆地棉的两条染色体参考序列，和一部分Hi-C测序结果（50万条reads的双端测序结果）跑下流程。后续制作Hi-C互作矩阵，和分析Compartment和TAD的<code>.bed</code>后缀文件和<code>.matrix</code>后缀文件来自尤师姐（前面的这点数据做不出互作图，太少了，跑完所有数据又很慢……）。</p><p>两个软件安装过程就不说了，可以参考github官方，如果HiC-Pro很难安装依赖的话可以用官方提供的singularity镜像：</p><p><a href="https://github.com/nservant/HiC-Pro/tree/master">nservant&#x2F;HiC-Pro: HiC-Pro: An optimized and flexible pipeline for Hi-C data processing (github.com)</a></p><p>当前路径文件结构如下：</p><p><img src="https://www.shelven.com/tuchuang/20230614/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="3-1-获得染色质互作矩阵（HiC-Pro）"><a href="#3-1-获得染色质互作矩阵（HiC-Pro）" class="headerlink" title="3.1 获得染色质互作矩阵（HiC-Pro）"></a>3.1 获得染色质互作矩阵（HiC-Pro）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 1.准备酶切片段</span><br><span class="line">## dpnii是选择的限制性核酸内切酶，可以用别的，查看digest_genome.py源码</span><br><span class="line">python digest_genome.py Gh_genome.fa –r dpnii –o Gh_dpnii.bed</span><br><span class="line"># 2.统计酶切片段大小</span><br><span class="line">awk ’&#123;print $3-$2;&#125;’ Gh_dpnii.bed &gt; Gh_dpnii_size.txt</span><br><span class="line"># 3.构建参考基因组索引，生成基因组大小的文件</span><br><span class="line">samtools faidx Gh_genome.fa</span><br><span class="line">awk ‘&#123;print $1”\t”$2;&#125;’ Gh_genome.fa.fai &gt; Gh_size.txt</span><br></pre></td></tr></table></figure><p>这里酶切参考基因组生成的bed文件如下所示：</p><img src="https://www.shelven.com/tuchuang/20230614/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 4.修改config文件</span><br><span class="line">## 主要修改基因组索引文件路径、基因组大小文件路径、酶切片段文件路径和分辨率</span><br><span class="line">## BOWTIE2_IDX_PATH、GENOME_SIZE、GENOME_FRAGMENT、BIN_SIZE</span><br><span class="line"></span><br><span class="line">vim config.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">## Alignment options</span><br><span class="line">#######################################################################</span><br><span class="line"></span><br><span class="line">FORMAT = phred33</span><br><span class="line">MIN_MAPQ = 0</span><br><span class="line"></span><br><span class="line">BOWTIE2_IDX_PATH = /home/Bioinfor/Gh_index</span><br><span class="line">BOWTIE2_GLOBAL_OPTIONS = --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder</span><br><span class="line">BOWTIE2_LOCAL_OPTIONS =  --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">## Annotation files</span><br><span class="line">#######################################################################</span><br><span class="line"></span><br><span class="line">REFERENCE_GENOME = Gh</span><br><span class="line">GENOME_SIZE = /home/Bioinfor/Gh_size.txt</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">## Digestion Hi-C</span><br><span class="line">#######################################################################</span><br><span class="line"></span><br><span class="line">GENOME_FRAGMENT = /home/Bioinfor/Gh_dpnii.bed</span><br><span class="line">LIGATION_SITE = AAGCTAGCTT</span><br><span class="line">MIN_FRAG_SIZE = 100</span><br><span class="line">MAX_FRAG_SIZE = 160000</span><br><span class="line">MIN_INSERT_SIZE = 200</span><br><span class="line">MAX_INSERT_SIZE = 600</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">## Contact Maps</span><br><span class="line">#######################################################################</span><br><span class="line"></span><br><span class="line">BIN_SIZE = 5000 20000 100000</span><br><span class="line">MATRIX_FORMAT = upper</span><br></pre></td></tr></table></figure><p>主要是修改以上内容，但也要注意下Hi-C双端测序文件的后缀，要让软件能匹配上。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 5.运行HiC-Pro，获得染色质互作矩阵</span><br><span class="line">HiC-Pro -c config.txt -i Gh/ -o HiC_Pro_out</span><br></pre></td></tr></table></figure><p>HiC-Pro的主要结果放置在目录HiC_Pro_out&#x2F; hic_results&#x2F;matrix&#x2F;Gh&#x2F;下，为5000、20000、100000 分辨率下的<code>_abs.bed</code> 以及<code>_iced.matrix</code>后缀文件。其他结果文件和分析图片可以在hic_results文件夹里查看，这里不展示了。</p><p>主要展示后续用的文件，以下为Gh_5000_abs.bed文件：</p><img src="https://www.shelven.com/tuchuang/20230614/7.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/7.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>这个文件将染色体划分为5000 bp的bin，并且在第四列进行编号。</p><p>以下为Gh_5000_iced.matrix文件：</p><img src="https://www.shelven.com/tuchuang/20230614/8.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/8.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>这个文件第一列和第二列都是bin编号，第三列为两个bin之间归一化之后的互作强度。</p><h3 id="3-2-绘制染色质互作图（HiCPlotter）"><a href="#3-2-绘制染色质互作图（HiCPlotter）" class="headerlink" title="3.2 绘制染色质互作图（HiCPlotter）"></a>3.2 绘制染色质互作图（HiCPlotter）</h3><p>这里使用的是尤师姐提供的跑完了A01染色体的<code>Gh_20000_iced.matrix</code>与<code>Gh_20000_abs.bed</code>文件（我的示例Hi-C数据量太少）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># HiCPlotter绘制染色体互作图</span><br><span class="line">python HiCPlotter.py -f Gh_20000_iced.matrix -o Ghir_A01 -r 20000 -tri 1 -bed Gh_20000_abs.bed -n Ghir_A01 -chr Ghir_A01</span><br><span class="line">## HiCPlotter绘制染色质互作几个常用参数：</span><br><span class="line">-chr 染色体名称，如果染色体名称不是Chr*，-chr参数需传入对应的值</span><br><span class="line">-o 输出文件名</span><br><span class="line">-tri 默认值为0，1代表着传入的matrix和bed文件是HiC-Pro运行的结果</span><br><span class="line">-r 分辨率</span><br><span class="line">-n 任务名</span><br><span class="line"></span><br><span class="line"># ZModem协议传输文件</span><br><span class="line">sz Ghir_A01-Ghir_A01.ofBins\(0-5887\).20K.png</span><br></pre></td></tr></table></figure><p>染色体Ghir_A01内部的互作图<code>Ghir_A01-Ghir_A01.ofBins(0-5887).20K.png</code>如下所示。</p><img src="https://www.shelven.com/tuchuang/20230614/Ghir_A01-Ghir_A01.ofBins(0-5887).20K.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/Ghir_A01-Ghir_A01.ofBins(0-5887).20K.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 50%;" /><h3 id="3-3-鉴定TAD（HiCPlotter）"><a href="#3-3-鉴定TAD（HiCPlotter）" class="headerlink" title="3.3 鉴定TAD（HiCPlotter）"></a>3.3 鉴定TAD（HiCPlotter）</h3><p>这里使用的数据与3.2一样。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># HiCPlotter鉴定TAD</span><br><span class="line">python HiCPlotter.py -f Gh_20000_iced.matrix –bed Gh_20000_abs.bed –o TAD -r 20000 -n Ghir_A01 -chr Ghir_A01 -tri 1 -fh 0 -s 600 -e 900 -ptd 1 -pi 1</span><br><span class="line">## HiCPlotter绘制TAD几个常用参数：</span><br><span class="line">-ptd 默认0，输入1，调用绘制TAD算法</span><br><span class="line">-fh 输入文件中抬头需要删除的行数，没有header lines就是0</span><br><span class="line">-s 起始位点（第几个bin）</span><br><span class="line">-e 结束位点（第几个bin）</span><br><span class="line"></span><br><span class="line"># ZModem协议传输文件</span><br><span class="line">sz TAD-Ghir_A01.ofBins\(600-900\).20K.png</span><br></pre></td></tr></table></figure><p>染色体Ghir_A01的12Mb到18Mb之间TAD鉴定结果图<code>TAD-Ghir_A01.ofBins(600-900).20K.png</code>如下：</p><img src="https://www.shelven.com/tuchuang/20230614/TAD-Ghir_A01.ofBins(600-900).20K.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/TAD-Ghir_A01.ofBins(600-900).20K.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 50%;" /><h3 id="3-4-鉴定染色质区室和TAD（HiTC包）"><a href="#3-4-鉴定染色质区室和TAD（HiTC包）" class="headerlink" title="3.4 鉴定染色质区室和TAD（HiTC包）"></a>3.4 鉴定染色质区室和TAD（HiTC包）</h3><p>这里使用的数据来自尤师姐提供的<code>LG02_50000_abs.bed</code>与<code>LG02_50000_iced.matrix</code>文件，也是HiC-Pro跑出来的结果文件。</p><p>因为用到了R包，集群R有点问题，我暂时传到本地用自己电脑跑了下：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载和加载HiTC包</span></span><br><span class="line"><span class="operator">&gt;</span> BiocManager<span class="operator">::</span>install<span class="punctuation">(</span><span class="string">&quot;HiTC&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> setwd<span class="punctuation">(</span><span class="string">&quot;D:/zhuomian/D5_50Kb/D5_50Kb&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> library<span class="punctuation">(</span>HiTC<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据（importC函数读取HiC-pro的结果）</span></span><br><span class="line"><span class="operator">&gt;</span> mydata <span class="operator">&lt;-</span> importC<span class="punctuation">(</span><span class="string">&quot;D:/zhuomian/D5_50Kb/D5_50Kb/LG02_50000_iced.matrix&quot;</span><span class="punctuation">,</span> xgi.bed <span class="operator">=</span> <span class="string">&quot;D:/zhuomian/D5_50Kb/D5_50Kb/LG02_50000_abs.bed&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主成分分析和鉴定Compartment</span></span><br><span class="line"><span class="operator">&gt;</span> pc <span class="operator">&lt;-</span> pca.hic<span class="punctuation">(</span>mydata<span class="operator">$</span>LG02LG02<span class="punctuation">,</span> npc <span class="operator">=</span> <span class="number">1</span><span class="punctuation">,</span> asGRangesList <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> write.csv<span class="punctuation">(</span>pc<span class="punctuation">,</span> file <span class="operator">=</span> <span class="string">&quot;D:/zhuomian/D5_50Kb/D5_50Kb/LG02_50k.csv&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> mydata2 <span class="operator">&lt;-</span> read.table<span class="punctuation">(</span><span class="string">&quot;D:/zhuomian/D5_50Kb/D5_50Kb/LG03_50k.csv&quot;</span><span class="punctuation">,</span>header <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span>sep <span class="operator">=</span> <span class="string">&quot;,&quot;</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> barplot<span class="punctuation">(</span>mydata2<span class="operator">$</span>score<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 热图展示</span></span><br><span class="line"><span class="operator">&gt;</span> mapC<span class="punctuation">(</span>mydata<span class="operator">$</span>LG02LG02<span class="punctuation">,</span> trim.range <span class="operator">=</span> <span class="number">0.94</span><span class="punctuation">,</span> col.pos <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;white&quot;</span><span class="punctuation">,</span> <span class="string">&quot;red&quot;</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p>这里主成分分析得到的LG02_50k.csv，统计第一主成分score做条形图就可以鉴定染色质区室Compartment A&#x2F;B了，以下链接是提出者的文章。</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2858594/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2858594/</a></p><img src="https://www.shelven.com/tuchuang/20230614/11.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/11.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>跑出来的互作热图如下：</p><img src="https://www.shelven.com/tuchuang/20230614/9.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/9.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>也可以选取染色体的一部分（一般是自己感兴趣的部分），做热图：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> data1 <span class="operator">&lt;-</span> extractRegion<span class="punctuation">(</span>mydata<span class="operator">$</span>LG02LG02<span class="punctuation">,</span>chr <span class="operator">=</span> <span class="string">&quot;LG02&quot;</span><span class="punctuation">,</span> from <span class="operator">=</span> <span class="number">1000</span><span class="punctuation">,</span> to <span class="operator">=</span> <span class="number">5000000</span><span class="punctuation">)</span></span><br><span class="line"><span class="operator">&gt;</span> mapC<span class="punctuation">(</span>data1<span class="punctuation">,</span> trim.range <span class="operator">=</span> <span class="number">0.94</span><span class="punctuation">,</span>col.pos <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;white&quot;</span><span class="punctuation">,</span> <span class="string">&quot;red&quot;</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><img src="https://www.shelven.com/tuchuang/20230614/10.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230614/10.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>关于如何用HiTC包分析Hi-C数据，也可以看bioconductor的一篇文章：</p><p><a href="https://bioconductor.org/packages/release/bioc/vignettes/HiTC/inst/doc/HiC_analysis.pdf">Analyzing Hi-C data with the HiTC BioC package (bioconductor.org)</a></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;本篇笔记主要记录三维基因组学的学习，以及演示如何利用Hi-C数据分析Compartment和拓扑关联结构域（TAD），所使用的分析Hi-C数据的软件为HiC-Pro，可视化软件为HiCPlotter和R包HiTC。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="三维基因组学" scheme="http://www.shelven.com/categories/%E4%B8%89%E7%BB%B4%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
    
    
    <category term="HiC-Pro" scheme="http://www.shelven.com/tags/HiC-Pro/"/>
    
    <category term="HiCPlotter" scheme="http://www.shelven.com/tags/HiCPlotter/"/>
    
    <category term="HiTC" scheme="http://www.shelven.com/tags/HiTC/"/>
    
  </entry>
  
  <entry>
    <title>单细胞转录组分析</title>
    <link href="http://www.shelven.com/2023/06/13/a.html"/>
    <id>http://www.shelven.com/2023/06/13/a.html</id>
    <published>2023-06-13T14:06:51.000Z</published>
    <updated>2023-06-16T08:50:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近因为学校网络信息中心升级防火墙，导致集群无法访问公网，我搭建的反向代理服务器也暂时无法使用（真的想吐槽学校的网络管理员，三个星期了还没能解决集群的网络问题）……近期要进行中期答辩，先用向日葵远程一下实验室闲置的电脑应急，顺便把最近的学习笔记补上。</p><p>这篇笔记主要记录下单细胞组学的学习，以及单细胞转录组（Single-cell RNA-sequencing，scRNA-seq）的分析流程。</p><span id="more"></span><h2 id="1-单细胞测序发展"><a href="#1-单细胞测序发展" class="headerlink" title="1. 单细胞测序发展"></a>1. 单细胞测序发展</h2><div class="story post-story"><p>我们做植物高通量测序做的最多的是RNA-seq，比较不同组织、不同时期或者不同处理下同一个组织基因的差异表达。我们做RNA-seq是建立在对一个<strong>组织</strong>的细胞进行测序的基础上，<strong>而组织是几类细胞的集合，因此我们得到的基因表达量是所有细胞的平均值。</strong></p><p>单细胞测序可以在单个细胞的水平上构建细胞图谱，让我们更深入了解植物组织的细胞类型，获取每个细胞的转录本信息，研究细胞的发育动态（比如细胞如何进行分化）等等。</p><p>Nature杂志每年都会总结每个领域最有价值的年度技术，<strong>2018年是单细胞转录组技术，2019年是单细胞多组学技术，2020年是空间转录组技术</strong>，可以看出带有单细胞和空间分辨率转录组技术应用的重要性。</p><img src="https://www.shelven.com/tuchuang/20230613/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>上图是单细胞技术在植物中的研究历程，最后一个2022年的<strong>Stereo-seq</strong>也就是华大自研的<strong>时空组学技术</strong>，据华大发表在cell上的文章<a href="https://www.sciencedirect.com/science/article/pii/S0092867422003993">Spatiotemporal transcriptomic atlas of mouse organogenesis using DNA nanoball-patterned arrays</a>描述，Stereo-seq的技术参数优于当前其他空间转录组技术，对空间异质性的描述更为灵敏和直观。</p><p>对于Stereo-seq我个人的理解是补上了部分空间转录组测序无法做到单个细胞分辨率的短板，真正做到对动植物的组织或者器官中的所有细胞进行转录组信息分析，鉴定不同类型细胞的差异基因表达，构建空间图谱来分辨不同细胞的发育轨迹。感兴趣可以看下面华大的这篇scStereo-seq技术用于拟南芥的文章：<a href="https://www.sciencedirect.com/science/article/pii/S1534580722002519">The single-cell stereo-seq reveals region-specific cell subtypes and transcriptome profiling in Arabidopsis leaves - ScienceDirect</a></p></div><h2 id="2-单细胞测序平台"><a href="#2-单细胞测序平台" class="headerlink" title="2. 单细胞测序平台"></a>2. 单细胞测序平台</h2><div class="story post-story"><ul><li><p><strong>10x Genomics Chromium</strong>  微流控芯片技术获得单细胞反应体系，并在传统文库构建的基础上引入标签，通过追溯标签序列将众多mRNA、表面蛋白信息定位回原来的单个细胞。捕获效率最高达65%</p></li><li><p><strong>BD</strong> <strong>Rhapsody™ Single-Cell Analysis System</strong>  能为单细胞中每个转录本标记特异性分子标签，实现单细胞水平上基因表达谱的绝对定量。捕获效率最高达80%</p></li><li><p><strong>Illumina® Bio-Rad® Single-Cell Sequencing</strong> <strong>Solution</strong>  捕获效率低，仅为3%，但测序成本相对较低</p></li><li><p><strong>ICELL8</strong> <strong>Single-Cell</strong> <strong>System</strong>  捕获效率为30%，成本相对较低</p></li><li><p><strong>C1™</strong> <strong>单细胞全自动制备系统</strong>  通量低、成本高、周期慢、对试验人员要求高，操作较繁琐和困难</p></li></ul></div><h2 id="3-单细胞测序分析流程"><a href="#3-单细胞测序分析流程" class="headerlink" title="3. 单细胞测序分析流程"></a>3. 单细胞测序分析流程</h2><div class="story post-story"><img src="https://www.shelven.com/tuchuang/20230613/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>质控部分和RNA-seq没有区别，去掉低质量的读序和测序接头。10X Genomics平台测的单细胞数据需要通过Cell Ranger回比到参考基因组，示例用法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> cellranger count --id=sample345</span><br><span class="line">    --transcriptome=/opt/refdata-cellranger-GRCh38-3.0.0</span><br><span class="line">    --fastqs=/home/jdoe/runs/HAWT7ADXX/outs/fastq_path</span><br><span class="line">    --sample=mysample</span><br><span class="line"># --id  文件名</span><br><span class="line"># --transcriptome 参考基因组</span><br><span class="line"># --fastqs 转录组数据所在的路径</span><br><span class="line"># --sample 指定要使用的样本</span><br></pre></td></tr></table></figure><p>这里主要记录下细胞过滤到亚群定义和标记基因筛选所要用到的软件Seurat4。因为我自己没有这方面的实验数据，仅仅只是尝试跑下流程，以下分析流程和代码来自：</p><p><a href="https://zhuanlan.zhihu.com/p/359020041">单细胞转录组|Seurat 4.0 使用指南 - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/465392721">《Seurat 4 R包源码解析》 总目录 | 单细胞转录组分析标准流程 - 知乎 (zhihu.com)</a></p><p>示例数据来自10X Genomics免费提供的外周血单核细胞(PBMC)数据集：<br><a href="https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz">https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz</a></p><p>将示例数据上传至集群，解压，得到如下文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">├── barcodes.tsv（10X Genomics测序的与细胞相关的barcode信息，用于标识细胞）</span><br><span class="line">├── genes.tsv（基因信息，包括了基因组数据库人类登记号和基因名称）</span><br><span class="line">└── matrix.mtx（基因表达量矩阵）</span><br></pre></td></tr></table></figure><ul><li>这三个文件实际上要通过软件<code>Cell Ranger</code>对10X Genomics单细胞测序的下机数据进行比对基因组，统计捕获的细胞数、测序量得到。详细可以参考官方Cell Ranger软件的用法和结果分析，这里用的是官方整理后的数据，只进行下一步Seurat分析的演示。</li></ul><p>以所在目录为工作目录，在linux中键入R进入交互命令行，运行Seurat。</p><h3 id="3-1-导入数据和初步过滤"><a href="#3-1-导入数据和初步过滤" class="headerlink" title="3.1 导入数据和初步过滤"></a>3.1 导入数据和初步过滤</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装和加载Seurat和dplyr（用于数据清洗）R包</span></span><br><span class="line">BiocManager<span class="operator">::</span>install<span class="punctuation">(</span><span class="string">&quot;Seurat&quot;</span><span class="punctuation">)</span> </span><br><span class="line">BiocManager<span class="operator">::</span>install<span class="punctuation">(</span><span class="string">&quot;dplyr&quot;</span><span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>dplyr<span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>Seurat<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入数据并初步筛选</span></span><br><span class="line">pbmc.data <span class="operator">&lt;-</span> Read10X<span class="punctuation">(</span>data.dir<span class="operator">=</span><span class="string">&quot;/path/to/yourfile&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Seurat对象，过滤检测少于200个基因的细胞，和少于3个细胞检测出的基因</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> CreateSeuratObject<span class="punctuation">(</span>counts <span class="operator">=</span> pbmc.data<span class="punctuation">,</span> project <span class="operator">=</span> <span class="string">&quot;pbmc3k&quot;</span><span class="punctuation">,</span> min.cells <span class="operator">=</span> <span class="number">3</span><span class="punctuation">,</span> min.features <span class="operator">=</span> <span class="number">200</span><span class="punctuation">)</span></span><br><span class="line">pbmc</span><br></pre></td></tr></table></figure><img src="https://www.shelven.com/tuchuang/20230613/1.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:150%;" /><p>可以看到初步过滤后，现在的一个数据集包含了2700个细胞的13714个基因。</p><h3 id="3-2-细胞过滤"><a href="#3-2-细胞过滤" class="headerlink" title="3.2 细胞过滤"></a>3.2 细胞过滤</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新增一列percent.mt用于统计映射到线粒体基因组的reads百分比</span></span><br><span class="line">pbmc<span class="punctuation">[[</span><span class="string">&quot;percent.mt&quot;</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> PercentageFeatureSet<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> pattern <span class="operator">=</span> <span class="string">&quot;^MT-&quot;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制细胞的三种特征，nFeature_RNA（每个细胞测到的特异基因数目）、nCount_RNA（每个细胞测到所有基因的表达量之和）、percent.mt的小提琴图</span></span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig01_cell_feature.png&quot;</span><span class="punctuation">)</span></span><br><span class="line">VlnPlot<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> features <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&quot;nFeature_RNA&quot;</span><span class="punctuation">,</span> <span class="string">&quot;nCount_RNA&quot;</span><span class="punctuation">,</span> <span class="string">&quot;percent.mt&quot;</span><span class="punctuation">)</span><span class="punctuation">,</span> ncol <span class="operator">=</span> <span class="number">3</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 细胞特征间的相关性绘图</span></span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig02_cell_feature_correlation.png&quot;</span><span class="punctuation">,</span> width<span class="operator">=</span><span class="number">1000</span><span class="punctuation">,</span> height<span class="operator">=</span><span class="number">400</span><span class="punctuation">)</span>  </span><br><span class="line">plot1 <span class="operator">&lt;-</span> FeatureScatter<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> feature1 <span class="operator">=</span> <span class="string">&quot;nCount_RNA&quot;</span><span class="punctuation">,</span> feature2 <span class="operator">=</span> <span class="string">&quot;percent.mt&quot;</span><span class="punctuation">)</span></span><br><span class="line">plot2 <span class="operator">&lt;-</span> FeatureScatter<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> feature1 <span class="operator">=</span> <span class="string">&quot;nCount_RNA&quot;</span><span class="punctuation">,</span> feature2 <span class="operator">=</span> <span class="string">&quot;nFeature_RNA&quot;</span><span class="punctuation">)</span></span><br><span class="line">CombinePlots<span class="punctuation">(</span>plots <span class="operator">=</span> <span class="built_in">list</span><span class="punctuation">(</span>plot1<span class="punctuation">,</span> plot2<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据特殊基因的数目以及线粒体基因比例过滤细胞，这里选取200 &lt; nFeature_RNA &lt; 2500 和percent.mt &lt; 5的数据</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> subset<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> subset <span class="operator">=</span> nFeature_RNA <span class="operator">&gt;</span> <span class="number">200</span> <span class="operator">&amp;</span> nFeature_RNA <span class="operator">&lt;</span> <span class="number">2500</span> <span class="operator">&amp;</span> percent.mt <span class="operator">&lt;</span> <span class="number">5</span><span class="punctuation">)</span> </span><br><span class="line">pbmc</span><br></pre></td></tr></table></figure><p>fig01_cell_feature.png如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig01_cell_feature.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig01_cell_feature.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这里可以看到有的细胞检测到的特异基因数特别多，可能是因为多个细胞被同时捕获了，而特异基因数特别少的可能是低质量细胞。而线粒体基因比例特别高的细胞，有可能是一些快要死亡的细胞。这些低质量的细胞需要在这一步被过滤。</p><p>fig02_cell_feature_correlation.png如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig02_cell_feature_correlation.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig02_cell_feature_correlation.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这两个图分别表示了每个细胞测到所有基因的表达量之和与线粒体基因组百分比呈负相关，每个细胞测到所有基因的表达量之和与每个细胞测到的特异基因数目呈正相关。</p><img src="https://www.shelven.com/tuchuang/20230613/2.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:150%;" /><p>这一步过滤后数据集剩下2638个细胞，共13714个基因。</p><h3 id="3-3-细胞群体聚类"><a href="#3-3-细胞群体聚类" class="headerlink" title="3.3 细胞群体聚类"></a>3.3 细胞群体聚类</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 表达水平标准化</span></span><br><span class="line"><span class="comment">## normalization.method  标准化方法，默认为“LogNormalize”</span></span><br><span class="line"><span class="comment">## scale.factor  比例因子，用以计算标准化值，默认为“10000”</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> NormalizeData<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> normalization.method <span class="operator">=</span> <span class="string">&quot;LogNormalize&quot;</span><span class="punctuation">,</span> scale.factor <span class="operator">=</span> <span class="number">10000</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 鉴定mark基因（也就是特征基因）</span></span><br><span class="line"><span class="comment">## selection.method  mark基因筛选方法，“vst”为通过方差与均值比进行筛选</span></span><br><span class="line"><span class="comment">## nfeatures  要筛选的mark基因的数目</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> FindVariableFeatures<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> selection.method <span class="operator">=</span> <span class="string">&quot;vst&quot;</span><span class="punctuation">,</span> nfeatures <span class="operator">=</span> <span class="number">2000</span><span class="punctuation">)</span></span><br><span class="line">top10 <span class="operator">&lt;-</span> head<span class="punctuation">(</span>VariableFeatures<span class="punctuation">(</span>pbmc<span class="punctuation">)</span><span class="punctuation">,</span> <span class="number">10</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示mark基因</span></span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig03_10marker_genes.png&quot;</span><span class="punctuation">,</span>width<span class="operator">=</span><span class="number">1000</span><span class="punctuation">,</span>height<span class="operator">=</span><span class="number">400</span><span class="punctuation">)</span></span><br><span class="line">plot1 <span class="operator">&lt;-</span> VariableFeaturePlot<span class="punctuation">(</span>pbmc<span class="punctuation">)</span></span><br><span class="line">plot2 <span class="operator">&lt;-</span> LabelPoints<span class="punctuation">(</span>plot <span class="operator">=</span> plot1<span class="punctuation">,</span> points <span class="operator">=</span> top10<span class="punctuation">,</span> repel <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span></span><br><span class="line">CombinePlots<span class="punctuation">(</span>plots <span class="operator">=</span> <span class="built_in">list</span><span class="punctuation">(</span>plot1<span class="punctuation">,</span> plot2<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p>fig03_10marker_genes.png如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig03_10marker_genes.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig03_10marker_genes.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这里筛选出2000个mark基因用于后续的下游分析，并且展示区分能力最强的前10个mark基因</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mark基因权重标准化</span></span><br><span class="line"><span class="comment">## ScaleData 缩放基因的表达，给予基因同等的权重，使高表达基因不占据主导地位</span></span><br><span class="line">all.genes <span class="operator">&lt;-</span> rownames<span class="punctuation">(</span>pbmc<span class="punctuation">)</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> ScaleData<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> features <span class="operator">=</span> all.genes<span class="punctuation">)</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA主成分分析</span></span><br><span class="line"><span class="comment">## RunPCA 计算特征值，在细胞间具有高度表达差异的基因有助于区分不同类型的细胞</span></span><br><span class="line"><span class="comment">## 采用DimPlot方法可视化</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> RunPCA<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> features <span class="operator">=</span> VariableFeatures<span class="punctuation">(</span>object <span class="operator">=</span> pbmc<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig04_PCA.png&quot;</span><span class="punctuation">)</span></span><br><span class="line">DimPlot<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> reduction <span class="operator">=</span> <span class="string">&quot;pca&quot;</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p>fig04_PCA.png如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig04_PCA.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig04_PCA.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 评估主成分维度</span></span><br><span class="line"><span class="comment">## num.replicate  重采样次数</span></span><br><span class="line"><span class="comment">## dims  维度范围</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> JackStraw<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> num.replicate <span class="operator">=</span> <span class="number">100</span><span class="punctuation">)</span>  </span><br><span class="line">pbmc <span class="operator">&lt;-</span> ScoreJackStraw<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> dims <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">20</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">## 评估主成分维度的方法1</span></span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig05_PC_importance_01.png&quot;</span><span class="punctuation">,</span>width<span class="operator">=</span><span class="number">700</span><span class="punctuation">,</span>height<span class="operator">=</span><span class="number">400</span><span class="punctuation">)</span></span><br><span class="line">JackStrawPlot<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> dims <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">15</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment">## 评估主成分维度的方法2</span></span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig05_PC_importance_02.png&quot;</span><span class="punctuation">,</span>width<span class="operator">=</span><span class="number">700</span><span class="punctuation">,</span>height<span class="operator">=</span><span class="number">400</span><span class="punctuation">)</span></span><br><span class="line">ElbowPlot<span class="punctuation">(</span>pbmc<span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p>R包 Seurat 函数 <code>JackStraw</code> 、<code>ScoreJackStraw</code>进行重采样测试，评估用以进行细胞聚类的主成分维度。</p><p>fig05_PC_importance_01.png如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig05_PC_importance_01.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig05_PC_importance_01.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>fig05_PC_importance_02.png如下所示：</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig05_PC_importance_02.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig05_PC_importance_02.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上图是比较不同主成分（PC）的P值分布与均匀分布（虚线）；显著的主成分具有较低的P值（位于虚线上方）；似乎<strong>10-12</strong>个主成分后，主成分的重要性急剧下降。</p><p>下图是肘部法则以确定最佳主成分数量，9-10个主成分附近有个拐点，表明大部分真实信号是在前10个pc中捕获的。</p><p>所以这里选择<strong>10个主成分</strong>用于后续分析。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 细胞群体聚簇</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> FindNeighbors<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> dims <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">)</span> </span><br><span class="line">pbmc <span class="operator">&lt;-</span> FindClusters<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> resolution <span class="operator">=</span> <span class="number">0.5</span><span class="punctuation">)</span> </span><br><span class="line"><span class="comment">## 绘图</span></span><br><span class="line">pbmc <span class="operator">&lt;-</span> RunUMAP<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> dims <span class="operator">=</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">)</span> </span><br><span class="line">png<span class="punctuation">(</span><span class="string">&quot;fig06_cluster_UMAP.png&quot;</span><span class="punctuation">,</span>width<span class="operator">=</span><span class="number">700</span><span class="punctuation">,</span>height<span class="operator">=</span><span class="number">400</span><span class="punctuation">)</span> </span><br><span class="line">DimPlot<span class="punctuation">(</span>pbmc<span class="punctuation">,</span> reduction <span class="operator">=</span> <span class="string">&quot;umap&quot;</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p>fig06_cluster_UMAP.png如下所示</p><p><img src="https://www.shelven.com/tuchuang/20230613/fig06_cluster_UMAP.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230613/fig06_cluster_UMAP.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>可以看到，根据mark基因的表达，所有细胞最终被分为了8种类型。</p><p>做完以上分析之后，还可以根据自己的研究目标新型不同的下游分析，具体来说可以筛选亚群的标记基因（与其他类别细胞的差异表达基因）、进行细胞的发育轨迹分析、做不同品种间细胞类型的比较等等。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近因为学校网络信息中心升级防火墙，导致集群无法访问公网，我搭建的反向代理服务器也暂时无法使用（真的想吐槽学校的网络管理员，三个星期了还没能解决集群的网络问题）……近期要进行中期答辩，先用向日葵远程一下实验室闲置的电脑应急，顺便把最近的学习笔记补上。&lt;/p&gt;
&lt;p&gt;这篇笔记主要记录下单细胞组学的学习，以及单细胞转录组（Single-cell RNA-sequencing，scRNA-seq）的分析流程。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="单细胞转录组" scheme="http://www.shelven.com/categories/%E5%8D%95%E7%BB%86%E8%83%9E%E8%BD%AC%E5%BD%95%E7%BB%84/"/>
    
    
    <category term="Seurat" scheme="http://www.shelven.com/tags/Seurat/"/>
    
  </entry>
  
  <entry>
    <title>基因组共线性分析——MCScanX</title>
    <link href="http://www.shelven.com/2023/04/20/a.html"/>
    <id>http://www.shelven.com/2023/04/20/a.html</id>
    <published>2023-04-20T15:55:19.000Z</published>
    <updated>2023-05-08T13:55:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>因为自己的生信基础知识比较薄弱，最近在华农跟着王老师上了一些植物基因组课程，记录一下。这一次主要结合课堂内容、MCScanX官方文档以及自己的理解，演示基因组共线性工具MCScanX的用法。</p><span id="more"></span><h2 id="1-共线性分析"><a href="#1-共线性分析" class="headerlink" title="1. 共线性分析"></a>1. 共线性分析</h2><div class="story post-story"><p>在樊龙江主编的《植物基因组学》中提到，植物起源于水生藻类，不同植物在基因水平上具有一定保守性（也就是具有一定的相同基因）。在一定的亲缘关系内，这种基因组水平上的保守性（基因组区块排列顺序保守性），也就是不同植物基因组间的共线性。</p><p>当我们拿到两个植物基因组数据，想要分析两个物种间是否存在基因进化历史、染色体结构变异、重要功能基因的插入缺失或者鉴定全基因组复制事件的时候，就可以利用一些基因组共线性分析工具进行直观的作图和分析。</p><p>做共线性分析之前需要区分两个描述基因组共线性的名词：</p><ul><li><p>Synteny：两个物种的一组基因位点，在每个物种中位于同一条<strong>染色体</strong>（顺序不一定相同）。</p><p><img src="https://www.shelven.com/tuchuang/20230420/1.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>Collinearity：两个物种的一组基因位点，分别位于各自的同一条<strong>染色体</strong>上，并且顺序也是一致的。</p><p><img src="https://www.shelven.com/tuchuang/20230420/2.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ul><p>这里染色体打了个重点，因为所有的共线性分析都是基于染色体水平的基因组进行比较的，只有contig数据分析的话意义不大。现在的共线性研究以及开发的工具一般用的是collinearity（包括后面要说的MCScanx）。</p><p><strong>共线性分析的原理主要都是分为三步：</strong></p><ol><li>获得基因在染色体上的位置（如基因组注释得到的gff文件）。</li><li>将基因的CDS&#x2F;蛋白序列进行比对，得到高度相似的基因对（Anchoring）。</li><li>鉴定相同基因排列顺序的共线性区块（Chaining），不同软件算法不一样，这里不讨论算法只讨论如何应用。</li></ol><p>其他就不过多介绍了，接下来主要讲讲MCScanX软件的用法。</p></div><h2 id="2-下载和编译MCScanX"><a href="#2-下载和编译MCScanX" class="headerlink" title="2. 下载和编译MCScanX"></a>2. 下载和编译MCScanX</h2><div class="story post-story"><p>按照官网克隆仓库，编译即可。<a href="https://github.com/wyp1125/MCScanX">MCScanX github官网</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/wyp1125/MCScanX.git</span><br><span class="line">cd MCScanX</span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>编译之后可以看到主文件的<code>MCScanX</code>、<code>MCScanX_h</code>和<code>Duplicate_gene_classifier</code>三个核心分析程序，以及<strong>downstream_analyses</strong>下游分析文件夹中的12个与下游分析有关的java和perl文件。</p></div><h2 id="3-运行MCScanX"><a href="#3-运行MCScanX" class="headerlink" title="3. 运行MCScanX"></a>3. 运行MCScanX</h2><div class="story post-story"><h3 id="3-1-数据预处理"><a href="#3-1-数据预处理" class="headerlink" title="3.1 数据预处理"></a>3.1 数据预处理</h3><p>MCScan支持的输入文件有两个：</p><ul><li>m8输出格式的BLASTP比对结果文件</li><li>记录染色体、基因名称以及起始和终止位点4个信息的gff文件</li></ul><p>这里以棉花基因组和近缘物种可可基因组为例，两者都可以在NCBI上找到蛋白序列和注释的gff3文件。由于上机课中给的蛋白序列和gff文件都是处理好的，如果自己处理gff文件，总体思路是从gff文件的第3列提取’gene’关键词，从第9列分离基因名称信息，保留第1列染色体信息，保留第4列和第5列保留start和end信息即可。</p><p>这里输入的gff文件不是标准格式，简单写个python脚本处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">&#x27;./Theobroma_cacao.chr.gff3&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    temp = pd.read_csv(file, sep = <span class="string">&#x27;\t&#x27;</span>,comment = <span class="string">&#x27;#&#x27;</span>, header = <span class="literal">None</span>)     <span class="comment"># 制表符分隔，#号为注释标识，无列名</span></span><br><span class="line">    temp = temp.drop(temp[temp[<span class="number">2</span>] != <span class="string">&#x27;gene&#x27;</span>].index)     <span class="comment"># 第3列不为gene的行的索引，drop()删除</span></span><br><span class="line">    temp = temp[[<span class="number">0</span>,<span class="number">8</span>,<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">    temp[<span class="number">8</span>] = temp[<span class="number">8</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;;&#x27;</span>)[<span class="number">0</span>].split(<span class="string">&#x27;=&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">1</span>])    <span class="comment"># 对第9列的处理，只取geneid</span></span><br><span class="line">    temp.to_csv(<span class="string">&#x27;Tcacao.gff3&#x27;</span>, header = <span class="literal">None</span>, index = <span class="literal">None</span>, sep = <span class="string">&#x27;\t&#x27;</span>)</span><br></pre></td></tr></table></figure><p>当然，根据官网的表述，最好将染色体名称改为<code>两个字母（物种缩写） + 数字（代表染色体编号）</code>的形式。不改也没关系，两个基因组的染色体名字不要一样就好了，不改的话只有在下游分析对共线性区块分组的时候有点影响（添加的物种那列只显示两个字母）<del>实质上不会有什么影响</del>。</p><p><strong>这步检查一下gene数量与pep文件的蛋白质条数是否一样</strong>，不一样的话可能是pep中有转录本蛋白序列，重新筛选完整的gff3文件，再用gffread提取蛋白序列，这里就不赘述了，如果处理有问题后续在更新。</p><p>本例中，棉花<em>Gossypium herbaceum</em>相关文件前缀为<strong>Gh</strong>；可可<em>Theobroma cacao</em>相关文件前缀为<strong>Tcacao</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并蛋白序列（方便做基因组组内和组间共线性分析）</span></span><br><span class="line">cat Gh.pep Tcacao.pep &gt; Gh_Tcacao.pep</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">blast建库</span></span><br><span class="line">makeblastdb -in /public/home/wlxie/biosoft/MCScanX/Data/ExerciseData/Gh_Tcacao.pep -dbtype prot -input_type fasta -out Gh_Tcacao</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">蛋白序列拆分40份（方便提交并行任务到集群）</span></span><br><span class="line">perl fasta-splitter.pl --n-parts 40 Gh_Tcacao.pep</span><br><span class="line">mkdir Gh_Tcacao</span><br><span class="line">mv Gh_Tcacao.part* Gh_Tcacao</span><br></pre></td></tr></table></figure><p>用到的蛋白序列拆分perl脚本来自于<a href="https://github.com/KirillKryukov">Kirill Kryukov</a>，具体在哪个仓库找不到了……这里<a href="https://www.shelven.com/tuchuang/20230420/fasta-splitter.pl">提供下载</a>，拆分后文件夹名称如下：</p><p><img src="https://www.shelven.com/tuchuang/20230420/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上面拆分的40个蛋白序列名称数字部分是等宽的，不方便提交并行任务到集群，这里简单修改下文件名称。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取目录下所有文件列表</span></span><br><span class="line">path = <span class="string">&#x27;/public/home/wlxie/biosoft/MCScanX/Data/ExerciseData/Gh_Tcacao/&#x27;</span></span><br><span class="line">fileList = os.listdir(path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置待修改的前缀和后缀</span></span><br><span class="line">prefix = <span class="string">&#x27;Gh_Tcacao_&#x27;</span></span><br><span class="line">suffix = <span class="string">&#x27;.pep&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量修改文件名</span></span><br><span class="line">m = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> fileList:</span><br><span class="line">    old_path = path + os.sep + file</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(old_path):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    new_path = path + os.sep + prefix + <span class="built_in">str</span>(m) + suffix</span><br><span class="line">    os.rename(old_path, new_path)</span><br><span class="line">    m += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>修改之后提交40个blastp并行任务，每个任务4核，很快就可以跑完。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --array=1-40</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --cpus-per-task=4</span></span><br><span class="line"></span><br><span class="line">echo start on  $(date)</span><br><span class="line">srun blastp -query Gh_Tcacao$&#123;SLURM_ARRAY_TASK_ID&#125;.pep -out Gh_Tcacao_$&#123;SLURM_ARRAY_TASK_ID&#125;.blast -db Gh_Tcacao -outfmt 6 -num_threads 4 -num_alignments 5 -evalue 1e-10</span><br><span class="line">echo end on $(date)</span><br></pre></td></tr></table></figure><p>最后合并blastp结果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat Gh_Tcacao_*.blast &gt; Gh_Tcacao.blast</span><br><span class="line">rm Gh_Tcacao_*.blast</span><br></pre></td></tr></table></figure><h3 id="3-2-运行MCScanX和结果解读"><a href="#3-2-运行MCScanX和结果解读" class="headerlink" title="3.2 运行MCScanX和结果解读"></a>3.2 运行MCScanX和结果解读</h3><p>MCScanX有三个主命令：</p><ol><li>MCScanX共线性分析</li><li>MCScanX_h也是共线性分析，输入不是BLASTP文件，而是第三方检测的以制表符分隔的成对同源关系文件</li><li>Duplicate_gene_classifier使用MCScanX的算法鉴定singleton（单基因）和重复基因</li></ol><p>这里用MCScanX，前面处理好了的blastp结果文件和gff文件放在同一个文件夹，输入的文件相对路径要到文件名的前缀部分</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./MCScanX Data/ExerciseData/Gh_Tcacao</span><br></pre></td></tr></table></figure><p>结果文件如下：</p><p><img src="https://www.shelven.com/tuchuang/20230420/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><code>.collinearity</code> 是两个基因组共线性结果文件（默认分析collinearity），包含了本次运行的参数、计算出的共线性区块等。还可以根据这个文件用<code>grep</code>的方法提取两个物种之间的同源基因（提取第二列第三列物种名字不一样的行，去重复，计数），这里也不赘述了。</p><p><img src="https://www.shelven.com/tuchuang/20230420/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><code>.html</code> 这个文件夹每个文件对应一条染色体共线性分析结果，包括基因座的共线性区块数量、基因名称（串联重复基因会标红）和具体比对上哪些共线性区块：</p><p><img src="https://www.shelven.com/tuchuang/20230420/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><code>.tandem</code>文件显示基因组内所有串联重复基因对：</p><p><img src="https://www.shelven.com/tuchuang/20230420/7.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/7.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="3-3-下游分析和作图"><a href="#3-3-下游分析和作图" class="headerlink" title="3.3 下游分析和作图"></a>3.3 下游分析和作图</h3><p>官方在<code>downstream_analyses</code>文件夹中提供了12个下游分析的perl和java脚本。我个人将这个文件下的分析工具分为两类：</p><ol><li>功能相关（此部分与数据处理相关）</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Detect_syntenic_tandem_arrays 检测串联重复基因</span></span><br><span class="line">../../../downstream_analyses/detect_collinear_tandem_arrays -g Gh_Tcacao.gff -b Gh_Tcacao.blast -c Gh_Tcacao.collinearity -o tandem_arrays</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Dissect_multiple_alignment 将共线性区块分为物种内和物种间共线性区块</span></span><br><span class="line">../../../downstream_analyses/dissect_multiple_alignment -g Gh_Tcacao.gff -c Gh_Tcacao.collinearity -o dissect_multiple_alignment</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">add_ka_and_ks_to_collinearity.pl 计算ka和ks值（在collinearity结果后面增加两列，执行时间较长）</span></span><br><span class="line">cat Gh.cds Tcacao.cds &gt; Gh_Tcacao.cds# 需要cds序列，且与collinearity文件中的序列名要一致，否则算出来全部都是-2</span><br><span class="line">perl ../../../downstream_analyses/add_ka_and_ks_to_collinearity.pl -i Gh_Tcacao.collinearity -d Gh_Tcacao.cds -o add_kaks_to_synteny</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">group_collinear_genes.pl 基因分组，构建基因家族（结果文件需要去掉第一行无效信息）</span></span><br><span class="line">perl ../../../downstream_analyses/group_collinear_genes.pl -i Gh_Tcacao.collinearity -o group_collinear_genes</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以及以下几种功能就不一一试了</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">detect_collinearity_within_gene_families.pl检测基因家族的共线性基因对，需要用到前面构建的基因家族文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">origin_enrichment_analysis.pl根据Duplicate_gene_classifier的结果识别输入基因家族的重复基因起源的潜在富集？不太懂什么意思</span></span><br></pre></td></tr></table></figure><ol start="2"><li>作图相关（此部分均有对应的配置文件，在downstream_analyses文件夹操作，其他文件路径java会发生未知错误）</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dot_plotter 两组染色体所有共线性区块做点图</span></span><br><span class="line">java dot_plotter -g ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.gff -s ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.collinearity -c dot.ctl -o dot.png</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dot.ctl配置文件内容如下</span></span><br><span class="line">800//x轴维度（像素大小，下同，不再赘述）</span><br><span class="line">800//y轴维度</span><br><span class="line">Ghir_A01,Ghir_A02,Ghir_A03,Ghir_A04,Ghir_A05,Ghir_A06,Ghir_A07,Ghir_A08,Ghir_A09,Ghir_A10,Ghir_A11,Ghir_A12,Ghir_A13//x轴染色体名称</span><br><span class="line">Chromosome_1,Chromosome_2,Chromosome_3,Chromosome_4,Chromosome_5,Chromosome_6,Chromosome_7,Chromosome_8,Chromosome_9//y轴染色体名称</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230420/dot.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/dot.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dual_synteny_plotter</span></span><br><span class="line">java dual_synteny_plotter -g ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.gff -s ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.collinearity -c dual_synteny.ctl -o dual_synteny.png</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dual_synteny.ctl</span></span><br><span class="line">600//图宽</span><br><span class="line">800//图高</span><br><span class="line">Ghir_A01,Ghir_A02,Ghir_A03,Ghir_A04,Ghir_A05,Ghir_A06,Ghir_A07,Ghir_A08,Ghir_A09,Ghir_A10,Ghir_A11,Ghir_A12,Ghir_A13//位于左边的染色体名称</span><br><span class="line">Chromosome_1,Chromosome_2,Chromosome_3,Chromosome_4,Chromosome_5,Chromosome_6,Chromosome_7,Chromosome_8,Chromosome_9//位于右边的染色体名称</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230420/dual_synteny.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/dual_synteny.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">circle_plotter</span></span><br><span class="line">java circle_plotter -g ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.gff -s ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.collinearity -c circle.ctl -o circle.png</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">circle.ctl</span></span><br><span class="line">800//图宽和高</span><br><span class="line">Ghir_A01,Ghir_A02,Ghir_A03,Ghir_A04,Ghir_A05,Ghir_A06,Ghir_A07,Ghir_A08,Ghir_A09,Ghir_A10,Ghir_A11,Ghir_A12,Ghir_A13,Chromosome_1,Chromosome_2,Chromosome_3,Chromosome_4,Chromosome_5,Chromosome_6,Chromosome_7,Chromosome_8,Chromosome_9//环状图的染色体名称</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230420/circle.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/circle.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">bar_plotter</span></span><br><span class="line">java bar_plotter -g ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.gff -s ../Data/ExerciseData/Gh_Tcacao/Gh_Tcacao.collinearity -c bar.ctl -o bar.png</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">bar.ctl</span></span><br><span class="line">800//x轴维度</span><br><span class="line">800//y轴维度</span><br><span class="line">Ghir_A01,Ghir_A02,Ghir_A03,Ghir_A04,Ghir_A05,Ghir_A06,Ghir_A07,Ghir_A08,Ghir_A09,Ghir_A10,Ghir_A11,Ghir_A12,Ghir_A13//参考染色体</span><br><span class="line">Chromosome_1,Chromosome_2,Chromosome_3,Chromosome_4,Chromosome_5,Chromosome_6,Chromosome_7,Chromosome_8,Chromosome_9//目标染色体</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230420/bar.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230420/bar.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">还有两个作图的工具也不一一试了，以后有需要再做</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">family_circle_plotter基因家族同源基因圆形图，红线连接一个基因家族所有同源基因</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">family_tree_plotter基因家族树，共线性基因对用红线连接，串联重复基因用蓝线连接</span></span><br></pre></td></tr></table></figure><p>可以看到这个软件绘图还是非常简单方便的，不过图片质量不是很好，作图的像素点大小都是由自己定义的，因此排版缩放也很容易失真。还是比较推荐JCVI一类的软件，引入多种过滤参数功能更强大，且做的图是矢量图，比较好看……而且有docker镜像，不怕安装依赖的问题：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">singularity -d build jcvi.sif docker://tanghaibao/jcvi</span><br></pre></td></tr></table></figure><p>以后有空再更新吧~</p></div><h2 id="2023-5-8-更新"><a href="#2023-5-8-更新" class="headerlink" title="2023.5.8 更新"></a>2023.5.8 更新</h2><div class="story post-story"><p>上面例子仅仅只是作图，没有阐明具体的生物学问题。这里通过以上的数据补充几个思考：</p><ul><li><ol><li>棉花和可可的WGD（全基因组加倍）事件分别在多少年前？</li></ol></li><li><ol start="2"><li>在多少年前棉花和可可发生了物种分化？</li></ol></li></ul><p>在解决上面两个问题前，需要知道一个基本概念——<strong>中性进化论</strong>。</p><p>在中性进化理论中，分子水平的变异是中性的，不受自然选择的影响。也就是说对于一个基因序列而言，每个位点上的演化（也就是发生突变）速率都是恒定的，如果一个基因位点发生同义突变，氨基酸序列并未发生变化，则这种突变不会影响物种的适应性。</p><p>同义突变率ds（Ks）指平均每个同义位点上发生同义置换的数目，在物种进化中代表了进化过程的背景碱基替换率，两个物种或者同个物种之间的Ks值可以通过上面的MCScanX的下游分析程序<code>add_ka_and_ks_to_collinearity.pl</code>计算得出。</p><p>如果一个物种发生了全基因组加倍事件，则会产生大量的旁系同源基因，反映在Ks值上就是有大量的Ks值接近的同源基因对产生，在Ks统计图中会出现一个峰（peak）；如果两个物种之间发生了物种分化，同样产生大量的直系同源基因（物种形成的伴随事件），同样是Ks值接近的同源基因产生，并且在Ks统计图出现峰值。因此，我们可以根据同一个物种内以及不同物种间的同源基因Ks值来反推物种的WGD事件和物种分歧事件，<strong>Ks峰值处发生的事件即为最近一次的物种WGD事件或物种分歧事件</strong>。</p><p>这些事件发生的时间点，如果有已知的化石证据则最准确（根据放射性同位素衰变），如果没有就需要根据分子钟理论计算对应的时间，我们用最基础的公式<code>T=Ks/2r</code>。Ks，即同义突变率，平均每个位点的突变次数；r是核酸突变速度，也就是这个分类的物种每个位点每年的突变概率。</p><p>解释一下这个公式怎么来的，在两个物种分化一定的时间T后，两者都以相似的速度r累积突变（分化后是近缘物种，核酸突变速度类似），则两个物种之间核酸替换率<code>K=T*（r+r）</code>。实际上为了避免进化选择对突变速率的影响，这里一般用同义突变率替代核酸替换率。r值是怎么计算的呢？同样要依赖化石证据，根据两个物种共同祖先的化石时间反推r值，假设同一类物种核酸突变率类似，则这个r值还可以进一步用于别的近缘物种。</p><p><strong>以上理论依据建立在同一类物种核酸突变率类似的假设中</strong>，实际不一定如我们所愿，且化石依据也会存在一定误差。这个r值也只是估计个大概，实际上只要在10的-9次方数量级，算出来的时间能自圆其说就行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用MCScanX计算物种内部的共线性结果</span></span><br><span class="line">./MCScanX -b 1 Data/ExerciseData/Gh_Tcacao_1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用MCScanX计算两个物种之间的共线性结果</span></span><br><span class="line">./MCScanX -b 2 Data/ExerciseData/Gh_Tcacao_2</span><br></pre></td></tr></table></figure><p>分别整理棉花与棉花、可可与可可、棉花与可可的基因组共线性结果，只选取最后一列ks值，用R做Ks密度分布图，可以参考现有的教程：</p><p><a href="https://www.jianshu.com/p/a494fa940f06">Ks密度曲线分布图绘图 - 简书 (jianshu.com)</a></p><p><a href="http://ianmadd.github.io/pages/PeakDensityDistribution.html">Finding Peak Values For a Density Distribution (ianmadd.github.io)</a></p><p>找到Ks密度分布图的峰值，选一个参考文献里合适的r值，就可以计算上面两个问题了。</p><p>顺便补充一下，下面这篇教程里有一个python脚本可以提取最长转录本，因为原作者给的是图片懒得敲下来试了，看了下代码逻辑是处理pep文件，根据序列名比较同一个基因的不同转录本长度，选取最长的那个。逻辑没有问题，因为不是刚需，有需要自己再去复现，就不重复造轮子了。</p><p><a href="https://www.jianshu.com/p/9d28de3d18e6?ivk_sa=1024320u">WGD（全基因组复制）分析——Ka&#x2F;Ks及4Dtv值计算 - 简书 (jianshu.com)</a></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;因为自己的生信基础知识比较薄弱，最近在华农跟着王老师上了一些植物基因组课程，记录一下。这一次主要结合课堂内容、MCScanX官方文档以及自己的理解，演示基因组共线性工具MCScanX的用法。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="比较基因组学" scheme="http://www.shelven.com/categories/%E6%AF%94%E8%BE%83%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
    
    
    <category term="MCScanX" scheme="http://www.shelven.com/tags/MCScanX/"/>
    
    <category term="共线性分析" scheme="http://www.shelven.com/tags/%E5%85%B1%E7%BA%BF%E6%80%A7%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>基因组注释（5）——预测基因筛选</title>
    <link href="http://www.shelven.com/2023/04/11/a.html"/>
    <id>http://www.shelven.com/2023/04/11/a.html</id>
    <published>2023-04-11T14:58:20.000Z</published>
    <updated>2023-04-17T11:41:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>注释得到的基因集中，可能某些基因存在被转座子插入的情况，该基因会在后续功能注释的时候被注释上，但实际在基因组中该基因可能已经被插入失活。因此在基因组的功能注释前，需要用检测转座子软件（如TransposonPSI、TEsorter等）将含有转座子的基因找出并去除。</p><span id="more"></span><p>这里记录下<code>TEsorter</code>软件筛选预测基因的方法。</p><h2 id="1-TEsorter安装"><a href="#1-TEsorter安装" class="headerlink" title="1. TEsorter安装"></a>1. TEsorter安装</h2><div class="story post-story"><p><a href="https://github.com/zhangrengang/TEsorter">TEsorter</a>原本是用于调用<a href="https://github.com/oushujun/LTR_retriever">LTR_retriever</a>鉴别长末端重复序列反转座子（LTR-RTs），也可以用于其他类型TE的鉴别，其鉴定原理为将待测序列与数据库<a href="http://repeatexplorer.org/?page_id=918">REXdb</a>（整合viridiplantae_v3.0 + metazoa_v3）的TE序列进行比对。</p><p>也可以使用<a href="http://gydb.org/">GyDB</a>数据库进行比对，官网上有具体的参数用法。</p><p><a href="https://github.com/zhangrengang/TEsorter">zhangrengang&#x2F;TEsorter: TEsorter: an accurate and fast method to classify LTR-retrotransposons in plant genomes (github.com)</a></p><p><code>TEsorter</code>提供conda安装，但是我没有安装成功，这里还是新建conda环境后手动安装各种依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &quot;TEs&quot;</span><br><span class="line">conda activate TEs</span><br><span class="line"></span><br><span class="line">conda install python==3.11# 官方要求python版本高于3，否则运行会报错</span><br><span class="line">conda install biopython</span><br><span class="line">conda install xopen</span><br><span class="line">conda install hmmer</span><br><span class="line">conda install blast</span><br><span class="line"></span><br><span class="line">git clone https://ghproxy.com/https://github.com/zhangrengang/TEsorter.git# 从github镜像网站下载</span><br><span class="line">cd TEsorter</span><br><span class="line">python setup.py install</span><br><span class="line"></span><br><span class="line">TEsorter TEsorter/test/rice6.9.5.liban# 测试</span><br></pre></td></tr></table></figure></div><h2 id="2-TEsorter运行"><a href="#2-TEsorter运行" class="headerlink" title="2. TEsorter运行"></a>2. TEsorter运行</h2><div class="story post-story"><p>这里有一个问题，Braker预测基因有<code>gtf</code>和<code>gff3</code>两种格式的输出结果，<strong>但是两者的行数不一样</strong>。<code>braker.aa</code>蛋白序列和<code>braker.codingseq</code>基因序列的条数与<code>gtf</code>文件中的<code>transcript</code>条数一致，但是比<code>gff3</code>文件中的<code>mRNA</code>条数多（按理来说两者应该是一致的）。</p><p>后来发现Braker加入<code>--gff3</code>参数生成的<code>gff3文件mRNA数量 + gtf文件的mRNA数量 = gtf文件的transcript数量</code>，不理解为什么有这种关系，方便起见我这里处理了<code>gtf</code>结果文件。</p><p>TEsorter软件可以输入<strong>基因序列</strong>或者<strong>蛋白序列</strong>，以基因序列为例，简单编写脚本如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 8</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">TEsorter /public/home/wlxie/baima_pre_mydb/braker.codingseq -eval 1e-6 -p 8</span><br></pre></td></tr></table></figure><p>大约十几分钟运行完毕。</p></div><h2 id="3-结果文件处理"><a href="#3-结果文件处理" class="headerlink" title="3. 结果文件处理"></a>3. 结果文件处理</h2><div class="story post-story"><p>结果文件如下：</p><p><img src="https://www.shelven.com/tuchuang/20230411/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230411/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><code>.tsv</code>后缀的文件中以列表形式列出了所有预测的TE类型，一个基因可能有多种类型的TE插入，因此需要处理结果文件，统计含有TE的基因，并在<code>gtf</code>结果文件中将该基因去除。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">筛选含有TE的基因</span></span><br><span class="line">grep -v &quot;^#&quot; braker.codingseq.rexdb.cls.tsv | cut -f1 | sort | uniq | cut -f1 -d &quot;_&quot; | sort | uniq &gt; TE-genes.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除含有TE的基因序列</span></span><br><span class="line">grep -Fvf /public/home/wlxie/biosoft/TEsorter/baima_mydb/TE-genes.txt braker.gtf | awk &#x27;$3 ~ /gene/&#x27; &gt; baima_gene_only.gtf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除含有TE的转录本序列</span></span><br><span class="line">grep -Fvf /public/home/wlxie/biosoft/TEsorter/baima_mydb/TE-genes.txt braker.gtf | awk &#x27;$3 ~ /transcript/&#x27; &gt; baima_transcript.gtf </span><br></pre></td></tr></table></figure><p>可以看看去除TE序列后的转录本和基因数量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(base) wlxie 17:03:52 ~/baima_pre_mydb</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> baima_transcript.gtf | <span class="built_in">wc</span> -l</span></span><br><span class="line">23716</span><br><span class="line">(base) wlxie 17:04:05 ~/baima_pre_mydb</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> baima_gene_only.gtf | <span class="built_in">wc</span> -l</span></span><br><span class="line">20742</span><br></pre></td></tr></table></figure><p>本想通过<code>gffread</code>软件根据处理后的gtf文件重新提取基因组的蛋白序列，但是运行过程中总是报错<code>no genomic sequence available</code>，原因暂时未知（可能是因为braker预测结果braker.gtf不是标准的gtf文件格式，同样用gffread做gtf2gff转换的时候会有部分信息丢失）。</p><p>可以直接写一个脚本处理<code>braker.aa</code>文件，根据前面筛选的<code>TE-genes.txt</code>文件，去除含有TE的蛋白序列，这里后续用到再做更新。</p></div><h2 id="2023-4-13-更新"><a href="#2023-4-13-更新" class="headerlink" title="2023.4.13 更新"></a>2023.4.13 更新</h2><div class="story post-story"><p><code>gffread</code>报错的原因找到了：</p><blockquote><ul><li>基因组文件的序列编号有空格</li><li>gtf文件缺少必要的位置信息</li></ul></blockquote><p>主要还是跑braker过程的疏忽和对gtf以及gff3数据格式的不了解。</p><p><img src="https://www.shelven.com/tuchuang/20230411/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230411/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>在<code>braker.log</code>日志文件中有提示，基因组的fasta文件的header中包含了空格，可能会导致后续的错误，<strong>因此braker运行时自动将空格替换为了下划线“_”</strong>，这就导致了预测后的gtf文件与基因组文件无法匹配上，自然就报错<code>no genomic sequence available</code>。</p><blockquote><p><strong>解决方法：</strong></p><p>手动将基因组文件中的header部分的空格用下划线“_”代替（我的基因组是59条contig，也就是手动改59个空格），并删除原<code>fai</code>索引文件（一定要删除，否则仍然无法找到基因序列）。</p></blockquote><p>用<code>gffread</code>软件做gtf和gff3格式相互转换的时候，确实会损失一部分信息，但仍然会保留最基本的CDS信息。如果直接从gtf文件的第三列提取<code>gene</code>和<code>transcript</code>信息保存成新的gtf文件，<strong>这个新的gtf文件是无法用gffread定位和提取蛋白序列的。</strong></p><p>这一点在<a href="http://mblab.wustl.edu/GTF22.html#fields">GTF官方文档</a>对第三列的&lt;feature&gt;解释中有提到：</p><blockquote><p><strong>&lt;feature&gt;</strong><br>The following feature types are required: “CDS”, “start_codon”, “stop_codon”. The features “5UTR”, “3UTR”, “inter”, “inter_CNS”, “intron_CNS” and “exon” are optional. All other features will be ignored. The types must have the correct capitalization shown here.</p><p>也就是说我如果从第三列只提取gene或者transcript，这些feature是会被忽略的，使用gffread提取蛋白序列会提示这是一个非法的GTF文件。</p></blockquote><p>因此，正确的筛选方式和提取蛋白的方式应该为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">筛选含有TE的基因</span></span><br><span class="line">grep -v &quot;^#&quot; braker.codingseq.rexdb.cls.tsv | cut -f1 | sort | uniq | cut -f1 -d &quot;_&quot; | sort | uniq &gt; TE-genes.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除含有TE的序列</span></span><br><span class="line">grep -Fvf /public/home/wlxie/biosoft/TEsorter/baima_mydb/TE-genes.txt braker.gtf &gt; baima_rmTE.gtf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从基因组重新提取去除了TE的蛋白序列</span></span><br><span class="line">gffread baima_rmTE.gtf -g /public/home/wlxie/biosoft/db_data/baima/RepeatMasker_soft/genome.nextpolish.fasta.masked -y pep_rmTE.fa</span><br></pre></td></tr></table></figure></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;注释得到的基因集中，可能某些基因存在被转座子插入的情况，该基因会在后续功能注释的时候被注释上，但实际在基因组中该基因可能已经被插入失活。因此在基因组的功能注释前，需要用检测转座子软件（如TransposonPSI、TEsorter等）将含有转座子的基因找出并去除。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="TEsorter" scheme="http://www.shelven.com/tags/TEsorter/"/>
    
  </entry>
  
  <entry>
    <title>基因组注释（4）——基因预测</title>
    <link href="http://www.shelven.com/2023/04/03/a.html"/>
    <id>http://www.shelven.com/2023/04/03/a.html</id>
    <published>2023-04-03T14:09:26.000Z</published>
    <updated>2023-04-08T02:38:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>在对基因组重复序列和ncRNA进行注释后，接下来是基因预测和功能注释，这也是寻找功能基因的基础和前提。这里主要记录下怎么用Braker3进行基因组的基因预测（也就是结构注释）。</p><span id="more"></span><p>基因预测的方法主要有三种：</p><ul><li>基于隐马尔可夫模型的自训练和迭代，获得从头预测的基因结构模型（软件Augustus、GeneMark-ES等）</li><li>基于已发表的近缘物种基因序列、蛋白序列的同源预测（软件DIAMOND、GeMoMa等）</li><li>基于本物种的RNA-Seq转录组数据，比对基因组内含子结构模型和基因侧翼序列信息（软件Hisat2、STAR等）</li></ul><p>一般的流程是将以上三种基因预测结果通过软件EvidenceModeler（EVM）进行整合，最终得到预测结果gff文件。网上对于上面的流程有很多教程，针对不同软件有不同的设置，比如知乎的这篇文章<a href="https://zhuanlan.zhihu.com/p/379464361">使用AUGSTUS + Geneid + GeneMark + GeMoMa + GenomeThreader + Exonerate 进行基因结构预测 - 知乎 (zhihu.com)</a></p><p>为了简化流程，现在也有越来越多的基因预测pipeline工具得以开发，比较有名的就是<a href="https://github.com/Gaius-Augustus/BRAKER">Braker</a>和<a href="https://www.yandell-lab.org/software/maker.html">Maker</a>，感兴趣的话可以做两者预测结果的比较，我这里就用发表时间比较近的Braker3为例。</p><p>Braker本质上是一个结合了多种基因组注释工具的perl程序，其核心为braker.pl文件。</p><h2 id="1-安装Braker3"><a href="#1-安装Braker3" class="headerlink" title="1. 安装Braker3"></a>1. 安装Braker3</h2><div class="story post-story"><p>目前为止（2023年4月3日）Braker的最新版本为3.0.2，conda上能搜到的最新版本只有2.1.6，<strong>因此不建议用conda安装</strong>，尤其是最新的版本Braker可以直接使用RNA-seq和蛋白数据，整合GeneMark-ETP和AUGUSTUS训练和预测基因，对于预测结果有较高的支持度。</p><p>因为整个pipeline包含了十几个注释用的软件，用到的perl模块也非常多（数了一下配置环境需要安装20个perl模块），还是推荐用给官方给的**<a href="https://hub.docker.com/r/teambraker/braker3">container</a>**。</p><h3 id="1-1-申请和下载GeneMark-ETP密钥"><a href="#1-1-申请和下载GeneMark-ETP密钥" class="headerlink" title="1.1 申请和下载GeneMark-ETP密钥"></a>1.1 申请和下载GeneMark-ETP密钥</h3><p>在Braker3中使用RNA-seq数据和蛋白数据预测基因，都要用到GeneMark-ETP这个软件。但是这个软件不能直接用，需要到<a href="http://topaz.gatech.edu/genemark/license_download.cgi">GeneMark网站</a>申请和下载对应的密钥文件放在集群用户的家目录中。</p><img src="https://www.shelven.com/tuchuang/20230403/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><img src="https://www.shelven.com/tuchuang/20230403/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>申请完成之后获得名称为<code>gm_key_64.gz</code>的密钥文件，解压之后命名为<code>.gm_key</code>（注意点号）并上传到集群用户的家目录下即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gunzip gm_key_64.gz</span><br><span class="line">mv gm_key_64 .gm_key</span><br></pre></td></tr></table></figure><h3 id="1-2-创建Braker3镜像"><a href="#1-2-创建Braker3镜像" class="headerlink" title="1.2 创建Braker3镜像"></a>1.2 创建Braker3镜像</h3><p>这一步在dockerhub网站的Braker3仓库中有详细说明，我这里选择创建singularity镜像：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">singularity build braker3.sif docker://teambraker/braker3:latest</span><br></pre></td></tr></table></figure><p>得到的<code>braker3.sif</code>就是Braker3的singularity image</p><p>创建braker3镜像文件的环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export BRAKER_SIF=/your/path/to/braker3.sif</span><br></pre></td></tr></table></figure><p>可以复制三个示例脚本到当前目录：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">singularity exec -B $PWD:$PWD braker3.sif cp /opt/BRAKER/example/singularity-tests/test1.sh .</span><br><span class="line">singularity exec -B $PWD:$PWD braker3.sif cp /opt/BRAKER/example/singularity-tests/test2.sh .</span><br><span class="line">singularity exec -B $PWD:$PWD braker3.sif cp /opt/BRAKER/example/singularity-tests/test3.sh .</span><br></pre></td></tr></table></figure><p>在本地申请计算资源并跑一下三个示例脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">salloc -n 50# 申请50个核跑test.sh，注意不要在登录节点直接运行计算程序</span><br><span class="line">bash test1.sh # tests BRAKER1</span><br><span class="line">bash test2.sh # tests BRAKER2</span><br><span class="line">bash test3.sh # tests BRAKER3</span><br><span class="line">exit# 退出并释放计算资源</span><br></pre></td></tr></table></figure></div><h2 id="2-运行Braker3"><a href="#2-运行Braker3" class="headerlink" title="2. 运行Braker3"></a>2. 运行Braker3</h2><div class="story post-story"><p>官方提供了4种BRAKER pipeline 模式：</p><ul><li>RNA-Seq数据跑BRAKER</li><li>蛋白数据跑BRAKER</li><li>整合RNA-Seq数据以及蛋白数据跑BRAKER</li><li>整合短读长与长读长的RNA-Seq数据以及蛋白数据跑BRAKER</li></ul><p>4种pipeline模式在调用软件的方法上有区别，根据自己手上有的数据选择用哪种，我这里选择第三种。</p><p><img src="https://www.shelven.com/tuchuang/20230403/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上图是整合RNA-Seq数据和蛋白数据跑Braker的流程图，需要注意基因组文件<code>genome.fa</code>在输入前需要需要进行softmasking（重复序列屏蔽为小写字母），官方建议不要用hardmasking（重复序列屏蔽为N），hardmasking后预测的基因数量会偏少，因为重复序列中可能也有功能基因的部分信息，屏蔽为N后就无法检测到了。</p><p>对RNA-Seq数据的处理，首先是通过<code>SRA tookit</code>将SRA ID对应的fastq数据下载下来（如果本来就是fastq格式就不需要这一步），用<code>Hisat2</code>比对到softmasking后的参考基因组并生成bam文件，再用<code>stringtie</code>进行转录本组装。</p><p><code>GeneMark-ETP</code>以组装后的转录本和同源蛋白数据库作为输入数据进行训练和预测，之后再用<code>AUGUSTUS</code>软件结合上一步的预测结果进行训练和预测，最后用<code>TSEBRA</code>对预测的基因集进行整合，得到最终的gtf结果文件。</p><p><code>barker.sh</code>脚本可以如下编写:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 48</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">wd=baima_pre</span><br><span class="line"></span><br><span class="line">if [ -d $wd ]; then</span><br><span class="line">    rm -r $wd</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">singularity exec -B $&#123;PWD&#125;:$&#123;PWD&#125; $&#123;BRAKER_SIF&#125; braker.pl --genome=/public/home/wlxie/biosoft/db_data/baima/RepeatMasker_soft/genome.nextpolish.fasta.masked --prot_seq=/public/home/wlxie/busco_soft/busco/test_data/eukaryota/busco_downloads/lineages/eudicots_odb10/refseq_db.faa --softmasking --threads 48 --workingdir=$&#123;wd&#125; --rnaseq_sets_dirs=/public/home/wlxie/RNAseq/BYT2022020901/rnaseq/baima --rnaseq_sets_ids=4-216031965_raw</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>几个参数的解释：</p><blockquote><p>genome    softmasking后的基因组文件位置</p><p>prot_seq    同源蛋白库的文件位置</p><p>–softmasking    mask的方式</p><p>–threads    跑程序用的核数</p><p>–workingdir    工作目录位置</p><p>rnaseq_sets_dirs    RNA-Seq数据所在目录</p><p>–rnaseq_sets_ids    双端测序数据文件前缀（比如我这里是4-216031965_raw_1.fq和4-216031965_raw_2.fq）</p></blockquote><p><del>说明一下同源蛋白来源于前面做BUSCO评估的真双子叶植物单拷贝直系同源库，怎么来的详情可见<a href="http://www.shelven.com/2023/03/01/a.html">这篇博客</a></del>（<strong>同源蛋白库建议用官方推荐的OrthoDB</strong>或者找几个模式植物的蛋白数据合并，见博客最下方的更新）</p><p><strong>前面说过塔大集群的计算节点没有安装singularity</strong>，所以在运行该容器的时候要在申请核在本地跑程序，并且用screen维持当前会话：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">screen -S singularity# 创建singularity会话</span><br><span class="line">salloc -n 48 -t 7200# 申请计算资源</span><br><span class="line">bash barker.sh</span><br><span class="line"></span><br><span class="line">screen -r singularity# 进入singularity会话</span><br><span class="line">exit# 退出会话</span><br><span class="line">exit# 运行结束释放计算资源</span><br></pre></td></tr></table></figure><p>正常跑完花费了9个小时时间（200Mbp大小的基因组），如果中途不幸出bug，braker支持有限度的断点重新运行，主要分为以下三个阶段：</p><p><img src="https://www.shelven.com/tuchuang/20230403/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>只要有中间文件存在，就可以在这三个阶段继续加入其他参数，跳过已经运行的阶段继续运行，详情可以看官方文档<a href="https://github.com/Gaius-Augustus/BRAKER#starting-braker-on-the-basis-of-previously-existing-braker-runs">https://github.com/Gaius-Augustus/BRAKER#starting-braker-on-the-basis-of-previously-existing-braker-runs</a></p></div><h2 id="3-结果文件"><a href="#3-结果文件" class="headerlink" title="3. 结果文件"></a>3. 结果文件</h2><div class="story post-story"><p>可以在前面给定的工作目录中看到如下结果文件:</p><p><img src="https://www.shelven.com/tuchuang/20230403/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><blockquote><ul><li>braker.gtf——Braker预测的基因集，包括了各种不同的基因结构预测结果</li><li>braker.codingseq——fasta格式的编码序列基因集（基因序列）</li><li>braker.aa——fasta格式的蛋白序列基因集（蛋白序列）</li><li>braker.gff3——需要–gff3参数指定，这里我没有，就是基因集的gff3格式</li><li>Augustus&#x2F;*——AUGUSTUS预测的基因集（包括gtf文件、基因序列和蛋白序列）</li><li>GeneMark-ETP&#x2F;*——GeneMark-ETP预测的基因集以及其他中间文件</li><li>hintsfile.gff——从RNA-Seq数据和蛋白库数据中提取的外部证据数据</li></ul></blockquote><p>可以通过awk命令查看gft文件的第三列，查看预测的编码蛋白基因数量和转录本数量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">awk <span class="string">&#x27;$3==&quot;gene&quot;&#x27;</span> braker.gtf | <span class="built_in">wc</span> -l</span></span><br><span class="line">17869</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">awk <span class="string">&#x27;$3==&quot;transcript&quot;&#x27;</span> braker.gtf | <span class="built_in">wc</span> -l</span></span><br><span class="line">20832</span><br></pre></td></tr></table></figure><p>后续就可以对这些预测的基因做质量评估，然后比对各数据库做功能注释。</p></div><h2 id="2023-4-7-更新"><a href="#2023-4-7-更新" class="headerlink" title="2023.4.7 更新"></a>2023.4.7 更新</h2><div class="story post-story"><h3 id="1-OrthoDB蛋白数据库下载"><a href="#1-OrthoDB蛋白数据库下载" class="headerlink" title="1. OrthoDB蛋白数据库下载"></a>1. OrthoDB蛋白数据库下载</h3><p>官方推荐使用OrthoDB数据库作为同源蛋白来源。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 真菌</span><br><span class="line">Fungi: https://v100.orthodb.org/download/odb10_fungi_fasta.tar.gz</span><br><span class="line"># 后生动物</span><br><span class="line">Metazoa: https://v100.orthodb.org/download/odb10_metazoa_fasta.tar.gz</span><br><span class="line"># 节肢动物</span><br><span class="line">- Arthropoda: https://v100.orthodb.org/download/odb10_arthropoda_fasta.tar.gz</span><br><span class="line"># 脊椎动物</span><br><span class="line">- Vertebrata: https://v100.orthodb.org/download/odb10_vertebrata_fasta.tar.gz</span><br><span class="line"># 单细胞生物</span><br><span class="line">Protozoa: https://v100.orthodb.org/download/odb10_protozoa_fasta.tar.gz</span><br><span class="line"># 绿色植物</span><br><span class="line">Viridiplantae: https://v100.orthodb.org/download/odb10_plants_fasta.tar.gz</span><br></pre></td></tr></table></figure><p>我这里要分析的物种是植物，所以下载最后一个绿色植物蛋白库：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nohup wget https://v100.orthodb.org/download/odb10_plants_fasta.tar.gz &amp;</span><br><span class="line">tar zxvf odb10_plants_fasta.tar.gz</span><br><span class="line">cat plants/Rawdata/* &gt; plant_proteins.fasta</span><br></pre></td></tr></table></figure><p>绿色植物蛋白库约780Mb大小，<strong>建议用wget下载</strong>，如果windows下载再ftp拖拽上传到集群可能会损坏文件（并且没有md5效验码没办法确认是否真的损坏）。</p><p>解压并将所有数据合并到一个文件<code>plant_proteins.fasta</code>中，截至目前2023年4月7日为止，这个数据库共有3510742条蛋白序列，总文件大小为1.4Gb，比原来我比对的蛋白库大了1500倍。而蛋白比对是一个很缓慢的过程，因此这一步预测基因的时间将会很长，可以根据自己要做的物种确定用哪些注释比较完善的模式生物的蛋白库。</p><h3 id="2-自建蛋白数据库"><a href="#2-自建蛋白数据库" class="headerlink" title="2. 自建蛋白数据库"></a>2. 自建蛋白数据库</h3><p>在NCBI网站上直接找一些组装注释结果较好的模式生物和近缘物种蛋白：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 拟南芥（TAIR10.1）</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/735/GCF_000001735.4_TAIR10.1/GCF_000001735.4_TAIR10.1_protein.faa.gz</span><br><span class="line"># 栽培烟草（Ntab-TN90）</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/715/135/GCF_000715135.1_Ntab-TN90/GCF_000715135.1_Ntab-TN90_protein.faa.gz</span><br><span class="line"># 水稻（IRGSP-1.0）</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/001/433/935/GCF_001433935.1_IRGSP-1.0/GCF_001433935.1_IRGSP-1.0_protein.faa.gz</span><br><span class="line"># 近缘物种coffea arabica</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/713/225/GCF_003713225.1_Cara_1.0/GCF_003713225.1_Cara_1.0_protein.faa.gz</span><br><span class="line"># 近缘物种coffea canephora</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/900/059/795/GCA_900059795.1_AUK_PRJEB4211_v1/GCA_900059795.1_AUK_PRJEB4211_v1_protein.faa.gz</span><br><span class="line"></span><br><span class="line">gunzip *.gz</span><br><span class="line">cat *.faa &gt; mydb_proteins.fasta</span><br></pre></td></tr></table></figure><p>顺便记录一下近缘物种的同源蛋白是如何找到的：</p><p><a href="https://www.plabipd.de/">plant Biology - Usadel lab (plabipd.de)</a>这个网站记录了多种已发表的植物基因组文章和数据，点击<a href="https://www.plabipd.de/plant_genomes_pa.ep">cladogram view</a>可以直观地看到已测过基因组的植物学名和树状图，比如我要找的物种是夹竹桃科（Apocynaceae），直接<code>ctrl + F</code> 就可以定位到夹竹桃科所处的进化节点。</p><img src="https://www.shelven.com/tuchuang/20230403/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>然后用Apocynaceae祖先节点和子节点的已发表基因组的植物学名，一个一个去搜NCBI网站的Genome库，有protein序列的就可以直接下载。</p><p><img src="https://www.shelven.com/tuchuang/20230403/7.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230403/7.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>两种同源蛋白建库方式预测的基因数量和花费的时间：</p><table><thead><tr><th></th><th>OrthoDB Plant数据库</th><th>自建蛋白数据库</th></tr></thead><tbody><tr><td>花费时间</td><td>13 h</td><td>12.5 h</td></tr><tr><td>预测基因数</td><td>23746</td><td>23953</td></tr></tbody></table><p>用自建蛋白数据库跑braker预测的基因数更多，且花费时间更短。后续以该预测结果继续分析。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;在对基因组重复序列和ncRNA进行注释后，接下来是基因预测和功能注释，这也是寻找功能基因的基础和前提。这里主要记录下怎么用Braker3进行基因组的基因预测（也就是结构注释）。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="Barker3" scheme="http://www.shelven.com/tags/Barker3/"/>
    
  </entry>
  
  <entry>
    <title>Apptainer/Singularity使用方法记录</title>
    <link href="http://www.shelven.com/2023/03/29/a.html"/>
    <id>http://www.shelven.com/2023/03/29/a.html</id>
    <published>2023-03-28T16:05:34.000Z</published>
    <updated>2023-03-28T16:21:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>在做生信分析的时候，难免会遇到一个pipeline上的软件存在冲突的情况，一般的解决方法是创建不同的conda环境，然后分别在不同的环境下跑不同的软件。这种操作可以解决环境冲突的问题但不适合写流程化的脚本，同时又非常占用空间。有的软件整合了pipeline流程的所有软件，按照顺序进行调用，这种软件虽然可以节省时间实现自动化分析，但是环境依赖的问题更加复杂，因此这一类的软件也往往提供容器来方便人们在一个封闭的环境中使用。</p><span id="more"></span><p>这篇博客主要讲一讲关于容器的一些基本常识，以及记录下学校集群中<code>singularity</code>的使用方法。</p><h2 id="1-容器（Container）"><a href="#1-容器（Container）" class="headerlink" title="1. 容器（Container）"></a>1. 容器（Container）</h2><div class="story post-story"><p>前面说到为了规避软件与现有环境依赖冲突，我们往往会把一个pipeline的软件封装到一个容器中。容器是一种在Linux系统上广泛采用的应用封装技术，它将可执行程序与依赖库打包成一个镜像文件，启动时与宿主节点共享操作系统内核。</p><blockquote><p>镜像（Image）：可执行的独立软件包，用于保存环境</p><p>实例（Instance）：基于镜像启动的运行实例，运行实际任务，不同实例之间互相隔离</p></blockquote><p>由于这个镜像文件自带了可执行文件和依赖库，因此不需要用到宿主机的依赖库，也就从源头上避免了环境冲突的情况。听起来这种实现方式类似于<strong>虚拟化技术</strong>，但还是有一些区别的：前面说过容器启动时与宿主机共享操作系统内核，没有运行独立的操作系统任务，在资源的占用上明显低于虚拟机。虚拟化可以认为它更全面和彻底一些，每个虚拟机从宿主机的物理框架中分割出来，有自己的一整套操作系统，会运行各种独立的操作系统任务，即使没有运行程序也会消耗内存和系统资源。</p><p><img src="https://www.shelven.com/tuchuang/20230329/11.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230329/11.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上图来自Microsoft Azure容器与虚拟机的比较。总结来说，在安全性和隔离性上虚拟机优于容器，在资源占用、可移植性和运行速度上，容器优于虚拟机。</p><p>现有的容器软件比较多，<a href="https://github.com/jenkinsci/docker">Docker</a>（5.8k star）是代表性的软件之一，其他开源容器化工具还有<a href="https://github.com/containers/podman">Podman</a>（17.4k star，无守护进程的容器技术，无需root权限）、<a href="https://github.com/lxc/lxd">LXD</a>（3.8k star，可运行多个进程）、<a href="https://github.com/apptainer/singularity">Apptainer</a>（以前叫<strong>singularity</strong>，2.4k star，无需root权限）、<a href="https://github.com/containerd/containerd">Containerd</a>（13.5k star）和<a href="https://github.com/opencontainers/runc">RunC</a>（10.1k star）等。</p><p>这些开源的容器化技术软件各有其特点，详情可以点各自的链接了解，这里就不过多介绍了。主要说下塔大集群部署的singularity（现在已改名为Apptainer，很多人不知道改名了，两个名字就放一块儿说）的使用方法。</p></div><h2 id="2-Apptainer-x2F-Singularity"><a href="#2-Apptainer-x2F-Singularity" class="headerlink" title="2. Apptainer&#x2F;Singularity"></a>2. Apptainer&#x2F;Singularity</h2><div class="story post-story"><p>首先还是要说明以一下什么时候选择用容器，并不是说每一个软件都要用容器封装——反而这样是对系统资源的浪费。一般是在需要批量部署环境、或者快速部署一个pipeline环境的时候选择用容器。在HPC上进行大规模计算的时候，一般考虑安全性不会用Docker（需要root权限），Apptainer&#x2F;Singularity这种无需root权限的容器工具是最好的选择。</p><p>需要说明一下，两年前Singularity改名为Apptainer，并且整个项目已经转移成为了Linux Foundation的一部分。Apptainer用法和Singularity几乎一模一样，可以参考<br><a href="https://apptainer.org/docs/user/latest/quick_start.html">https://apptainer.org/docs/user/latest/quick_start.html</a><br><a href="https://docs.sylabs.io/guides/latest/user-guide/quick_start.html#">https://docs.sylabs.io/guides/latest/user-guide/quick_start.html#</a><br>两个官方手册。因为塔大超算预装了singularity，以下统一用Singularity命令来讲解。</p><p>Singularity的镜像文件以<code>.sif</code>为后缀（<strong>Singularity Image File, SIF</strong>），<strong>且该文件是只读的</strong>，这和Docker镜像文件有本质上的区别。</p><h3 id="2-1-使用镜像库获取镜像文件"><a href="#2-1-使用镜像库获取镜像文件" class="headerlink" title="2.1 使用镜像库获取镜像文件"></a>2.1 使用镜像库获取镜像文件</h3><p>Singularity image文件是基于Docker image创建的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">singularity -d build braker3.sif docker://teambraker/braker3:latest</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以获取的镜像文件库（云平台）有以下几种</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Sylabs cloud librarylibrary://</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Dockerdocker://</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Shubshub://</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">OCI registryoras://</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建之后的文件名为braker3.sif</span></span><br></pre></td></tr></table></figure><blockquote><p>build&#x2F;pull 这两个命令都可以拉取镜像文件并创建为singularity的sif文件</p><p>创建的image路径、名字都可以在-d参数后根据需要自己改</p></blockquote><p>当一个软件提供docker镜像，我们就可以通过上面的方法下载并创建一个singularity镜像，需要注意这个镜像文件是<strong>只读的</strong>。</p><h3 id="2-2-创建自定义镜像文件"><a href="#2-2-创建自定义镜像文件" class="headerlink" title="2.2 创建自定义镜像文件"></a>2.2 创建自定义镜像文件</h3><p>这里顺带提一下如何制作自定义的SIF镜像文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">singularity -d build --sandbox ubuntu/ docker://ubuntu</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以沙盒的形式创建一个空的操作系统，放在ubuntu这个文件夹中</span></span><br><span class="line"></span><br><span class="line">singularity shell --writable ubuntu</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--writable或者-w以可修改模式进入沙盒。也可以不用这种方法进入，直接进入对应的文件位置修改即可</span></span><br><span class="line"></span><br><span class="line">singularity build name.sif ubuntu</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建sif镜像文件</span></span><br></pre></td></tr></table></figure><p>进入沙盒，就可以和正常的linux操作系统一样进行安装软件，最后build制作成名为name.sif的singularity镜像，和2.1从镜像库拉取创建的镜像后续是一样的用法。</p><p>第二步以可修改模式进入沙盒时可能会有如下提示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WARNING: By using --writable, Singularity can&#x27;t create /public destination automatically without overlay or underlay</span><br><span class="line">FATAL:   container creation failed: mount /var/singularity/mnt/session/public-&gt;/public error: while mounting /var/singularity/mnt/session/public: destination /public doesn&#x27;t exist in container</span><br></pre></td></tr></table></figure><p>无法自动创建public这个文件夹，并且进入<code>/var/singularity/mnt/session/</code>这个文件夹下你会发现是空的，此时需要手动在你创建ubuntu的文件夹中创建public文件夹 <code>mkdir public</code>，提示缺少其他文件也是一样的处理方法，缺啥创建啥，就可以正常进入了。</p><p><strong>需要注意，塔大集群无法制作sif镜像文件！！！</strong>会在最后一步build的时候提示permission denied，因此，创建自定义镜像文件要在自己的计算机上（拥有root权限），制作完成之后的sif镜像文件可以上传到集群中再运行。</p><h3 id="2-3-运行镜像文件"><a href="#2-3-运行镜像文件" class="headerlink" title="2.3 运行镜像文件"></a>2.3 运行镜像文件</h3><p>singularity主要有两种运行方式，一种是执行镜像文件中的命令 <code>singularity exec</code>；一种是进入交互模式<code>singularity shell</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">singularity exec name.sif test/test.pl </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行name.sif镜像文件中<span class="built_in">test</span>文件夹下的test.pl程序</span></span><br><span class="line"></span><br><span class="line">singularity shell name.sif</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以交互模式进入name.sif镜像文件</span></span><br></pre></td></tr></table></figure><p>需要注意，运行镜像文件后，singularity会自动挂载当前目录<code>$PWD</code>、用户家目录<code>$HOME</code>和宿主机的<code>/tmp</code>目录，<strong>对这些目录的文件进行修改会影响到原文件</strong>。对于一般的程序来说已经足够了，如果需要访问宿主机的其他目录，需要用<code>--bind</code>将宿主机目录映射到容器内。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">singularity exec --bind /pub/software:/mnt name.sif python test.py</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--<span class="built_in">bind</span>挂载宿主机的文件夹，冒号前为宿主机的路径，冒号后为容器中的路径。内容挂载到/mnt中</span></span><br><span class="line"></span><br><span class="line">singularity exec --bind /pub/software name.sif python test.py</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不写挂载点，则与宿主机的目录一致。内容挂载到/pub/software中</span></span><br></pre></td></tr></table></figure><h3 id="2-4-在集群中提交singularity作业"><a href="#2-4-在集群中提交singularity作业" class="headerlink" title="2.4 在集群中提交singularity作业"></a>2.4 在集群中提交singularity作业</h3><p>一般来说登录节点预装了singularity，计算节点也会装singularity才对，但是无论我直接用singularity命令还是指定singularity命令的绝对路径，在sbatch提交作业后都是提示该命令不存在。很疑惑，又去查了一些资料，发现有的平台需要在作业里<code>module load singularity</code>之后才可以加载，但是塔大集群用这个指令仍然行不通，只有本地（登录节点）才可以使用该命令。</p><p>百思不得其解，询问集群管理员暂时没有答复，后续有新消息会更新。这里说一下我的解决方法：</p><p>既然可以在本地运行singularity，那就可以用<code>salloc</code>申请计算资源，在本地跑程序。但是我又不可能一直坐在电脑跟前，因此需要用到<code>screen</code>这个工具维持当前会话。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">screen -S test</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建名为<span class="built_in">test</span>的session对象</span></span><br><span class="line"></span><br><span class="line">salloc -n 50 -t 7200</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">申请50核的计算资源</span></span><br><span class="line"></span><br><span class="line">export BRAKER_SIF=\$PWD/braker3.sif</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给host添加环境变量（非必须，打个比方）</span></span><br><span class="line"></span><br><span class="line">singularity esec braker3.sif braker.pl </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行容器中的程序</span></span><br></pre></td></tr></table></figure><p>运行之后就可以双手离开键盘，关上电脑，等待第二天程序运行结束了。</p><p>再次打开session的时候只需要运行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">screen -r test</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次打开session</span></span><br><span class="line"></span><br><span class="line">exit</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退出session</span></span><br><span class="line"></span><br><span class="line">exit</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">释放计算资源</span></span><br></pre></td></tr></table></figure><p>注意需要两次exit之后才会回到原来的登录节点。</p><p>singularity还有很多其他参数，对我而言暂时用不到，需要用的时候再更新。</p><p>可以参考武大超算中心的文档<a href="http://docs.hpc.whu.edu.cn/files/whuhpcdocs.wiki/sbatch/singularity.html">运行 Singularity · GitBook (whu.edu.cn)</a>和北鲲云的介绍文档<a href="https://www.cloudam.cn/helpce/docs/2030/about2/%E3%80%82">https://www.cloudam.cn/helpce/docs/2030/about2/。</a><br><del>（可恶，我们学校集群什么时候能出一个详细的文档啊。好想吐槽，slurm调度系统和各种软件都要自己学，功能还不一定全，也不知道到底预装了哪些东西，以后要是我来管理集群一定会做详细的文档介绍所有花里胡哨的功能，而不是藏着不告诉用户）</del></p><h3 id="2023-3-29更新"><a href="#2023-3-29更新" class="headerlink" title="2023.3.29更新"></a>2023.3.29更新</h3><p>破案了，计算节点确实没装singularity（噎住.jpg）</p><p><img src="https://www.shelven.com/tuchuang/20230329/22.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230329/22.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;在做生信分析的时候，难免会遇到一个pipeline上的软件存在冲突的情况，一般的解决方法是创建不同的conda环境，然后分别在不同的环境下跑不同的软件。这种操作可以解决环境冲突的问题但不适合写流程化的脚本，同时又非常占用空间。有的软件整合了pipeline流程的所有软件，按照顺序进行调用，这种软件虽然可以节省时间实现自动化分析，但是环境依赖的问题更加复杂，因此这一类的软件也往往提供容器来方便人们在一个封闭的环境中使用。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="容器" scheme="http://www.shelven.com/tags/%E5%AE%B9%E5%99%A8/"/>
    
    <category term="singularity" scheme="http://www.shelven.com/tags/singularity/"/>
    
  </entry>
  
  <entry>
    <title>基因组注释（3）——ncRNA注释</title>
    <link href="http://www.shelven.com/2023/03/22/a.html"/>
    <id>http://www.shelven.com/2023/03/22/a.html</id>
    <published>2023-03-21T16:29:28.000Z</published>
    <updated>2023-03-21T16:31:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>非编码RNA(non-coding RNA，ncRNA)指不编码蛋白质的RNA，包括rRNA、tRNA、snRNA、snoRNA 和 microRNA 等多种已知功能的 RNA，和未知功能的RNA。tRNA预测可以使用经典的<strong>tRNAscan-SE</strong>，其他类型的RNA都可以用<strong>Infernal+Rfam数据库</strong>方式预测。</p><span id="more"></span><h2 id="1-tRNAscan-SE"><a href="#1-tRNAscan-SE" class="headerlink" title="1. tRNAscan-SE"></a>1. tRNAscan-SE</h2><div class="story post-story"><p>tRNAscan-SE的安装需要依赖Infernal软件，因此可以用conda直接安装tRNAscan-SE顺带解决依赖问题：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c bioconda trnascan-se</span><br></pre></td></tr></table></figure><p>写一个脚本运行tRNAscan-SE：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">tRNAscan-SE --thread 50 -E -I -m tRNA_luobuma.stats -o tRNA_luobuma.out -f tRNA_luobuma.ss /public/home/wlxie/NextPolish/luobuma_rundir/genome.nextpolish.fasta</span><br></pre></td></tr></table></figure><p>参数解释：</p><blockquote><p>-E  搜寻真核生物tRNA</p><p>-I  使用Infernal软件进行搜索</p><p>-m  保存结果统计文件</p><p>-o  输出tRNA预测结果</p><p>-f  保存tRNA的二级结构</p></blockquote><p>也可以直接使用<code>-j</code>参数保存gff3格式，<code>-b</code>参数保存bed格式，详情可以见<code>tRNAscan-SE -h</code></p><p>生成的二级结构结果文件如下：</p><img src="https://www.shelven.com/tuchuang/20230320/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>str一行记录的二级结构信息，每个<code>&lt;&gt;</code>是互相配对的，代表在二级结构中这两个碱基连在一起。可以通过其他软件（如VARNA）绘制成图。</p><p>输出的out文件也推荐转成gff文件方便在基因组上可视化，因为我这里只是粗略统计一下tRNA数量，所以只看stat文件就可以了：</p><img src="https://www.shelven.com/tuchuang/20230320/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom: 67%;" /><p>可以看到第一轮预测出526个tRNA，通过Infernal验证的有479个。</p></div><h2 id="2-Infernal-Rfam"><a href="#2-Infernal-Rfam" class="headerlink" title="2. Infernal + Rfam"></a>2. Infernal + Rfam</h2><div class="story post-story"><p><a href="http://eddylab.org/infernal/">Infernal（INFERence of RNA ALignment）</a>是Sanger实验室开发的ncRNA预测软件，他们建立了1600多个RNA家族，每个家族建立了一致性二级结构和协方差模型，也就是Rfam数据库。总体的注释思路是基因组与 Rfam数据库进行比对，Rfam是一个RNA分类数据库，其比对方法是调用软件Infernal中的程序<code>cmscan</code>，将提交的序列在<code>Rfam.cm</code>数据库中进行检索，从而得到其比对的结果。</p><p><code>cmscan</code>（search sequence(s) against a covariance model database, 针对协方差模型数据库的序列搜索），主要参考官方手册<a href="http://eddylab.org/infernal/Userguide.pdf">Userguide.pdf (eddylab.org)</a>中的<strong>Searching the Rfam CM database with a query sequence</strong>步骤。</p><p>前面已经安装了Infernal，这里需要再下载一个Rfam数据库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载Rfam数据库，注意两个文件版本必须一致</span></span><br><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/CURRENT/Rfam.cm.gz</span><br><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/CURRENT/Rfam.clanin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压建库</span></span><br><span class="line">gunzip Rfam.cm.gz</span><br><span class="line">cmpress Rfam.cm</span><br></pre></td></tr></table></figure><p>官方手册这里使用默认参数运行<code>cmscan</code>，稍微注意下<code>-Z</code>，以下是官方对<code>-Z</code>参数的定义：</p><blockquote><p> -Z <x> Calculate  E-values as if the search space size was <x> megabases (Mb). Without the<br>            use of this option, the search space size changes for each query  sequence,  it  is<br>            defined  as  the length of the current query sequence times 2 (because both strands<br>            of the sequence will be searched) times the number of CMs in <cmdb>.</p></blockquote><p><code>Z</code>值代表搜索数据库的大小（database size），是和<code>E-Values</code>计算相关的，在默认情况下，每一个query sequence的-Z参数值是不同的，等于query sequence本身的碱基数*2*CM数据库中模型的数量，只有<code>E-Values</code>小于10的hits会被报道。</p><p>在作者的原文中，可以找到这么一句话：</p><blockquote><p>To manually set the database size used in the E-value calculation to <X> megabases when running cmsearch or cmscan on the command line, use the -Z <X> option. It makes sense to do this if, for example, a large sequence file has been split up into many smaller files, and searches have been performed in parallel on a compute cluster, with the results combined. In that scenario, if <X> is set as the total number of models used times the total number of nucleotides in all sequence files times two (for both strands), then the combined results should have appropriate E-values. That is, the expectation is that in the collection of all hits between all sequences and models there will be about 1 hit with an E-value of 1 or below by chance (not due to homology), about 10 with an E-value of 10 or below by chance, etc.</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6754622/">Non-coding RNA analysis using the Rfam database - PMC (nih.gov)</a></p></blockquote><p>也就是说一个大的序列文件被分割成数个文件，并在一个集群上并行搜索，最终将结果文件整合的时候，设置Z值为使用的CM模型数量*所有序列文件的核苷酸总数*2，合并的结果会有一个适当的E-value值。</p><p>前面建库的时候可以看到CM数据库中模型的数量：</p><p><img src="https://www.shelven.com/tuchuang/20230320/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>CM模型的数量不可以直接用<code>cat Rfam.cm | grep &quot;ACC&quot; | wc -l</code>这种方式查询，你会发现这种只搜索<code>ACC</code>或者<code>NAME</code>字段查找到的数量是实际数量的两倍（包括了HMM filter）。</p><p>Z值&#x3D; <code>基因组核苷酸数*2*数据库中模型数量/1000000</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">esl-seqstat my-genome.fa# HMMER插件，统计基因组大小，计算Z值用</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230320/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>因此这里的Z值计算如下：<br>$$<br>Z &#x3D; 2<em>230888863</em>4108&#x2F;1000000&#x3D;1896982.90<br>$$<br><strong>但是很神奇的是</strong>，在Rfam的帮助文档中给了一个对古菌<em>Methanobrevibacter ruminantium</em>注释ncRNA的例子，其中也用了Rfam数据库的，计算Z值时没有乘以CM模型的数量，我也有点疑惑，以下是链接地址。</p><p><a href="https://docs.rfam.org/en/latest/genome-annotation.html#">Genome annotation — Rfam Help documentation</a></p><blockquote><p>For the purposes of Infernal, the total database size is the number of nucleotides that will be searched, in units of megabases (Mb, millions of nucleotides). So, it is the <strong>total number of nucleotides</strong> in all sequences that make up the genome, <strong>multiplied by two</strong> (because both strands will be searched), and <strong>divided by 1,000,000</strong> (to convert to millions of nucleotides).</p><p>就 Infernal 而言，数据库总大小是将要搜索的核苷酸数量，以兆碱基（Mb，百万核苷酸）为单位。因此，它是构成基因组的所有序列中的核苷酸总数乘以2（因为将搜索两条链），然后除以 1,000,000（转换为Mb）。</p></blockquote><p>两种方法计算Z值相差4000多倍，我无法断定哪种是正确的，后续有更深的理解再更新（也许是版本问题？）。</p><p>这里我<strong>按照文章作者给的默认参数对基因组进行注释</strong>（也就是没有指定Z值，每条序列的Z值是变动的）。</p><p>运行脚本如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">cmscan --cut_ga --rfam --nohmmonly --tblout luobuma.tblout --fmt 2 -o luobuma.out --clanin Rfam.clanin Rfam.cm /public/home/wlxie/NextPolish/luobuma_rundir/genome.nextpolish.fasta</span><br></pre></td></tr></table></figure><p>参数解释：</p><blockquote><p>–cut_ga  指定Rfam GA阈值，决定哪些hits可以报告。有多种标准，可以见<a href="https://docs.rfam.org/en/latest/glossary.html#gathering-cutoff">Glossary — Rfam Help documentation</a></p><p>–fram  以快速模式运行</p><p>–nohmmonly  决定所有模型都是CM模型（非HMM模型）</p><p>–tblout  表格形式输出结果</p><p>–fmt 2  输出格式2，包括overlapping hit的注释</p><p>-o  标准输出文件</p><p>–clanin  Rfam.clanin文件的位置，该文件记录哪些模型属于同一家族</p></blockquote><p>最终获得<code>luobuma.out</code>的标准输出文件和整理成表格的<code>luobuma.tblout</code>文件，这里整理一下表格文件：</p><p><img src="https://www.shelven.com/tuchuang/20230320/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://www.shelven.com/tuchuang/20230320/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>27列对应预测ncRNA类型和信息；前后都有#键注释的行，除此之外每一行是预测的ncRNA具体内容</p><p>需要注意<code>olp</code>这一列，在<code>infernal 1.1.4版本</code>这一列有以下四个值：</p><blockquote><p>*  indicates this hit does not overlap with any other reported hits  这条序列与其他已报道的序列之间无重叠区域（保留）</p><p>ˆ  indicates that this hit does overlap with at least one other hit, but none of the hits that overlap with it have a lower E-value (occur above it in the hit list)  这条序列与至少一条已报道的序列之间有重叠区域，但是这条序列的E-value最低（保留）</p><p>$  indicates that this hit does overlap with at least one other hit that does have a lower E-value (occurs above it in the hit list) but none of those higher scoring hits have ˆ in this column  这条序列与至少一条已报道序列之间有重叠区域，且其他序列E-value更低但不是最低的（过滤，1.1.2版本的infernal中没有）</p><p>&#x3D;  indicates that this hit does overlap with at least one other hit that has a lower E-value (occurs above it in the hit list) and does itself have a ˆ in this column  这条序列与至少一条已报道序列之间有重叠区域，且其他序列的E-value值更低且是最低的（过滤）</p></blockquote><p>我们只关注预测结果中<strong>准确度最高的ncRNA</strong>，记录种类和长度，因此可以写个python脚本处理并统计数据。</p><p>因为这里输出的列表没有具体给出分类，因此对数据处理前要去Rfam官网的<strong>Entry type search</strong>栏下找到每个accession号对应的ncRNA类型<a href="https://rfam.org/search#tabview=tab5">Rfam: Search Rfam</a>：</p><img src="https://www.shelven.com/tuchuang/20230320/7.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/7.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:50%;" /><p>我这里只关心上面红框中的ncRNA（根据情况自己选择），勾选之后点击submit：</p><p><img src="https://www.shelven.com/tuchuang/20230320/8.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/8.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>拉到最底下看到官网提供未格式化的列表，点击show，将显示的列表复制粘贴到一个新建的<code>accession.txt</code>文档，接下来就是对<code>tblout</code>文件和<code>accession.txt</code>文件处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Infernal预测ncRNA结果文件统计脚本</span></span><br><span class="line"><span class="string">2023.3.22</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 结果文件数据过滤，获取每条预测ncRNA的accession号和长度</span></span><br><span class="line">loci_length = []</span><br><span class="line">accession = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./luobuma.tblout&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> <span class="built_in">input</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">input</span>.readlines():</span><br><span class="line">        <span class="keyword">if</span> i.find(<span class="string">&#x27;#&#x27;</span>) != -<span class="number">1</span> <span class="keyword">or</span> i.find(<span class="string">&#x27;=&#x27;</span>) != -<span class="number">1</span> <span class="keyword">or</span> i.find(<span class="string">&#x27;$&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            lst = i.strip().split()</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(lst) &lt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            length = <span class="built_in">abs</span>(<span class="built_in">int</span>(lst[<span class="number">10</span>]) - <span class="built_in">int</span>(lst[<span class="number">9</span>]))</span><br><span class="line">            loci_length.append(length)</span><br><span class="line">            accession.append(lst[<span class="number">2</span>])</span><br><span class="line">len_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> loci_length:</span><br><span class="line">    len_sum += i</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理accession.txt,提取accession号和ncRNA类型的关系</span></span><br><span class="line">accession_num = []</span><br><span class="line">dicts = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./accession.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> ac:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ac.readlines():</span><br><span class="line">        m = i.strip().split(<span class="string">&#x27;\t&#x27;</span>)<span class="comment"># 以制表符分割</span></span><br><span class="line">        accession_num.append(m[<span class="number">0</span>])</span><br><span class="line">        nc_type = m[<span class="number">2</span>].split(<span class="string">&#x27;;&#x27;</span>)[<span class="number">1</span>].strip()<span class="comment"># 获取第三列第二个分号处的ncRNA类型</span></span><br><span class="line">        <span class="keyword">if</span> m[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> dicts:</span><br><span class="line">            dicts[m[<span class="number">0</span>]] = nc_type</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计结果文件accession号对应的ncRNA类型数量</span></span><br><span class="line">mi = s = sn = lnc = t = r = other = <span class="number">0</span></span><br><span class="line">mi_len = s_len = sn_len = lnc_len = t_len= r_len = other_len =<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(accession)):</span><br><span class="line">    item = accession[i]</span><br><span class="line">    <span class="keyword">if</span> item <span class="keyword">in</span> dicts:</span><br><span class="line">        <span class="keyword">if</span> dicts[item] == <span class="string">&#x27;miRNA&#x27;</span>:</span><br><span class="line">            mi += <span class="number">1</span></span><br><span class="line">            mi_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line">        <span class="keyword">elif</span> dicts[item] == <span class="string">&#x27;sRNA&#x27;</span>:</span><br><span class="line">            s += <span class="number">1</span></span><br><span class="line">            s_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line">        <span class="keyword">elif</span> dicts[item] == <span class="string">&#x27;snRNA&#x27;</span>:</span><br><span class="line">            sn += <span class="number">1</span></span><br><span class="line">            sn_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line">        <span class="keyword">elif</span> dicts[item] == <span class="string">&#x27;lncRNA&#x27;</span>:</span><br><span class="line">            lnc += <span class="number">1</span></span><br><span class="line">            lnc_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line">        <span class="keyword">elif</span> dicts[item] == <span class="string">&#x27;tRNA&#x27;</span>:</span><br><span class="line">            t += <span class="number">1</span></span><br><span class="line">            t_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r += <span class="number">1</span></span><br><span class="line">            r_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        other += <span class="number">1</span></span><br><span class="line">        other_len += <span class="built_in">int</span>(loci_length[i])</span><br><span class="line"></span><br><span class="line">outputlst = [(<span class="string">&#x27;miRNA&#x27;</span>, mi, mi_len), (<span class="string">&#x27;sRNA&#x27;</span>, s, s_len), (<span class="string">&#x27;snRNA&#x27;</span>, sn, sn_len), (<span class="string">&#x27;lncRNA&#x27;</span>, lnc, lnc_len), (<span class="string">&#x27;tRNA&#x27;</span>, t, t_len), (<span class="string">&#x27;rRNA&#x27;</span>, r, r_len), (<span class="string">&#x27;others&#x27;</span>, other, other_len), (<span class="string">&#x27;total&#x27;</span>, <span class="built_in">len</span>(accession), len_sum)]</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./res.xls&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> output:</span><br><span class="line">    output.write(<span class="string">&#x27;Type\tCopy Number\tTotal length(bp)\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> outputlst:</span><br><span class="line">        <span class="built_in">type</span> = <span class="built_in">str</span>(i[<span class="number">0</span>])</span><br><span class="line">        number = <span class="built_in">str</span>(i[<span class="number">1</span>])</span><br><span class="line">        length = <span class="built_in">str</span>(i[<span class="number">2</span>])</span><br><span class="line">        output.write(<span class="built_in">type</span> + <span class="string">&#x27;\t&#x27;</span> + number + <span class="string">&#x27;\t&#x27;</span> + length + <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure><p>我对python掌握的不好，统计的地方可以写个循环的，怕自己绕不清楚这里就用最笨的方法…..</p><p>结果统计如下：</p><p><img src="https://www.shelven.com/tuchuang/20230320/9.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/9.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>tRNA这里预测470，与上面的tRNAscan-SE预测的479个基本没有差别。</strong></p><img src="https://www.shelven.com/tuchuang/20230320/10.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230320/10.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:80%;" /><p>顺带说一下，Rfam官网上也说了这种方法可以统计所有类型的RNA，如果针对不同ncRNA有特殊需求的话，可以用不同软件进行分析（但是RNAMMER现在似乎已经用不了了）。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;非编码RNA(non-coding RNA，ncRNA)指不编码蛋白质的RNA，包括rRNA、tRNA、snRNA、snoRNA 和 microRNA 等多种已知功能的 RNA，和未知功能的RNA。tRNA预测可以使用经典的&lt;strong&gt;tRNAscan-SE&lt;/strong&gt;，其他类型的RNA都可以用&lt;strong&gt;Infernal+Rfam数据库&lt;/strong&gt;方式预测。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="tRNAscan-SE" scheme="http://www.shelven.com/tags/tRNAscan-SE/"/>
    
    <category term="Rfam/Infernal" scheme="http://www.shelven.com/tags/Rfam-Infernal/"/>
    
  </entry>
  
  <entry>
    <title>SSL证书申请和部署</title>
    <link href="http://www.shelven.com/2023/03/17/a.html"/>
    <id>http://www.shelven.com/2023/03/17/a.html</id>
    <published>2023-03-17T10:00:39.000Z</published>
    <updated>2023-04-13T08:41:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>不知不觉这个小破站运行也快要一年整了，一年前网站刚开放，我天天修bug到凌晨两三点的情景还历历在目……主要还是自己对网站搭建框架不熟悉，看不懂代码整不清楚linux操作<del>（虽然现在也没好到哪儿去）</del>。一年过去了通过自学确实学习了很多计算机方面的知识，有空再做个总结吧~</p><p>一年前想写如何部署ssl证书的，如今一年快到了正好要续上ssl证书，这篇博客算是补档吧~记录下自己的操作</p><span id="more"></span><h2 id="1-SSL部署的意义"><a href="#1-SSL部署的意义" class="headerlink" title="1. SSL部署的意义"></a>1. SSL部署的意义</h2><div class="story post-story"><p>前面在<a href="https://www.shelven.com/2022/12/10/a.html">http原理</a>部分说过，HTTPS的安全基础是ssl，部署ssl之后有以下优点：</p><blockquote><ol><li>建立数据信息安全通道，保障信息安全</li><li>有https协议的网站更容易被google、baidu收录</li><li>用户浏览https协议的网站地址有锁头标志，不会显示信息安全提醒页面</li></ol></blockquote></div><h2 id="2-申请SSL证书"><a href="#2-申请SSL证书" class="headerlink" title="2. 申请SSL证书"></a>2. 申请SSL证书</h2><div class="story post-story"><p>我是在腾讯云上购买的轻量云服务器，在哪个服务器供应商买的服务器就到对应的平台，搜索SSL证书，点击申请免费证书</p><p><img src="https://www.shelven.com/tuchuang/20230317/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>选择第一个免费版即可，填写你要绑定的域名，验证方法选择手动DNS验证，提交申请</p><p><img src="https://www.shelven.com/tuchuang/20230317/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这一步需要到对应的域名供应商那里进行DNS解析</p><p><img src="https://www.shelven.com/tuchuang/20230317/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>我是在阿里云买的域名，因此在阿里云控制台找到你要绑定的域名，添加记录，输入上面图红框里的对应信息</p><p><img src="https://www.shelven.com/tuchuang/20230317/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>回到腾讯云，点击<strong>验证域名</strong>即可，后续根据自己的服务器类型（我是Apache 服务器）选择对应的证书。第一次申请的话可能会让你完善身份信息。需要注意，如果域名被托管到其他平台，需要到对应的托管平台进行DNS解析，否则会查询不到解析记录。</p></div><h2 id="3-部署SSL证书"><a href="#3-部署SSL证书" class="headerlink" title="3. 部署SSL证书"></a>3. 部署SSL证书</h2><div class="story post-story"><p>申请成功后，进入SSL证书管理平台，点击已签发，就可以看到刚刚申请的SSL证书了，首先把证书下载到本地</p><p><img src="https://www.shelven.com/tuchuang/20230317/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>解压可以看到如下四个文件，<code>.crt</code>后缀的是证书链和证书文件，<code>.csr</code>后缀的是提供给CA的文件，<code>.key</code>后缀是私钥文件</p><p><img src="https://www.shelven.com/tuchuang/20230317/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>再次强调一下Apache服务器、Nginx服务器等等的部署目录是不同的，我这里是apache服务器，需要将上面的四个文件上传到服务器<code>/etc/httpd/ssl/</code>目录下。</p><p><strong>如果之前部署过ssl证书，到这一步以后直接<code>service network restart</code>重启http服务就行了。</strong></p><p>如果是第一次安装，进入<code>/etc/httpd/conf</code>目录，修改 <code>httpd.conf</code> 配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Include conf.modules.d/*.conf# 第56行确保该命令未被注释，用于加载SSL的配置目录</span><br></pre></td></tr></table></figure><p>进入<code>/etc/httpd/conf.modules.d</code>目录，修改<code>00-ssl.conf</code> 配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LoadModule ssl_module modules/mod_ssl.so# 第1行确保该命令未被注释，用于加载SSL模块</span><br></pre></td></tr></table></figure><p>进入<code>/etc/httpd/conf.d</code>目录，修改<code>ssl.conf</code>配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DocumentRoot &quot;/var/www/html&quot;# 配置虚拟主机的位置，路径可以改，建议还是用默认的</span><br><span class="line">ServerName xxxxx.com # 填写证书网站名称</span><br><span class="line">SSLEngine on# 确保SSL功能打开</span><br><span class="line">SSLCertificateFile /etc/httpd/ssl/xxxxx.com.crt# 确定证书路径</span><br><span class="line">SSLCertificateKeyFile /etc/httpd/ssl/xxxxx.com.key# 确定私钥路径</span><br><span class="line">SSLCertificateChainFile /etc/httpd/ssl/root_bundle.crt# 确定证书链路径</span><br></pre></td></tr></table></figure><p>以上配置完成后，重启网络服务<code>service network restart</code>，这个时候再访问网站就是https协议了。</p><p>参考自<a href="https://cloud.tencent.com/document/product/400/35243">SSL 证书 Apache 服务器 SSL 证书安装部署（Linux）-证书安装-文档中心-腾讯云 (tencent.com)</a></p><p>需要注意下，证书到期之后不会自动部署…一般这种免费的SSL证书时间都是1年，在到期前一个月会有提醒，申请完成之后直接覆盖快到期的原证书即可。<del>（省下了一笔自动部署的90块钱）</del></p></div><h2 id="特别注意"><a href="#特别注意" class="headerlink" title="特别注意"></a>特别注意</h2><div class="story post-story"><p>SSL证书部署后都是立即生效的，如果你发现网站仍然提示非安全连接，可以看看自己是否用了其他第三方加速。</p><p><strong>比如你的网站用了CDN加速，需要同时在第三方加速平台上进行HTTPS配置更改，否则SSL证书无法生效！</strong></p><p><img src="https://www.shelven.com/tuchuang/20230317/10.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230317/10.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>比如我这里用了又拍云的CDN加速，且设置了HTTPS访问，不更改成新申请的证书就无法生效。每个CDN加速平台设置HTTPS方法不一样，这里就不详细说了。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;不知不觉这个小破站运行也快要一年整了，一年前网站刚开放，我天天修bug到凌晨两三点的情景还历历在目……主要还是自己对网站搭建框架不熟悉，看不懂代码整不清楚linux操作&lt;del&gt;（虽然现在也没好到哪儿去）&lt;/del&gt;。一年过去了通过自学确实学习了很多计算机方面的知识，有空再做个总结吧~&lt;/p&gt;
&lt;p&gt;一年前想写如何部署ssl证书的，如今一年快到了正好要续上ssl证书，这篇博客算是补档吧~记录下自己的操作&lt;/p&gt;</summary>
    
    
    
    <category term="个人主页" scheme="http://www.shelven.com/categories/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/"/>
    
    
    <category term="建站" scheme="http://www.shelven.com/tags/%E5%BB%BA%E7%AB%99/"/>
    
  </entry>
  
  <entry>
    <title>基因组注释（2）——散在重复序列注释</title>
    <link href="http://www.shelven.com/2023/03/16/a.html"/>
    <id>http://www.shelven.com/2023/03/16/a.html</id>
    <published>2023-03-16T15:13:10.000Z</published>
    <updated>2023-07-10T14:40:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们注释了串联重复序列（Tandem repeat，TR），接下来是对散在重复序列（也称转座子，transposable element，TE）进行注释。注释之后我们对所有重复序列在基因组上进行屏蔽，就可以进行后面的结构基因预测和注释了。</p><span id="more"></span><h2 id="1-散在重复序列"><a href="#1-散在重复序列" class="headerlink" title="1. 散在重复序列"></a>1. 散在重复序列</h2><div class="story post-story"><p>散在重复序列可以分为<strong>反转录转座子（class-I TEs）</strong>和<strong>DNA转座子（class-II TEs）</strong></p><blockquote><p>反转录转座子：通过RNA介导的copy and paste机制进行转座，主要由LTR（long terminal repeat）构成，而non-LTR根据长度又分为LINEs（long interspersed nuclear elements）和SINEs（short interspersed elements）。</p><p>DNA转座子：通过DNA介导的cut and paste机制进行转座。</p></blockquote><p>这里我们用<strong>RepeatModeler</strong>和<strong>RepeatMasker</strong>两个软件跑一遍基因组散在重复序列注释的流程，需要注意下因为前面做了TRF注释串联重复序列，我们运行RepeatMasker的时候要改下下参数设置。</p></div><h2 id="2-RepeatModeler和RepeatMasker安装"><a href="#2-RepeatModeler和RepeatMasker安装" class="headerlink" title="2. RepeatModeler和RepeatMasker安装"></a>2. RepeatModeler和RepeatMasker安装</h2><div class="story post-story"><p><strong>不建议用conda安装两款软件的本体（但是可以安装其他依赖）</strong></p><p>RepeatMasker配置成功过是RepeatModeler配置的前提条件，且两者之间有版本关联（比如最新的RepeatModeler版本为2.0.4，需要最新的RepeatMasker版本4.1.4安装为前提），conda直接安装RepeatMasker会导致RepeatModeler无法找到RepeatMasker的路径，且输入正确路径也会提示找不到（不知道是不是我的原因）。</p><p>下载源码包编译，可以看官网<a href="https://www.repeatmasker.org/">RepeatMasker Home Page</a>。</p><p><strong>本篇博客所使用RepeatMasker版本为4.1.2，RepeatModeler版本为2.0.3</strong></p><h3 id="2-1-RepeatMasker安装"><a href="#2-1-RepeatMasker安装" class="headerlink" title="2.1 RepeatMasker安装"></a>2.1 RepeatMasker安装</h3><p>本体安装过程不多说，主要说一下<strong>加载Repbase数据库</strong>：</p><p>RepeatMasker自带的重复序列数据库是Dfam数据库，这是一个转座子（TE）序列数据库，收录的物种比较少。Repbase是重复序列参考数据库，其中收录了大部分真核物种，适用于<strong>重复序列的同源预测</strong>。然而Repbase不是RepeatMasker自带的，需要额外下载，我这里提供20181026版本的Repbase下载地址：<a href="https://www.shelven.com/tuchuang/20230316/RepBaseRepeatMaskerEdition-20181026.tar">点击这里</a></p><p>下载Repbase数据库后用<code>tar -xvf</code>解压，将<code>RMRBSeqs.embl</code>和<code>README.RMRBSeqs</code>两个数据库文件放在RepeatMasker安装目录的<code>Libraries</code>目录下，注意不要修改后缀名。</p><p>在RepeatMasker安装目录下运行<code>perl ./configure</code>，一路回车确定路径，如果有缺失的依赖就用conda下载，一直到最后选择序列搜索比对的软件，我这里输入3回车，之后的界面再输入5回车确认：</p><p><img src="https://www.shelven.com/tuchuang/20230316/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230316/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>当看到提示信息Dfam和RBRM（也就是RepBase数据库）两个数据库版本的时候，就说明加载Repbase数据库成功了。</p><p>用<code>RepeatMasker -h</code>查看是否可以正常运行，如果提示<strong>Devel::Size</strong>这个perl模块缺失，可以用conda安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c bioconda perl-devel-size</span><br></pre></td></tr></table></figure><p><strong>最后需要修改一下环境变量（不修改运行的时候找不到pm文件）</strong>，将RepeatMasker 安装路径添加到<strong>PERL5LIB</strong>环境变量中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开 ~/.bashrc</span></span><br><span class="line">export PERL5LIB=&quot;/public/home/wlxie/miniconda3/envs/biosoft/share/RepeatMasker:$PERL5LIB&quot;</span><br></pre></td></tr></table></figure><h3 id="2-2-RepeatModeler安装"><a href="#2-2-RepeatModeler安装" class="headerlink" title="2.2 RepeatModeler安装"></a>2.2 RepeatModeler安装</h3><p>安装过程与RepeatMasker差不多，有一个比较坑的地方是官方可选的一部分软件（比如CD-HIT）在configure过程中是必须指定的，所以还是按照github上的说明将所有依赖都用conda安装好。<a href="https://github.com/Dfam-consortium/RepeatModeler">Dfam-consortium&#x2F;RepeatModeler: De-Novo Repeat Discovery Tool (github.com)</a></p><p>接下来在RepeatModeler安装的目录下运行<code>perl ./configure</code>，同样是一路回车到底确定路径，最后会询问是否需要预测LTR结构，<strong>因为我在之前的求<a href="https://www.shelven.com/2023/03/01/a.html">LAI指数的博客</a>中已经做过LTR预测，因此这一步选择n跳过</strong>，后续我会说明如何利用LTR预测数据：</p><p><img src="https://www.shelven.com/tuchuang/20230316/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230316/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div><h2 id="3-TE注释策略"><a href="#3-TE注释策略" class="headerlink" title="3. TE注释策略"></a>3. TE注释策略</h2><div class="story post-story"><p>因为我要注释的生物是<strong>非模式生物</strong>，在Dfam库和Repbase库中均没有该物种信息（无法在RepeatMasker软件中指定特定的物种，-species 和 -lib的参数是冲突的，需要自建数据库），因此注释所用的数据库将由以下三种数据库组成：</p><blockquote><ol><li>LTR_retriever整合的LTR预测数据库（见<a href="https://www.shelven.com/2023/03/01/a.html">这篇博客</a>）</li><li>同源的（指该类群祖先和衍生节点）重复序列数据库</li><li>使用RepeatModeler从头预测序列，训练该物种的重复序列模型，构建预测的重复序列数据库</li></ol></blockquote><p>需要注意<strong>这三种数据库都需要fasta格式</strong>，将三种数据库合并之后，使用<code>RepeatMasker -lib</code>指定自建数据库，预测TE序列。</p></div><h2 id="4-注释流程"><a href="#4-注释流程" class="headerlink" title="4. 注释流程"></a>4. 注释流程</h2><div class="story post-story"><h3 id="4-1-导出同源物种重复序列库"><a href="#4-1-导出同源物种重复序列库" class="headerlink" title="4.1 导出同源物种重复序列库"></a>4.1 导出同源物种重复序列库</h3><p>前面2.1步骤将Repbase和Dfam数据库整合之后，<code>RepeatMasker/Libraries</code>目录下<code>RepeatMaskerLib.h5</code>这个文件为整合后构建的数据库文件，我们要在这个文件中导出同源物种的重复序列。</p><p>在RepeatMasker目录下提供了<code>famdb.py</code>这个程序查询目标近缘物种。如果你不知道自己的物种在什么分支上，我这里推荐一个查找已发表的<strong>植物基因组</strong>的网站<a href="https://www.plabipd.de/plant_genomes_pa.ep">Published Plant Genomes (plabipd.de)</a>，可以一级一级查看哪些近缘物种有人做过了。用以下命令查看物种重复序列否收录到库中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python famdb.py -i Libraries/RepeatMaskerLib.h5 lineage -ad lamiids# lamiids是我能查找到的最近的分支</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230316/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230316/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>找到最近的分支后，导出最近分支的祖先节点和衍生节点物种的重复序列库，使用内置的perl软件转换成fasta格式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python famdb.py -i Libraries/RepeatMaskerLib.h5 families -f embl -a -d lamiids &gt; lamiids.embl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查找近缘物种及其上祖先节点，其下所有类群repeat famlies，输出格式embl。 -a ancestor，-d descendent</span></span><br><span class="line"></span><br><span class="line">buildRMLibFromEMBL.pl lamiids.embl &gt; lamiids.fasta# 转换格式为fasta，方便后续合并</span><br></pre></td></tr></table></figure><h3 id="4-2-RepeatModeler从头预测"><a href="#4-2-RepeatModeler从头预测" class="headerlink" title="4.2 RepeatModeler从头预测"></a>4.2 RepeatModeler从头预测</h3><p>新建一个目录，用于存放RepeatModeler的预测结果，写一个repeatmodeler.slurm脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 100</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">BuildDatabase -name luobuma -engine ncbi /public/home/wlxie/NextPolish/luobuma_rundir/genome.nextpolish.fasta# 用基因组组装结果构建数据库</span><br><span class="line"></span><br><span class="line">RepeatModeler -pa 25 -database luobuma -engine ncbi# 自训练</span><br></pre></td></tr></table></figure><p>RepeatModeler以自身基因组数据做训练集，用三种重复序列分析软件（ RECON, RepeatScout 和 LtrHarvest&#x2F;Ltr_retriever）进行预测，最后给出de novo预测结果。需要i说明一下，程序结束之后会给出如下四个文件：</p><blockquote><ol><li>sample-families.fa    de novo预测重复序列家族文件，也就是预测的重复序列库</li><li>sample-familes.stk    Seed alignments</li><li>RM_123456.XXXXXXXXX    中间文件（记录每一轮训练的流程和结果，仅用于中间程序崩了以后可以识别并继续跑流程）</li><li>sample-rmod.log    log文件</li></ol></blockquote><p>最终得到的<code>luobuma-families.fa</code>文件是我们需要的，里面记录了各种de novo预测的重复序列家族。中间文件具体有什么可以参考<a href="https://github.com/Dfam-consortium/RepeatModeler">官方的github文档</a>，这里仅仅是起到Recover from a failure的作用，<strong>中间程序没有崩就不用管它</strong>。</p><p>注意下<code>RepeatModeler -pa</code>参数，1 pa可以运行4个线程，我申请了100个核，这里就是25 pa可以用完所有资源。</p><p>这一步运行时间最久，100个核对200Mbp大小的植物基因组进行de novo预测重复序列，跑了17个小时。</p><h3 id="4-3-整合数据库"><a href="#4-3-整合数据库" class="headerlink" title="4.3 整合数据库"></a>4.3 整合数据库</h3><p>将4.1、4.2步骤的结果，以及前面做的LTR预测结果进行整合（都是fasta格式）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat lamiids.fasta luobuma-families.fa luobuma.fasta.mod.LTRlib.fa &gt; final_luobuma_repeat.fasta# 合并同源数据库、RepeatModeler训练结果和LTR预测结果</span><br></pre></td></tr></table></figure><p>此时得到的<code>final_luobuma_repeat.fasta</code>就是后一步运行RepeatMarsker需要指定的自建数据库。</p><h3 id="4-4-RepeatMasker搜索重复序列"><a href="#4-4-RepeatMasker搜索重复序列" class="headerlink" title="4.4 RepeatMasker搜索重复序列"></a>4.4 RepeatMasker搜索重复序列</h3><p>根据需求确定参数，写一个repeatmasker.slurm脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 100</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">RepeatMasker -nolow -no_is -pa 25 -lib final_luobuma_repeat.fasta -engine ncbi -gff -norna -dir luobuma /public/home/wlxie/NextPolish/luobuma_rundir/luobuma.fasta </span><br></pre></td></tr></table></figure><p>RepeatMasker的参数非常多，介绍一下这里用到的：</p><blockquote><p>-nolowDoes <strong>not mask</strong> low_complexity DNA or simple repeats 不屏蔽低复杂度DNA或简单重复序列（有的学者认为simple repeat不算严格意义上的重复序列类型）</p><p>-nornaDoes <strong>not mask</strong> small RNA (pseudo) genes 不屏蔽sRNA</p><p>-no_isSkips bacterial insertion element check 跳过细菌插入元件检查</p><p>-pa和RepeatModeler一样，1 pa是4个线程</p><p>-lib指定自建数据库（与-species冲突）</p><p>-gff生成gff文件</p><p>-dir指定输出目录</p></blockquote><p>在输出目录下可以找到以下几种格式的文件:</p><blockquote><p>sample.fasta.cat.gz基因组和数据库中参考重复序列比对详情，i代表碱基转换，v代表碱基颠换</p><p>sample.fasta.masked重复序列屏蔽我iN后的序列</p><p>sample.fasta.out预测的重复序列详细信息，Smith-Waterman 算法得分等等</p><p>sample.fasta.out.gff上一个文件的gff格式</p><p>sample.fasta.tblRepeatMasker的结果报告</p></blockquote><p>主要看一下结果报告：</p><p><img src="https://www.shelven.com/tuchuang/20230316/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230316/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>TE的预测结果被分为逆转录转座子、DNA转座子和Unclassified三类，总的转座子序列数量和在基因组的占比见<code>Total interspersed repeats</code>统计结果。做到这里可以再结合前面做的TR分析，做一个基因组重复序列注释汇总表，我这里就不再演示了。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面我们注释了串联重复序列（Tandem repeat，TR），接下来是对散在重复序列（也称转座子，transposable element，TE）进行注释。注释之后我们对所有重复序列在基因组上进行屏蔽，就可以进行后面的结构基因预测和注释了。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="RepeatModeler" scheme="http://www.shelven.com/tags/RepeatModeler/"/>
    
    <category term="RepeatMasker" scheme="http://www.shelven.com/tags/RepeatMasker/"/>
    
  </entry>
  
  <entry>
    <title>基因组注释（1）——串联重复序列注释</title>
    <link href="http://www.shelven.com/2023/03/12/a.html"/>
    <id>http://www.shelven.com/2023/03/12/a.html</id>
    <published>2023-03-12T15:14:40.000Z</published>
    <updated>2023-03-12T15:18:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本系列笔记开始记录如何对组装的植物基因组进行注释。前面通过一系列组装过程，我们拿到了组装好的基因组草图，而这个基因组草图只是研究的开始，我们关注的是基因组中有哪些我们感兴趣的功能基因或者结构基因，以及怎么用这些基因阐述生物学问题等等，这个时候一个高准确度的基因组注释结果就非常重要了。</p><span id="more"></span><p>基因组注释可以分为两部分：<strong>基因组的结构注释</strong>（重复序列识别、非编码基因预测、编码基因预测）和<strong>基因功能注释</strong>，结构注释是功能注释的基础。</p><p>这里先从结构注释中的重复序列注释开始。我们知道植物基因组多倍化频繁，且基因组中存在大量的重复序列（有的植物基因组中重复序列甚至能达到80%），这些重复序列控制植物表型调控中有非常重要的作用。基因组中的重复序列可以分为以下几种：</p><p><img src="https://www.shelven.com/tuchuang/20230312/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230312/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h2 id="1-串联重复序列注释"><a href="#1-串联重复序列注释" class="headerlink" title="1. 串联重复序列注释"></a>1. 串联重复序列注释</h2><div class="story post-story"><p>串联重复（Tandem Repeat, TR）指DNA中的一个或多个核苷酸前后相连接的重复。串联重复又分为卫星DNA(Satellite DNA)、小卫星（Minisatellite）、微卫星（Microsatellite）。微卫星在植物中一般称为SSR（Simple Sequence Repeats）SSR在植物基因组常被用做遗传标记使用。下面我用两款软件跑下串联重复序列注释。</p><h3 id="1-1-GMATA"><a href="#1-1-GMATA" class="headerlink" title="1.1 GMATA"></a>1.1 GMATA</h3><p>这个软件主要用来搜索重复单元较短的简单重复序列，也就是微卫星SSR序列。这软件运行速度比较快，而且可以同时设计SSR引物，还可以预测elect-PCR结果，或者将预测结果显示在基因组浏览器上，可以在github上找到项目地址：<a href="https://github.com/XuewenWangUGA/GMATA">XuewenWangUGA&#x2F;GMATA: software GMATA (github.com)</a></p><p>需要注意如果是在<strong>linux系统</strong>上跑一键流程的话，<strong>需要单独安装primer3和e-pcr（可以直接用conda安装）</strong>，分别是设计SSR引物和模拟PCR的时候需要调用。如果没有这方面需要，可以在设置文件<code>default_cfg.txt</code>修改为不启用后面的模块。我这里统一用linux系统演示，只演示命令行操作，<strong>这个软件在windows上运行有UI界面</strong>，还是比较直观的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">perl gmata.pl -c default_cfg.txt -i /public/home/wlxie/NextPolish/luobuma_rundir/genome.nextpolish.fasta</span><br></pre></td></tr></table></figure><p>我这里直接用了一键流程，修改默认的设置文件中三个模块<code>[set]:doprimer_smt</code>、<code>[set]:elctPCR</code>和<code>[set]:mk2gff3</code>的<code>ModulRun = N</code>，虽然可以批量设计引物，但是我这里用不着…..</p><p>预测的SSR结果在原fasta文件路径下，以<code>.ssr</code>和<code>.ssr.sat2</code>为后缀：</p><p><img src="https://www.shelven.com/tuchuang/20230312/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230312/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://www.shelven.com/tuchuang/20230312/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230312/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>在sat结果文件中，最终结果以4个表格的方式呈现，分别统计motif k-mer、motif和成对的motif信息以及最后每个contig的SSR统计信息。以上是其中两个表格。</p><h3 id="1-2-TRF"><a href="#1-2-TRF" class="headerlink" title="1.2 TRF"></a>1.2 TRF</h3><p>这个软件和上面软件类似，可以统计整个基因组上的串联重复序列，在上面一个软件输出结果上稍微有些不同。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">trf /public/home/wlxie/NextPolish/luobuma_rundir/genome.nextpolish.fasta 2 7 7 80 10 50 500 -f -d -m -r -h</span><br></pre></td></tr></table></figure><p>说明一下这个软件使用过程中传参的一堆数字代表什么：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Match  = matching weight# 匹配上的权重，缺省值2</span><br><span class="line">Mismatch  = mismatching penalty# 未匹配上的权重，缺省值7</span><br><span class="line">Delta = indel penalty# 插入罚分，缺省值7</span><br><span class="line">PM = match probability (whole number)# 比对上的概率，可选值为80和75</span><br><span class="line">PI = indel probability (whole number)# 插入的概率，可选值为10和20</span><br><span class="line">Minscore = minimum alignment score to report# 串联重复序列的比对必须达到或超过要报告的比对分数</span><br><span class="line">MaxPeriod = maximum period size to report# 最大重复单元的bp数，不指定的话从1到2000</span><br><span class="line"></span><br><span class="line">其他主要可选参数（列一部分）:</span><br><span class="line">-m 输出屏蔽重复序列后的基因组</span><br><span class="line">-f 记录每个重复序列侧翼的500个核苷酸，主要用于PCR引物设计</span><br><span class="line">-d 生成屏蔽数据文件，与汇总表有相同的信息，不包含标签，主要方便做其他处理</span><br><span class="line">-h 不生成html结果文件（contig数量多的话建议使用，否则有大量的文件生成）</span><br></pre></td></tr></table></figure><p>运行结束后可以生成<code>.mask</code>后缀的屏蔽后的序列文件，还有一个<code>.dat</code>后缀的结果文件，包含了重复序列的详细信息。</p><p>主要讲解下这个dat文件，先<code>less -S</code>打开看看：</p><p><img src="https://www.shelven.com/tuchuang/20230312/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230312/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>上面记录的参数和其他信息就不说了，主要是底下的数据，每一行是一个重复序列的信息，每行分为15列：</p><blockquote><p>第1列和第2列是预测到的重复序列的起始和结束位点；</p><p>第3列是重复单元的长度；</p><p>第4列是重复单元的拷贝数，不一定是整数，因为可能存在插入缺失；</p><p>第5列是一致性序列的长度；</p><p>第6列是匹配的百分率；</p><p>第7列是插入缺失的百分率；</p><p>第8列是TRF软件给的分值，越高越可靠；</p><p>第9-12列分别为ACGT碱基的个数；</p><p>第13列表示比对的熵值；</p><p>第14列是一致性序列的具体碱基排列；</p><p>第15列是整个重复序列的具体碱基排列顺序。</p></blockquote><p>对于结果文件的处理有两种方法，一种是将<code>.dat</code>后缀的结果文件转换成标准的<code>.gff3</code>文件格式，然后用bedtools提取trf特征。转化gff的的方法github上有不少开源的项目，这里推荐一个<a href="https://github.com/Adamtaranto/TRF2GFF/">Adamtaranto&#x2F;TRF2GFF: Convert Tandem Repeat Finder dat file output into gff3 format (github.com)</a></p><p>还有一种方法就是自己写个脚本，可以看到同一位点处可能有多条预测的串联重复序列<strong>，也就是说这些串联重复序列之间可能存在交叠，思路是将同一位点预测的重复序列</strong>只保留最短的一条（起始位点相同保留前一条，结束位点相同保留后一条），然后统计第3列重复序列k-mer数量和类型，根据第1列和第2列计算长度，统计总长度和占比即可。</p><p><img src="https://www.shelven.com/tuchuang/20230312/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230312/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">自编TFR dat格式结果文件统计脚本</span></span><br><span class="line"><span class="string">2023.3.12</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据过滤</span></span><br><span class="line">loci_start = []</span><br><span class="line">loci_finish = []</span><br><span class="line">total_line = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./genome.baima.fasta.2.7.7.80.10.50.500.dat&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> <span class="built_in">input</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">input</span>.readlines()[<span class="number">15</span>:]:</span><br><span class="line">        <span class="keyword">if</span> i.find(<span class="string">&#x27;Sequence&#x27;</span>) != -<span class="number">1</span> <span class="keyword">or</span> i.find(<span class="string">&#x27;Parameters&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            lst = i.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(lst) &lt; <span class="number">15</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(loci_start) &lt; <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(loci_finish) &lt; <span class="number">1</span>:    <span class="comment"># 处理列表为空的情况</span></span><br><span class="line">                loci_start.append(lst[<span class="number">0</span>])</span><br><span class="line">                loci_finish.append(lst[<span class="number">1</span>])</span><br><span class="line">                total_line.append(lst)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> lst[<span class="number">0</span>] != loci_start[-<span class="number">1</span>] <span class="keyword">and</span> lst[<span class="number">1</span>] != loci_finish[-<span class="number">1</span>]:  <span class="comment"># 开始结束位点都不同，则记录数据</span></span><br><span class="line">                    loci_start.append(lst[<span class="number">0</span>])</span><br><span class="line">                    loci_finish.append(lst[<span class="number">1</span>])</span><br><span class="line">                    total_line.append(lst)</span><br><span class="line">                <span class="keyword">elif</span> lst[<span class="number">0</span>] == loci_start[-<span class="number">1</span>]:        <span class="comment"># 开始位点相同，跳过</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">elif</span> lst[<span class="number">1</span>] == loci_finish[-<span class="number">1</span>]:       <span class="comment"># 结束位点相同，删除列表最后一个元素并加入新元素</span></span><br><span class="line">                    <span class="keyword">del</span> loci_start[-<span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">del</span> loci_finish[-<span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">del</span> total_line[-<span class="number">1</span>]</span><br><span class="line">                    loci_start.append(lst[<span class="number">0</span>])</span><br><span class="line">                    loci_finish.append(lst[<span class="number">1</span>])</span><br><span class="line">                    total_line.append(lst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取motif长度和重复序列长度</span></span><br><span class="line">motif_lst = []</span><br><span class="line">leng_lst = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> total_line:</span><br><span class="line">    motif_lst.append(i[<span class="number">2</span>])</span><br><span class="line">    leng = <span class="built_in">int</span>(i[<span class="number">1</span>]) - <span class="built_in">int</span>(i[<span class="number">0</span>]) + <span class="number">1</span></span><br><span class="line">    leng_lst.append(leng)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计相同motif的总长度和所有重复序列总长度</span></span><br><span class="line">total_leng = &#123;&#125;</span><br><span class="line">motif_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(motif_lst)):</span><br><span class="line">    item = motif_lst[i]</span><br><span class="line">    motif_sum += leng_lst[i]</span><br><span class="line">    <span class="keyword">if</span> item <span class="keyword">in</span> total_leng:</span><br><span class="line">        total_leng[item] += leng_lst[i]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        total_leng[item] = leng_lst[i]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计motif-mer数量，总数，占比</span></span><br><span class="line">count_motif = Counter(motif_lst)</span><br><span class="line">count_lst = <span class="built_in">list</span>(count_motif.items())</span><br><span class="line">count_lst.sort(key = <span class="keyword">lambda</span> x : x[<span class="number">1</span>], reverse = <span class="literal">True</span>)</span><br><span class="line">lst_ = []</span><br><span class="line">hit_num = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> count_lst:</span><br><span class="line">    hit_num += i[<span class="number">1</span>] </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> count_lst:</span><br><span class="line">    ls = i[<span class="number">0</span>]</span><br><span class="line">    lst1 = <span class="built_in">list</span>(i)</span><br><span class="line">    <span class="keyword">if</span> ls <span class="keyword">in</span> total_leng:</span><br><span class="line">        lst1.append(total_leng[ls])</span><br><span class="line">    precentage = <span class="string">&#x27;%.2f%%&#x27;</span>%(<span class="number">100</span> * i[<span class="number">1</span>] / hit_num)</span><br><span class="line">    lst1.append(precentage)</span><br><span class="line">    lst_.append(lst1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计结果过滤（取前二十）</span></span><br><span class="line">lst_filted = []</span><br><span class="line">hit_ = <span class="number">0</span></span><br><span class="line">motif_ = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">20</span>):</span><br><span class="line">    lst_filted.append(lst_[i])</span><br><span class="line">    hit_ += lst_[i][<span class="number">1</span>]</span><br><span class="line">    motif_ += lst_[i][<span class="number">2</span>]</span><br><span class="line">lst_filted.append([<span class="string">&#x27;Other&#x27;</span>, <span class="built_in">int</span>(hit_num - hit_), <span class="built_in">int</span>(motif_sum - motif_), <span class="string">&#x27;%.2f%%&#x27;</span>%(<span class="number">100</span> - <span class="number">100</span> * hit_ / hit_num)])</span><br><span class="line">lst_filted.append([<span class="string">&#x27;Total&#x27;</span>, <span class="built_in">int</span>(hit_num), <span class="built_in">int</span>(motif_sum), <span class="string">&#x27;100%&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./stastics.xls&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> output:</span><br><span class="line">    output.write(<span class="string">&#x27;Motif(-mer)\tNumber\tLength(bp)\tPrecentage\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> lst_filted:</span><br><span class="line">        motif = i[<span class="number">0</span>]</span><br><span class="line">        number = i[<span class="number">1</span>]</span><br><span class="line">        length = i[<span class="number">2</span>]</span><br><span class="line">        pre = i[<span class="number">3</span>]</span><br><span class="line">        output.write(motif + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(number) + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(length) + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(pre) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>**写的有点冗长，能实现统计功能就行…..**实现的结果如下：</p><p><img src="https://www.shelven.com/tuchuang/20230312/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230312/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>可以看到两个软件统计结果还是有比较大的出入的，<strong>可能是在算法上有不同</strong>。在单独分析SSR序列的时候还是用GMATA准确一些，如果是统计全基因组上的串联重复序列则使用老牌的TRF更为合适。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;本系列笔记开始记录如何对组装的植物基因组进行注释。前面通过一系列组装过程，我们拿到了组装好的基因组草图，而这个基因组草图只是研究的开始，我们关注的是基因组中有哪些我们感兴趣的功能基因或者结构基因，以及怎么用这些基因阐述生物学问题等等，这个时候一个高准确度的基因组注释结果就非常重要了。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="GMATA" scheme="http://www.shelven.com/tags/GMATA/"/>
    
    <category term="TRF" scheme="http://www.shelven.com/tags/TRF/"/>
    
  </entry>
  
  <entry>
    <title>绕过双重封锁部署ChatGPT到zhenxun_bot</title>
    <link href="http://www.shelven.com/2023/03/08/a.html"/>
    <id>http://www.shelven.com/2023/03/08/a.html</id>
    <published>2023-03-08T13:54:56.000Z</published>
    <updated>2023-03-08T14:01:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>作为一个从ChatGPT公测用到现在的用户，有些无奈很难言说。本来OpenAI就不对咱们这个区域开放，使用官方的API搭建应用可以不借助VPN访问，算是解除了区域限制。但是，从<strong>2023年3月2日傍晚</strong>开始，API接口就开始没有响应了，官网没有问题，四处查询发现可能是API的域名上了GFW名单（暂不确定，有可能重大会议过去后会恢复？）。</p><span id="more"></span><p>因此，现在摆在眼前的问题是如何绕过双重封锁调用OpenAI的API接口？最稳妥的方式当然是给服务器挂个全局代理，但是我的服务器本身就在作代理服务器，给服务器再上个代理会比较麻烦……这里记录下自己实现的方式，顺便记录下是如何部署ChatGPT到zhenxun_bot（这个bot真的超级好用！）上的。</p><p>本人在这方面是小白，只是记录实现过程。</p><p><strong>此部分内容需要以部署zhenxun_bot为前提、有一个未上GFW名单的域名（国内需要实名）</strong>。</p><h2 id="1-部署ChatGPT到zhenxun-bot"><a href="#1-部署ChatGPT到zhenxun-bot" class="headerlink" title="1. 部署ChatGPT到zhenxun_bot"></a>1. 部署ChatGPT到zhenxun_bot</h2><div class="story post-story"><p>时间过去太久，已经找不到写插件的原作者了…我是在原插件的基础上copy和修改了一部分代码，实际上就是在zhenxun_bot的AI插件基础上做的一点删改（可能有些没删干净，懒得查了）。如果没有修改路径的话，原文件路径是<code>/zhenxun_bot/plugins/ai/data_source.py</code>，下面代码替代原文件内容（原文件最好另存以防万一）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> utils.http_utils <span class="keyword">import</span> AsyncHttpx</span><br><span class="line"><span class="keyword">from</span> configs.path_config <span class="keyword">import</span> IMAGE_PATH, DATA_PATH</span><br><span class="line"><span class="keyword">from</span> services.log <span class="keyword">import</span> logger</span><br><span class="line"><span class="keyword">from</span> utils.message_builder <span class="keyword">import</span> image, face</span><br><span class="line"><span class="keyword">from</span> configs.config <span class="keyword">import</span> Config, NICKNAME</span><br><span class="line"><span class="keyword">from</span> .utils <span class="keyword">import</span> ai_message_manager</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2TokenizerFast</span><br><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"></span><br><span class="line">openai.api_key = <span class="string">&quot;xxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> ujson <span class="keyword">as</span> json</span><br><span class="line"><span class="keyword">except</span> ModuleNotFoundError:</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">session_config = &#123;</span><br><span class="line">    <span class="string">&#x27;preset&#x27;</span>: <span class="string">&#x27;你是一个大型语言模型，可以回答我的问题。如果我有任何问题，请随时告诉你，你会尽力为我解答。&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;context&#x27;</span>: <span class="string">&#x27;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">sessions = &#123;&#125;</span><br><span class="line">tokenizer = GPT2TokenizerFast.from_pretrained(<span class="string">&quot;gpt2-large&quot;</span>)</span><br><span class="line">check_url = <span class="string">&quot;https://v2.alapi.cn/api/censor/text&quot;</span></span><br><span class="line">index = <span class="number">0</span></span><br><span class="line">anime_data = json.load(<span class="built_in">open</span>(DATA_PATH / <span class="string">&quot;anime.json&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取对话session</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_chat_session</span>(<span class="params">sessionid</span>):</span><br><span class="line">    <span class="keyword">if</span> sessionid <span class="keyword">not</span> <span class="keyword">in</span> sessions:</span><br><span class="line">        config = deepcopy(session_config)</span><br><span class="line">        config[<span class="string">&#x27;id&#x27;</span>] = sessionid</span><br><span class="line">        sessions[sessionid] = config</span><br><span class="line">    <span class="keyword">return</span> sessions[sessionid]</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat_with_gpt</span>(<span class="params">prompt</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        resp = openai.Completion.create(</span><br><span class="line">            model = <span class="string">&quot;text-davinci-003&quot;</span>, </span><br><span class="line">            temperature = <span class="number">0.9</span>,</span><br><span class="line">            max_tokens=<span class="number">3000</span>,</span><br><span class="line">            top_p=<span class="number">1</span>,</span><br><span class="line">            presence_penalty=<span class="number">0</span>,</span><br><span class="line">            frequency_penalty=<span class="number">0</span>,</span><br><span class="line">            prompt=prompt)</span><br><span class="line">        resp = resp[<span class="string">&#x27;choices&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">    <span class="keyword">except</span> openai.OpenAIError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;openai 接口报错: &#x27;</span> + <span class="built_in">str</span>(e))</span><br><span class="line">        resp = <span class="built_in">str</span>(e)</span><br><span class="line">    <span class="keyword">return</span> resp</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_chat_result</span>(<span class="params">text: <span class="built_in">str</span>, img_url: <span class="built_in">str</span>, user_id: <span class="built_in">int</span>, nickname: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取 AI 返回值，顺序： 特殊回复 -&gt; GPT3 -&gt; 青云客</span></span><br><span class="line"><span class="string">    :param text: 问题</span></span><br><span class="line"><span class="string">    :param img_url: 图片链接</span></span><br><span class="line"><span class="string">    :param user_id: 用户id</span></span><br><span class="line"><span class="string">    :param nickname: 用户昵称</span></span><br><span class="line"><span class="string">    :return: 回答</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">global</span> index</span><br><span class="line">    ai_message_manager.add_message(user_id, text)</span><br><span class="line">    special_rst = <span class="keyword">await</span> ai_message_manager.get_result(user_id, nickname)</span><br><span class="line">    <span class="keyword">if</span> special_rst:</span><br><span class="line">        ai_message_manager.add_result(user_id, special_rst)</span><br><span class="line">        <span class="keyword">return</span> special_rst</span><br><span class="line">    <span class="keyword">if</span> index == <span class="number">5</span>:</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(text) &lt; <span class="number">6</span> <span class="keyword">and</span> random.random() &lt; <span class="number">0.6</span>:</span><br><span class="line">        keys = anime_data.keys()</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> keys:</span><br><span class="line">            <span class="keyword">if</span> text.find(key) != -<span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> random.choice(anime_data[key]).replace(<span class="string">&quot;你&quot;</span>, nickname)</span><br><span class="line">    rst = <span class="keyword">await</span> GPT_3(text, user_id)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> rst:</span><br><span class="line">        rst = <span class="keyword">await</span> xie_ai(text)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> rst:</span><br><span class="line">        <span class="keyword">return</span> no_result()</span><br><span class="line">    <span class="keyword">if</span> nickname:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nickname) &lt; <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">if</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">                nickname = <span class="string">&quot;~&quot;</span>.join(nickname) + <span class="string">&quot;~&quot;</span></span><br><span class="line">                <span class="keyword">if</span> random.random() &lt; <span class="number">0.2</span>:</span><br><span class="line">                    <span class="keyword">if</span> nickname.find(<span class="string">&quot;大人&quot;</span>) == -<span class="number">1</span>:</span><br><span class="line">                        nickname += <span class="string">&quot;大~人~&quot;</span></span><br><span class="line">        rst = <span class="built_in">str</span>(rst).replace(<span class="string">&quot;小主人&quot;</span>, nickname).replace(<span class="string">&quot;小朋友&quot;</span>, nickname)</span><br><span class="line">    ai_message_manager.add_result(user_id, rst)</span><br><span class="line">    <span class="keyword">return</span> rst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># GPT3接口</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">GPT_3</span>(<span class="params">msg: <span class="built_in">str</span>, sessionid: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取GPT3接口的回复</span></span><br><span class="line"><span class="string">    指令如下(群内需@机器人)：1.[重置会话] 请发送 重置会话2.[设置人格] 请发送 设置人格+人格描述3.[重置人格] 请发送 重置人格。</span></span><br><span class="line"><span class="string">    注意：重置会话不会清空人格,重置人格会重置会话!设置人格后人格将一直存在，除非重置人格或重启逻辑端!</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> msg.strip() == <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;您好，我是人工智能助手，如果您有任何问题，请随时告诉我，我将尽力回答。\n如果您需要重置我们的会话，请回复`重置会话`&#x27;</span></span><br><span class="line">        <span class="comment"># 获得对话session</span></span><br><span class="line">        session = get_chat_session(sessionid)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;重置会话&#x27;</span> == msg.strip():</span><br><span class="line">            session[<span class="string">&#x27;context&#x27;</span>] = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;会话已重置&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;重置人格&#x27;</span> == msg.strip():</span><br><span class="line">            session[<span class="string">&#x27;context&#x27;</span>] = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            session[<span class="string">&#x27;preset&#x27;</span>] = session_config[<span class="string">&#x27;preset&#x27;</span>]</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;人格已重置&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> msg.strip().startswith(<span class="string">&#x27;设置人格&#x27;</span>):</span><br><span class="line">            session[<span class="string">&#x27;preset&#x27;</span>] = msg.strip().replace(<span class="string">&#x27;设置人格&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            session[<span class="string">&#x27;context&#x27;</span>] = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 处理上下文逻辑</span></span><br><span class="line">        token_limit = <span class="number">4096</span> - <span class="number">3000</span> - <span class="built_in">len</span>(tokenizer.encode(session[<span class="string">&#x27;preset&#x27;</span>])) - <span class="number">3</span></span><br><span class="line">        session[<span class="string">&#x27;context&#x27;</span>] = session[<span class="string">&#x27;context&#x27;</span>] + <span class="string">&quot;\n\nQ:&quot;</span> + msg + <span class="string">&quot;\nA:&quot;</span></span><br><span class="line">        ids = tokenizer.encode(session[<span class="string">&#x27;context&#x27;</span>])</span><br><span class="line">        tokens = tokenizer.decode(ids[-token_limit:])</span><br><span class="line">        <span class="comment"># 计算可发送的字符数量</span></span><br><span class="line">        char_limit = <span class="built_in">len</span>(<span class="string">&#x27;&#x27;</span>.join(tokens))</span><br><span class="line">        session[<span class="string">&#x27;context&#x27;</span>] = session[<span class="string">&#x27;context&#x27;</span>][-char_limit:]</span><br><span class="line">        <span class="comment"># 从最早的提问开始截取</span></span><br><span class="line">        pos = session[<span class="string">&#x27;context&#x27;</span>].find(<span class="string">&#x27;Q:&#x27;</span>)</span><br><span class="line">        session[<span class="string">&#x27;context&#x27;</span>] = session[<span class="string">&#x27;context&#x27;</span>][pos:]</span><br><span class="line">        <span class="comment"># 设置预设</span></span><br><span class="line">        msg = session[<span class="string">&#x27;preset&#x27;</span>] + <span class="string">&#x27;\n\n&#x27;</span> + session[<span class="string">&#x27;context&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(msg)</span><br><span class="line">        <span class="comment"># 与ChatGPT交互获得对话内容</span></span><br><span class="line">        message = chat_with_gpt(msg)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;会话ID: &quot;</span> + <span class="built_in">str</span>(sessionid))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;ChatGPT返回内容: &quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(message)</span><br><span class="line">        <span class="keyword">return</span> message </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">        traceback.print_exc()</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(<span class="string">&#x27;异常: &#x27;</span> + <span class="built_in">str</span>(error)) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 屑 AI</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">xie_ai</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取青云客回复</span></span><br><span class="line"><span class="string">    :param text: 问题</span></span><br><span class="line"><span class="string">    :return: 青云可回复</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    res = <span class="keyword">await</span> AsyncHttpx.get(<span class="string">f&quot;http://api.qingyunke.com/api.php?key=free&amp;appid=0&amp;msg=<span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line">    content = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        data = json.loads(res.text)</span><br><span class="line">        <span class="keyword">if</span> data[<span class="string">&quot;result&quot;</span>] == <span class="number">0</span>:</span><br><span class="line">            content = data[<span class="string">&quot;content&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;菲菲&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.replace(<span class="string">&quot;菲菲&quot;</span>, NICKNAME)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;艳儿&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.replace(<span class="string">&quot;艳儿&quot;</span>, NICKNAME)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;公众号&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;&#123;br&#125;&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.replace(<span class="string">&quot;&#123;br&#125;&quot;</span>, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;提示&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content[: content.find(<span class="string">&quot;提示&quot;</span>)]</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;淘宝&quot;</span> <span class="keyword">in</span> content <span class="keyword">or</span> <span class="string">&quot;taobao.com&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                r = re.search(<span class="string">&quot;&#123;face:(.*)&#125;&quot;</span>, content)</span><br><span class="line">                <span class="keyword">if</span> r:</span><br><span class="line">                    id_ = r.group(<span class="number">1</span>)</span><br><span class="line">                    content = content.replace(</span><br><span class="line">                        <span class="string">&quot;&#123;&quot;</span> + <span class="string">f&quot;face:<span class="subst">&#123;id_&#125;</span>&quot;</span> + <span class="string">&quot;&#125;&quot;</span>, <span class="built_in">str</span>(face(<span class="built_in">int</span>(id_)))</span><br><span class="line">                    )</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            content</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> content <span class="keyword">and</span> <span class="keyword">not</span> Config.get_config(<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;ALAPI_AI_CHECK&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">await</span> check_text(content)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;Ai xie_ai 发生错误 <span class="subst">&#123;<span class="built_in">type</span>(e)&#125;</span>：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello</span>() -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    一些打招呼的内容</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = random.choice(</span><br><span class="line">        (</span><br><span class="line">            <span class="string">&quot;哦豁？！&quot;</span>,</span><br><span class="line">            <span class="string">&quot;你好！Ov&lt;&quot;</span>,</span><br><span class="line">            <span class="string">f&quot;库库库，呼唤<span class="subst">&#123;NICKNAME&#125;</span>做什么呢&quot;</span>,</span><br><span class="line">            <span class="string">&quot;我在呢！&quot;</span>,</span><br><span class="line">            <span class="string">&quot;呼呼，叫俺干嘛&quot;</span>,</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    img = random.choice(os.listdir(IMAGE_PATH / <span class="string">&quot;zai&quot;</span>))</span><br><span class="line">    <span class="keyword">if</span> img[-<span class="number">4</span>:] == <span class="string">&quot;.gif&quot;</span>:</span><br><span class="line">        result += image(img, <span class="string">&quot;zai&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result += image(img, <span class="string">&quot;zai&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没有回答时回复内容</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">no_result</span>() -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    没有回答时的回复</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        random.choice(</span><br><span class="line">            [</span><br><span class="line">                <span class="string">&quot;你在说啥子？&quot;</span>,</span><br><span class="line">                <span class="string">f&quot;纯洁的<span class="subst">&#123;NICKNAME&#125;</span>没听懂&quot;</span>,</span><br><span class="line">                <span class="string">&quot;下次再告诉你(下次一定)&quot;</span>,</span><br><span class="line">                <span class="string">&quot;你觉得我听懂了吗？嗯？&quot;</span>,</span><br><span class="line">                <span class="string">&quot;我！不！知！道！&quot;</span>,</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        + image(random.choice(os.listdir(IMAGE_PATH / <span class="string">&quot;noresult&quot;</span>)), <span class="string">&quot;noresult&quot;</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">check_text</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ALAPI文本检测，主要针对青云客API，检测为恶俗文本改为无回复的回答</span></span><br><span class="line"><span class="string">    :param text: 回复</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> Config.get_config(<span class="string">&quot;alapi&quot;</span>, <span class="string">&quot;ALAPI_TOKEN&quot;</span>):</span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line">    params = &#123;<span class="string">&quot;token&quot;</span>: Config.get_config(<span class="string">&quot;alapi&quot;</span>, <span class="string">&quot;ALAPI_TOKEN&quot;</span>), <span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        data = (<span class="keyword">await</span> AsyncHttpx.get(check_url, timeout=<span class="number">2</span>, params=params)).json()</span><br><span class="line">        <span class="keyword">if</span> data[<span class="string">&quot;code&quot;</span>] == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">if</span> data[<span class="string">&quot;data&quot;</span>][<span class="string">&quot;conclusion_type&quot;</span>] == <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;检测违规文本错误...<span class="subst">&#123;<span class="built_in">type</span>(e)&#125;</span>：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong><code>openai.api_key</code>需要上官网获取后填入</strong></p><p>实际上就是把原来的图灵接口替换成GPT3接口。引入openai库和transformers库，使用了前者的<code>openai.Completion.create()</code>方法和后者<code>GPT2TokenizerFast.from_pretrained()</code>预训练的GPT2模型和分词器。</p><p>关键在于前者，因为OpenAI的API网站已经上了GFW名单，所以我们现在就算有api_key也无法调用API接口（会显示超时）。以下是解决方法。</p></div><h2 id="2-托管域名到CLOUDFLARE"><a href="#2-托管域名到CLOUDFLARE" class="headerlink" title="2. 托管域名到CLOUDFLARE"></a>2. 托管域名到CLOUDFLARE</h2><div class="story post-story"><p>后面我们要用到CLOUDFLARE，没有账户的话注册一个：<a href="https://dash.cloudflare.com/">https://dash.cloudflare.com/</a></p><p>注册之后点击右边的<code>Websites</code>，按照操作流程添加主域名，修改两个DNS服务器名字。</p><p><img src="https://www.shelven.com/tuchuang/20230308/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230308/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>比如我这里用阿里云买了一个域名，需要登录阿里云的域名控制台，点击管理，进入右边DNS修改页面</p><p><img src="https://www.shelven.com/tuchuang/20230308/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230308/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>修改原来默认的DNS服务器为<code>lorna.ns.cloudflare.com</code>和<code>ram.ns.cloudflare.com</code>。</p><p>中间可能还需要你邮件确认，按照提示操作就可以。</p></div><h2 id="3-创建CLOUDFLARE-Workers"><a href="#3-创建CLOUDFLARE-Workers" class="headerlink" title="3. 创建CLOUDFLARE Workers"></a>3. 创建CLOUDFLARE Workers</h2><div class="story post-story"><p>该步骤参考来自<a href="https://github.com/noobnooc/noobnooc/discussions/9">github [noobnooc]</a>，感谢大佬提供的解决方案！</p><p>回到CLOUDFLARE，点击右边的创建Workers——Create a Service，这里直接确认创建一个服务。</p><p><img src="https://www.shelven.com/tuchuang/20230308/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230308/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>创建之后点击<code>Quick edit</code>修改workers代码如下（<strong>起到代理api.openai.com的作用</strong>）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line">// Website you intended to retrieve <span class="keyword">for</span> users.</span><br><span class="line">const upstream = <span class="string">&#x27;api.openai.com&#x27;</span></span><br><span class="line"></span><br><span class="line">// Custom pathname <span class="keyword">for</span> the upstream website.</span><br><span class="line">const upstream_path = <span class="string">&#x27;/&#x27;</span></span><br><span class="line"></span><br><span class="line">// Website you intended to retrieve <span class="keyword">for</span> users using mobile devices.</span><br><span class="line">const upstream_mobile = upstream</span><br><span class="line"></span><br><span class="line">// Countries <span class="keyword">and</span> regions where you wish to suspend your service.</span><br><span class="line">const blocked_region = []</span><br><span class="line"></span><br><span class="line">// IP addresses which you wish to block <span class="keyword">from</span> using your service.</span><br><span class="line">const blocked_ip_address = [<span class="string">&#x27;0.0.0.0&#x27;</span>, <span class="string">&#x27;127.0.0.1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">// Whether to use HTTPS protocol <span class="keyword">for</span> upstream address.</span><br><span class="line">const https = true</span><br><span class="line"></span><br><span class="line">// Whether to disable cache.</span><br><span class="line">const disable_cache = false</span><br><span class="line"></span><br><span class="line">// Replace texts.</span><br><span class="line">const replace_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;$upstream&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">addEventListener(<span class="string">&#x27;fetch&#x27;</span>, event =&gt; &#123;</span><br><span class="line">    event.respondWith(fetchAndApply(event.request));</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> function fetchAndApply(request) &#123;</span><br><span class="line">    const region = request.headers.get(<span class="string">&#x27;cf-ipcountry&#x27;</span>).toUpperCase();</span><br><span class="line">    const ip_address = request.headers.get(<span class="string">&#x27;cf-connecting-ip&#x27;</span>);</span><br><span class="line">    const user_agent = request.headers.get(<span class="string">&#x27;user-agent&#x27;</span>);</span><br><span class="line"></span><br><span class="line">    let response = null;</span><br><span class="line">    let url = new URL(request.url);</span><br><span class="line">    let url_hostname = url.hostname;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (https == true) &#123;</span><br><span class="line">        url.protocol = <span class="string">&#x27;https:&#x27;</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        url.protocol = <span class="string">&#x27;http:&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">await</span> device_status(user_agent)) &#123;</span><br><span class="line">        var upstream_domain = upstream;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        var upstream_domain = upstream_mobile;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    url.host = upstream_domain;</span><br><span class="line">    <span class="keyword">if</span> (url.pathname == <span class="string">&#x27;/&#x27;</span>) &#123;</span><br><span class="line">        url.pathname = upstream_path;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        url.pathname = upstream_path + url.pathname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (blocked_region.includes(region)) &#123;</span><br><span class="line">        response = new Response(<span class="string">&#x27;Access denied: WorkersProxy is not available in your region yet.&#x27;</span>, &#123;</span><br><span class="line">            status: <span class="number">403</span></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (blocked_ip_address.includes(ip_address)) &#123;</span><br><span class="line">        response = new Response(<span class="string">&#x27;Access denied: Your IP address is blocked by WorkersProxy.&#x27;</span>, &#123;</span><br><span class="line">            status: <span class="number">403</span></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        let method = request.method;</span><br><span class="line">        let request_headers = request.headers;</span><br><span class="line">        let new_request_headers = new Headers(request_headers);</span><br><span class="line"></span><br><span class="line">        new_request_headers.<span class="built_in">set</span>(<span class="string">&#x27;Host&#x27;</span>, upstream_domain);</span><br><span class="line">        new_request_headers.<span class="built_in">set</span>(<span class="string">&#x27;Referer&#x27;</span>, url.protocol + <span class="string">&#x27;//&#x27;</span> + url_hostname);</span><br><span class="line"></span><br><span class="line">        let original_response = <span class="keyword">await</span> fetch(url.href, &#123;</span><br><span class="line">            method: method,</span><br><span class="line">            headers: new_request_headers,</span><br><span class="line">            body: request.body</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        connection_upgrade = new_request_headers.get(<span class="string">&quot;Upgrade&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (connection_upgrade &amp;&amp; connection_upgrade.toLowerCase() == <span class="string">&quot;websocket&quot;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> original_response;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        let original_response_clone = original_response.clone();</span><br><span class="line">        let original_text = null;</span><br><span class="line">        let response_headers = original_response.headers;</span><br><span class="line">        let new_response_headers = new Headers(response_headers);</span><br><span class="line">        let status = original_response.status;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (disable_cache) &#123;</span><br><span class="line">new_response_headers.<span class="built_in">set</span>(<span class="string">&#x27;Cache-Control&#x27;</span>, <span class="string">&#x27;no-store&#x27;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">        new_response_headers.<span class="built_in">set</span>(<span class="string">&#x27;access-control-allow-origin&#x27;</span>, <span class="string">&#x27;*&#x27;</span>);</span><br><span class="line">        new_response_headers.<span class="built_in">set</span>(<span class="string">&#x27;access-control-allow-credentials&#x27;</span>, true);</span><br><span class="line">        new_response_headers.delete(<span class="string">&#x27;content-security-policy&#x27;</span>);</span><br><span class="line">        new_response_headers.delete(<span class="string">&#x27;content-security-policy-report-only&#x27;</span>);</span><br><span class="line">        new_response_headers.delete(<span class="string">&#x27;clear-site-data&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (new_response_headers.get(<span class="string">&quot;x-pjax-url&quot;</span>)) &#123;</span><br><span class="line">            new_response_headers.<span class="built_in">set</span>(<span class="string">&quot;x-pjax-url&quot;</span>, response_headers.get(<span class="string">&quot;x-pjax-url&quot;</span>).replace(<span class="string">&quot;//&quot;</span> + upstream_domain, <span class="string">&quot;//&quot;</span> + url_hostname));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        const content_type = new_response_headers.get(<span class="string">&#x27;content-type&#x27;</span>);</span><br><span class="line">        <span class="keyword">if</span> (content_type != null &amp;&amp; content_type.includes(<span class="string">&#x27;text/html&#x27;</span>) &amp;&amp; content_type.includes(<span class="string">&#x27;UTF-8&#x27;</span>)) &#123;</span><br><span class="line">            original_text = <span class="keyword">await</span> replace_response_text(original_response_clone, upstream_domain, url_hostname);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            original_text = original_response_clone.body</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        response = new Response(original_text, &#123;</span><br><span class="line">            status,</span><br><span class="line">            headers: new_response_headers</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> function replace_response_text(response, upstream_domain, host_name) &#123;</span><br><span class="line">    let text = <span class="keyword">await</span> response.text()</span><br><span class="line"></span><br><span class="line">    var i, j;</span><br><span class="line">    <span class="keyword">for</span> (i <span class="keyword">in</span> replace_dict) &#123;</span><br><span class="line">        j = replace_dict[i]</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="string">&#x27;$upstream&#x27;</span>) &#123;</span><br><span class="line">            i = upstream_domain</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (i == <span class="string">&#x27;$custom_domain&#x27;</span>) &#123;</span><br><span class="line">            i = host_name</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (j == <span class="string">&#x27;$upstream&#x27;</span>) &#123;</span><br><span class="line">            j = upstream_domain</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (j == <span class="string">&#x27;$custom_domain&#x27;</span>) &#123;</span><br><span class="line">            j = host_name</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        let re = new RegExp(i, <span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">        text = text.replace(re, j);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> text;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> function device_status(user_agent_info) &#123;</span><br><span class="line">    var agents = [<span class="string">&quot;Android&quot;</span>, <span class="string">&quot;iPhone&quot;</span>, <span class="string">&quot;SymbianOS&quot;</span>, <span class="string">&quot;Windows Phone&quot;</span>, <span class="string">&quot;iPad&quot;</span>, <span class="string">&quot;iPod&quot;</span>];</span><br><span class="line">    var flag = true;</span><br><span class="line">    <span class="keyword">for</span> (var v = <span class="number">0</span>; v &lt; agents.length; v++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (user_agent_info.indexOf(agents[v]) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            flag = false;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> flag;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改之后点击右下角<code>Save and deploy</code>，此时worker地址还不能直接代替openai的API地址，需要进一步绑定前面的域名（CLOUDFLARE Workers只能绑定托管到CLOUDFLARE的域名，所以有了前面一步）。</p></div><h2 id="4-绑定域名"><a href="#4-绑定域名" class="headerlink" title="4. 绑定域名"></a>4. 绑定域名</h2><div class="story post-story"><p>点击Workers进入管理页面，点击<code>Triggers</code>——<code>Add Custom Domain</code>，将前面托管的域名填进去，可以用自己喜欢的二级域名：</p><p><img src="https://www.shelven.com/tuchuang/20230308/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230308/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>大约过几分钟，custom domains显示Certificate 为 <code>Activate</code>即可。</p><p>这个时候就可以通过你绑定的域名来访问<code>api.openai.com</code>了，可以通过其他POST工具调试接口，就不多说了。</p></div><h2 id="5-修改openai库"><a href="#5-修改openai库" class="headerlink" title="5. 修改openai库"></a>5. 修改openai库</h2><div class="story post-story"><p>前面做的一系列步骤是让你可以通过其他域名访问openai的API网站，但是前面第一步写的插件调用了<code>openai.Completion.create()</code>方法函数，此时仍然会直接访问api.openai.com，这个时候就是扒源代码修改了。</p><p><code>locate openai</code>先找到服务器上openai下载的位置，在对应的路径修改，比如我的文件路径是<code>/root/anaconda3/lib/python3.9/site-packages/openai</code>，修改该路径下的__init__.py文件：</p><p><img src="https://www.shelven.com/tuchuang/20230308/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230308/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>第34行<code>api_base</code>后面的网址<strong>改为刚刚绑定的网址</strong>（&#x2F;v1的部分不要动）。</p><p>上述步骤完成后，重启zhenxun_bot就可以在<strong>不对自己服务器做任何代理的情况下正常调用OpenAI的API接口了</strong>。</p><p><img src="https://www.shelven.com/tuchuang/20230308/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230308/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>顺便说一下，2022年12月申请的openAI账号每个账户有18美元的额度，现在（2023年3月）申请的账号就只有5美元额度了，emmmmmmm…</p><p>不过上面的那个插件用的是<code>text-davinci-003</code>模型，和ChatGPT用的模型稍有不同，就在前几天ChatGPT公开了API，所使用的模型为<code>gpt-3.5-turbo</code>。并且我前面用的方法是<a href="https://platform.openai.com/docs/api-reference/completions/create">Create completion</a>，和ChatGPT创建实例的方法<a href="https://platform.openai.com/docs/api-reference/chat/create">Create chat completion</a>是不同的，且收费也不一样，现在ChatGPT API收费标准是0.002美元&#x2F;1000 tokens，token数和字数是不一样的，要看分词器怎么分，不过现在API输出上限均为4096 token。有空再更新一下模型方法，这里只是做个记录。</p><p>详细的API调用方法需要参考官网<a href="https://platform.openai.com/docs/api-reference/chat/create">API Reference - OpenAI API</a></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个从ChatGPT公测用到现在的用户，有些无奈很难言说。本来OpenAI就不对咱们这个区域开放，使用官方的API搭建应用可以不借助VPN访问，算是解除了区域限制。但是，从&lt;strong&gt;2023年3月2日傍晚&lt;/strong&gt;开始，API接口就开始没有响应了，官网没有问题，四处查询发现可能是API的域名上了GFW名单（暂不确定，有可能重大会议过去后会恢复？）。&lt;/p&gt;</summary>
    
    
    
    <category term="网络相关" scheme="http://www.shelven.com/categories/%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3/"/>
    
    <category term="QQ机器人" scheme="http://www.shelven.com/categories/QQ%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
    
    <category term="ChatGPT" scheme="http://www.shelven.com/tags/ChatGPT/"/>
    
  </entry>
  
  <entry>
    <title>0基础学习三代基因组测序组装（9）——GATK检测植物基因组SNP和INDEL变异</title>
    <link href="http://www.shelven.com/2023/03/07/a.html"/>
    <id>http://www.shelven.com/2023/03/07/a.html</id>
    <published>2023-03-07T09:53:32.000Z</published>
    <updated>2023-03-07T09:56:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>基因组组装完成之后，我们就可以对基因组进行变异分析了。这里主要介绍由 <a href="http://www.broadinstitute.org/">Broad Institute</a>开发的一款基因组分析工具GATK，这款工具设计之初是用于处理分析Illumina二代测序技术产生的人类全外显子和全基因组数据，经过多个版本的优化迭代，GATK集合了多种高通量测序数据处理和质控的软件，如今GATK可以说是对DNA和RNA-seq数据检测SNP和Indel的标准。</p><span id="more"></span><h2 id="1-GATK安装"><a href="#1-GATK安装" class="headerlink" title="1. GATK安装"></a>1. GATK安装</h2><div class="story post-story"><p>GATK的运行依赖于JAVA环境，目前（2023年3月6日）GATK更新到版本4.3.0，可以直接用conda下载。为了避免环境冲突，最好创建一个新环境专门用于GATK和相关变异检测工具运行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create -n GATK</span><br><span class="line">conda install -c bioconda gatk</span><br><span class="line"></span><br><span class="line">conda install bwa-mem2</span><br><span class="line">conda install samtools</span><br></pre></td></tr></table></figure><p>bwa-mem2和samtools用于双端序列比对回基因组，需要单独下载这两个软件，后面再说。</p><p>安装完成之后可以通过<code>gatk --help</code>查看是否正常。</p></div><h2 id="2-流程详解"><a href="#2-流程详解" class="headerlink" title="2. 流程详解"></a>2. 流程详解</h2><div class="story post-story"><p>流程内容主要参考官网<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035535932-Germline-short-variant-discovery-SNPs-Indels-">Best Practices Workflows的文章</a>。</p><p>GATK工具的变异注释主要包括3个部分：<strong>数据预处理（Data Pre-processing）、变异检测（Variant Discovery）和变异优化（Callset Refinement）</strong>。</p><p>以Germline short variant discovery (SNPs + Indels) ，即胚系短变异的发现为例，官网对多个样本（群组数据，Cohort Data）的变异检测分析流程如下：</p><p><img src="https://www.shelven.com/tuchuang/20230306/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>单个样本（Single-Sample Data）的变异检测标准流程如下：</p><p><img src="https://www.shelven.com/tuchuang/20230306/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>分析流程基本类似，以我前面组装的三代<strong>植物</strong>基因组为例跑一下这两个流程，<strong>强调一下我用的是植物基因组，后续无法用Germline的注释数据资源对变异集进行功能注释！</strong>因此这里只跑到变异集过滤的步骤，拿到SNP和INDEL。</p><h3 id="2-1-数据预处理"><a href="#2-1-数据预处理" class="headerlink" title="2.1 数据预处理"></a>2.1 数据预处理</h3><ol><li><strong>构建参考基因组索引</strong>：组装的基因组作为reference参考基因组，首先需要对参考基因组建立索引，方便后续进行比对和对参考基因组进行查询。<strong>注意三个软件的索引文件不同，每个软件都必须建立索引</strong>。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">ref=$1</span><br><span class="line"></span><br><span class="line">bwa-mem2 index $ref</span><br><span class="line">samtools faidx $ref</span><br><span class="line">referencename=`basename $ref | sed  &quot;s/fasta/dict/&quot; `# .fasta文件后缀改为.dict</span><br><span class="line">gatk CreateSequenceDictionary -R $ref -O $referencename </span><br></pre></td></tr></table></figure><ol start="2"><li><strong>fasta文件转化uBAM文件，标记adapter 序列</strong>：组装好的基因组格式是fasta格式，需要转换成uBAM格式（umapped的BAM文件），接着标记illumina二代测序的adapter序列。本质上都是调用了Picard工具，也可以直接用java写脚本。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line"></span><br><span class="line">gatk FastqToSam -F1 raw_fastq/$&#123;sampleName&#125;_1.fq.gz -F2 raw_fastq/$&#123;sampleName&#125;_2.fq.gz -RG $sampleName -SM $sampleName -O ubam/$&#123;sampleName&#125;.bam</span><br><span class="line"></span><br><span class="line">gatk MarkIlluminaAdapters -I ubam/$&#123;sampleName&#125;.bam -O markadapeters/$&#123;sampleName&#125;.markadapeters.bam -M markadapeters/$&#123;sampleName&#125;.metrics.txt</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>标记后的序列转化成fastq格式，回比参考基因组，得到干净的BAM文件</strong>：第二和第三步来自官方的文章<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360039568932--How-to-Map-and-clean-up-short-read-sequence-data-efficiently">(How to) Map and clean up short read sequence data efficiently</a>，通过联合SamToFastq、BWA - MEM和MergeBamAlignment三个程序，节省比对时间，绕过占用空间过大的SAM文件，MergeBamAlignment可以将已排序的SAM中的定义信息（我这里将SAM文件转换成BAM文件）与uBAM中的定义信息进行合并，得到干净的BAM并进行排序和构建索引。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line">threads=50</span><br><span class="line">ref=/public/home/wlxie/biosoft/GATK_file/gatk/ref/luobuma.fasta</span><br><span class="line"></span><br><span class="line">gatk SamToFastq -I markadapeters/$&#123;sampleName&#125;.markadapeters.bam -F  interleaved_fq/$&#123;sampleName&#125;_1.interleaved.fq.gz -F2  interleaved_fq/$&#123;sampleName&#125;_2.interleaved.fq.gz -CLIP_ATTR XT -CLIP_ACT 2</span><br><span class="line"></span><br><span class="line">bwa-mem2 mem -M -t $threads $ref  interleaved_fq/$&#123;sampleName&#125;_1.interleaved.fq.gz interleaved_fq/$&#123;sampleName&#125;_2.interleaved.fq.gz | samtools view -Sb - &gt; raw_bam/$&#123;sampleName&#125;.bam</span><br><span class="line"></span><br><span class="line">gatk MergeBamAlignment -R $ref -UNMAPPED  ubam/$&#123;sampleName&#125;.bam -O align_bam/$&#123;sampleName&#125;.bam -ALIGNED  raw_bam/$&#123;sampleName&#125;.bam -MC true --CREATE_INDEX true</span><br><span class="line"></span><br><span class="line">rm -rf markadapeters/$&#123;sampleName&#125;.markadapeters.ba interleaved_fq/$&#123;sampleName&#125;_1.interleaved.fq.gz  interleaved_fq/$&#123;sampleName&#125;_2.interleaved.fq.gz raw_bam/$&#123;sampleName&#125;.bam # 删除中间文件</span><br></pre></td></tr></table></figure><ol start="4"><li><strong>标记重复序列</strong>：做SNP分析前最重要的一点就是标记重复序列（mark duplicate），二代测序是在PCR扩增的基础上进行的，因此PCR扩增产生的多拷贝会结合到flowcell的不同位置，生成完全相同的测序cluster，最后得到重复序列。这一步就是标记这些重复序列（但是没有删除，对结果应该不影响），最后得到一个<strong>metrics文件</strong>（duplicate的统计信息）和一个<strong>bam文件</strong>（duplicate的详细信息，注意要创建索引）。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line"></span><br><span class="line">gatk MarkDuplicates -I align_bam/$&#123;sampleName&#125;.bam -O markdup/$&#123;sampleName&#125;.markdup.bam -M markdup/$&#123;sampleName&#125;.markdup_metrics.txt --CREATE_INDEX true</span><br><span class="line"></span><br><span class="line">rm -rf  align_bam/$&#123;sampleName&#125;.bam # 删除中间文件</span><br></pre></td></tr></table></figure><p>最终生成的bam文件进行下一步变异检测，可以用<code>samtools -view</code> 查看bam文件的内容（也没啥好看的，感兴趣可以看看之前博客写的<a href="https://www.shelven.com/2022/04/15/a.html">sam文件格式解读</a>）。</p><p><img src="https://www.shelven.com/tuchuang/20230306/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>注意：官网的数据预处理后续还有一步<strong>碱基质量重校正BQSR</strong>（Base Quality Scores Recallbrate），官方提供了两个工具BaseRecalibrator和ApplyBQSR。第一个工具计算需要校正的reads和特征值，输出校准表文件，需要注意的是，<strong>这个工具需要一个或者多个已知且可靠的物种变异位点数据库</strong>，比如人类就有千人基因组计划的各种变异位点数据库，1000G_omni2.5.hg38.vcf.gz、dbsnp_146.hg38.vcf.gz等等；第二个工具根据第一个工具生成校准表，重新调整原来BAM文件中的碱基质量值，重新输出到一个新的BAM文件中。</li></ul><p>因为我这个植物没有已知的可靠变异位点数据，因此不用做最后这一步。</p><p><strong>本部分程序需要运行10小时。</strong></p><h3 id="2-2-变异检测"><a href="#2-2-变异检测" class="headerlink" title="2.2 变异检测"></a>2.2 变异检测</h3><p>因为我只有一个样本，所以可以按照单个样本（Single-Sample Data）的标准流程来做，也可以按照多样本（Cohort Data）的流程做。该部分主要用到的工具是HaplotypeCaller，两个流程只是对HaplotypeCaller工具产生的结果做了不同的处理，最后都是得到包含SNP和Indel的VCF文件。我也将分别跑两个流程来对比下差异。</p><p>首先要明白HaplotypeCaller这个工具具体做了什么，是怎么找出单碱基变异的：</p><ul><li><strong>1.定义活跃区域</strong>（<a href="https://software.broadinstitute.org/gatk/documentation/article?id=4147">Define active regions</a>）：根据是否存在变异来确定需要操作的基因组的活跃区域。</li><li><strong>2.通过组装活跃区域确定单倍型</strong>（<a href="https://software.broadinstitute.org/gatk/documentation/article?id=4146">Determine haplotypes by assembly of the active region</a>）：对于每个活跃区域，构建一个类似De Bruijn图来重新组装活性区域，识别可能的单倍型，然后用Smith-Waterman算法将每个单倍型与参考基因组单倍型重新比对，发现潜在的变异位点。</li><li><strong>3.确定read单倍型似然值</strong>（<a href="https://software.broadinstitute.org/gatk/documentation/article?id=4441">Determine likelihoods of the haplotypes given the read data</a>）：对每个活跃区域使用PairHMM算法对每个read与每个单倍型进行两两比对，生成单倍型似然矩阵，将似然值边缘化，以获得每个潜在变异位点的等位基因的可能性。</li><li><strong>4.指定样本基因型</strong>（<a href="https://software.broadinstitute.org/gatk/documentation/article?id=4442">Assign sample genotypes</a>）：对每个潜在的变异位点使用贝叶斯算法，转化每个位点的基因型的似然值。然后将最可能的基因型指定为样本基因型。</li></ul><p>以上流程翻译自<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360056969012-HaplotypeCaller">HaplotypeCaller – GATK (broadinstitute.org)</a>，这个工具可用参数非常之多，下面跑的流程就展示一些常用的。</p><h4 id="2-2-1-多样本的SNP和INDEL检测"><a href="#2-2-1-多样本的SNP和INDEL检测" class="headerlink" title="2.2.1 多样本的SNP和INDEL检测"></a>2.2.1 多样本的SNP和INDEL检测</h4><ol><li><strong>使用HaplotypeCaller的GVCF模式，找到每个样本SNP和INDEL变异</strong>。在GVCF模式下，每个样本的结果文件以gvcf（genomic vcf）格式文件呈现，实际上gvcf格式和vcf格式类似，gvcf记录所有位点的突变情况，并且提供这些位点是否是纯和的置信度，主要还是方便将所有样本的gvcf联合起来方便分析。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line">threads=50</span><br><span class="line">ref=/public/home/wlxie/biosoft/GATK_file/gatk/ref/luobuma.fasta</span><br><span class="line"></span><br><span class="line">gatk HaplotypeCaller -R $ref --native-pair-hmm-threads $&#123;threads&#125; --emit-ref-confidence GVCF -I ../../pre_processing/markdup/$&#123;sampleName&#125;.markdup.bam -O $&#123;sampleName&#125;.g.vcf.gz</span><br></pre></td></tr></table></figure><p>这一步是整个SNP和IDEL检测中运行时间最长，需要算力最多的一步（主要是Pair-HMM算法花时间），Pair-HMM算法在本地调用的线程数是可以更改的，官方是给定默认值为4。GATK4.0版本开始放弃了多线程任务，<strong>这个参数可能是更新后遗漏的，因为我这里用的50线程和默认的4线程跑几乎没有区别，都是在28小时左右完成，此处参数存疑</strong>。</p><ol start="2"><li><strong>建库合并所有样本的GVCF文件（单样本不用做这步），并将GVCF文件转化为VCF文件</strong>。对于多样本的GVCF合并，现在<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035890411?id=3893">官方建议</a>用GenomicsDBImport这个工具进行建库合并，速度会快很多。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line">threads=50</span><br><span class="line">ref=/public/home/wlxie/biosoft/GATK_file/gatk/ref/luobuma.fasta</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">gatk GenomicsDBImport $(<span class="keyword">for</span> file <span class="keyword">in</span> `<span class="built_in">ls</span> *.g.vcf.gz`; <span class="keyword">do</span> <span class="built_in">echo</span> <span class="string">&quot;-V <span class="variable">$file</span>&quot;</span>; <span class="keyword">done</span>)  --genomicsdb-workspace-path database -L chr01<span class="comment"># 单样本不用做这步，因为就一个GVCF。多样本注意-L参数是建库必须的,根据fasta参考基因组的染色体名称命名，拆分</span></span></span><br><span class="line"></span><br><span class="line">gatk GenotypeGVCFs -R $ref -V $&#123;sampleName&#125;.g.vcf.gz -O raw_variants.vcf.gz# 多样本使用参数-V gendb://database 也就是上一步建的数据库名，单样本直接用gvcf文件</span><br></pre></td></tr></table></figure><p>可以看看最后生成的VCF文件：</p><p><img src="https://www.shelven.com/tuchuang/20230306/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>文件解读放在最后过滤和拆分SNP和INDEL的时候再说，这里是初步得到变异信息，需要经过过滤和筛选。</p><p><strong>本部分程序需要运行28小时。</strong></p><h4 id="2-2-2-单个样本的SNP和INDEL检测"><a href="#2-2-2-单个样本的SNP和INDEL检测" class="headerlink" title="2.2.2 单个样本的SNP和INDEL检测"></a>2.2.2 单个样本的SNP和INDEL检测</h4><p><strong>使用HaplotypeCaller默认的single-sample模式，直接生成统计SNP和INDEL变异的VCF文件</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line">threads=50</span><br><span class="line">ref=/public/home/wlxie/biosoft/GATK_file/gatk/ref/baima.fasta</span><br><span class="line"></span><br><span class="line">gatk HaplotypeCaller -R $ref --native-pair-hmm-threads $&#123;threads&#125; -I ../../pre_processing/markdup/$&#123;sampleName&#125;.markdup.bam -O $&#123;sampleName&#125;.vcf.gz</span><br></pre></td></tr></table></figure><p>同上一个步骤，此处参数<code>--native-pair-hmm-threads</code>对运算速度的提升存疑，最后同样是生成VCF文件，<strong>运行时间同样为28小时</strong>。</p><h3 id="2-3-变异过滤（优化）"><a href="#2-3-变异过滤（优化）" class="headerlink" title="2.3 变异过滤（优化）"></a>2.3 变异过滤（优化）</h3><p>变异集过滤方法主要有两种：</p><ul><li>1.软过滤：基于机器学习的方法，对原始vcf文件进行变异质量重矫正和过滤。比如有基于卷积神经网络CNN的CNNVariantTrain（有预训练的模型1D和2D），VariantRecalibrator、ApplyVQSR等可以用已知的人类变异数据集作为训练集，检测得到的SNP和INDEL的准确性（官方推荐用于人类变异过滤的方法，Variant Quality Score Recalibration，VQSR）。缺点显而易见，需要已知的真实变异数据集，<strong>除人类以外大多数生物都没有这方面的数据集</strong>。如果是研究人类基因组的话，可以从GATK官网资源处下载。</li><li>2.硬过滤：通过对6个指标的硬性阈值筛选质量合格的SNP和INDEL。</li></ul><p>记录下硬过滤的6个指标，有些说明看不懂干脆都放英文了，参考自官网<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035890471-Hard-filtering-germline-short-variants">Hard-filtering germline short variants</a>：</p><blockquote><p>（1）<a href="https://gatk.broadinstitute.org/hc/en-us/articles/9570266920219--Tool-Documentation-Index#QualByDepth">QualByDepth (QD)</a>：This is the variant confidence (from the QUAL field) divided by the unfiltered depth of non-hom-ref samples. 变异置信度，官方建议过滤该值小于2的变异。</p><p>（2）<a href="https://gatk.broadinstitute.org/hc/en-us/articles/9570266920219--Tool-Documentation-Index#FisherStrand">FisherStrand (FS)</a>：This is the Phred-scaled probability that there is strand bias at the site.</p><p>（3）<a href="https://gatk.broadinstitute.org/hc/en-us/articles/9570266920219--Tool-Documentation-Index#StrandOddsRatio">StrandOddsRatio (SOR)</a>：This is another way to estimate strand bias using a test similar to the symmetric odds ratio test.</p><p>（4）<a href="https://gatk.broadinstitute.org/hc/en-us/articles/9570266920219--Tool-Documentation-Index#RMSMappingQuality">RMSMappingQuality (MQ)</a>：This is the root mean square mapping quality over all the reads at the site.比对reads质量的平方根。</p><p>（5）<a href="https://gatk.broadinstitute.org/hc/en-us/articles/9570266920219--Tool-Documentation-Index#MappingQualityRankSumTest">MappingQualityRankSumTest (MQRankSum)</a>：This is the u-based z-approximation from the Rank Sum Test for mapping qualities. </p><p>（6）<a href="https://gatk.broadinstitute.org/hc/en-us/articles/9570266920219--Tool-Documentation-Index#ReadPosRankSumTest">ReadPosRankSumTest (ReadPosRankSum)</a>：This is the u-based z-approximation from the Rank Sum Test for site position within reads. </p></blockquote><p>看不懂没关系，官方给出了6个硬过滤指标在SNP和INDEL中的阈值设置，详情可以看<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035890471-Hard-filtering-germline-short-variants">Hard-filtering germline short variants – GATK (broadinstitute.org)</a>。以下例子均以官方的硬过滤指标为准，感兴趣可以去官网看各个参数的作用或者自己微调。</p><p>SelectVariants工具用于从vcf文件中提取SNP和INDEL信息，VariantFiltration工具用于硬过滤筛选：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">sampleName=$1</span><br><span class="line">threads=50</span><br><span class="line">VARIANTS=/public/home/wlxie/biosoft/GATK_file/gatk/variants_discover/luobuma/raw_variants.vcf.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">SNP筛选、过滤和提取</span></span><br><span class="line">gatk SelectVariants -select-type SNP -V $VARIANTS --restrict-alleles-to BIALLELIC  -O $&#123;sampleName&#125;_SNP.vcf.gz# BIALLELIC 限制双等位基因，不考虑其他等位多态性</span><br><span class="line">gatk VariantFiltration -V $&#123;sampleName&#125;_SNP.vcf.gz --filter-expression &quot;QD &lt; 2.0 || MQ &lt; 40.0 || FS &gt; 60.0 || SOR &gt; 3.0 || MQRankSum &lt; -12.5 || ReadPosRankSum &lt; -8.0&quot; --filter-name &quot;Filter&quot; -O $&#123;sampleName&#125;_SNP.filter.vcf.gz</span><br><span class="line">gatk SelectVariants  -V $&#123;sampleName&#125;_SNP.filter.vcf.gz --exclude-filtered true -O final.$&#123;sampleName&#125;_SNP.vcf.gz# 只显示通过过滤的变异（pass）</span><br><span class="line">rm -rf $&#123;sampleName&#125;_SNP.vcf.gz*</span><br><span class="line">rm -rf $&#123;sampleName&#125;_SNP.filter.vcf.gz*</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">INDEL筛选、过滤和提取</span></span><br><span class="line">gatk SelectVariants -select-type INDEL -V $VARIANTS --restrict-alleles-to BIALLELIC  -O $&#123;sampleName&#125;_INDEL.vcf.gz# BIALLELIC 限制双等位基因，不考虑其他等位多态性</span><br><span class="line">gatk VariantFiltration -V $&#123;sampleName&#125;_INDEL.vcf.gz --filter-expression &quot;QD &lt; 2.0 || FS &gt; 200.0 || SOR &gt; 10.0 || MQRankSum &lt; -12.5 || ReadPosRankSum &lt; -8.0&quot; --filter-name &quot;Filter&quot; -O $&#123;sampleName&#125;_INDEL.filter.vcf.gz</span><br><span class="line">gatk SelectVariants  -V $&#123;sampleName&#125;_INDEL.filter.vcf.gz --exclude-filtered true -O final.$&#123;sampleName&#125;_INDEL.vcf.gz# 只显示通过过滤的变异（pass）</span><br><span class="line">rm -rf $&#123;sampleName&#125;_INDEL.vcf.gz*</span><br><span class="line">rm -rf $&#123;sampleName&#125;_INDEL.filter.vcf.gz*</span><br></pre></td></tr></table></figure><p>得到的<code>final.sampleName_SNP.vcf.gz</code>和<code>final.sampleName_INDEL.vcf.gz</code>为最终的变异集结果文件。</p></div><h2 id="3-结果文件解读"><a href="#3-结果文件解读" class="headerlink" title="3. 结果文件解读"></a>3. 结果文件解读</h2><div class="story post-story"><p>因为结果文件时一个压缩过后的vcf文件，且vcf文件中前面带<code>#</code>部分的注释内容是用不到的，后面每一行代表一个变异位点信息，因此可以直直接统计行数来得到最终的SNP和INDEL的数量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zcat final.luobuma_SNP.vcf.gz | grep -v -P &quot;^#&quot; -c</span><br></pre></td></tr></table></figure><p><img src="https://www.shelven.com/tuchuang/20230306/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>用2.2.1多样本流程的SNP和INDEL结果文件为<code>final.luobuma_SNP.vcf.gz</code>和<code>final.luobuma_INDEL.vcf.gz</code>；用2.2.2单个样本流程的SNP和INDEL结果为<code>final.luobuma_sm_SNP.vcf.gz</code>和<code>final.luobuma_sm_INDEL.vcf.gz</code>。可以看到两者在统计SNP和INDEL数量上的差距非常小，<strong>说明这两个流程对单样本来说都是可以用的</strong>。</p><p>以<code>final.luobuma_SNP.vcf.gz</code>文件进行解读，通过<code>less -S</code>命令一行一条信息查看文件内容：</p><p><img src="https://www.shelven.com/tuchuang/20230306/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://www.shelven.com/tuchuang/20230306/7.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230306/7.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>每列信息如下：</p><ul><li>1.CHROM：染色体信息</li><li>2.POS：变异所在参考基因组的位置</li><li>3.ID：变异的ID，如果有参考变异集，会给出id，否则为<code>.</code>表示新发现的变异</li><li>4.REF：变异在参考基因组上的信息，必须为ATCGN五个之一</li><li>5.ALT：突变之后的情况，类型同上，<code>.</code>表示缺失</li><li>6.QUAL：突变后的质量值，质量值越高越可靠，通常只用pass的数据</li><li>7.FILTER：是否通过过滤</li><li>8.INFO：每个位点的详细信息（包括硬过滤的指标，详细可以到header里找）</li><li>9.FORMAT：格式</li><li>10.样本名（实际是前面格式的具体值）</li></ul><p>主要解释一下第九列和第十列，就是上图中红色框框起来的部分，两列值是用冒号分隔且一一对应的，需要注意的值是<strong>GT</strong>：</p><ul><li><strong>GT</strong>：0表示和参考序列一致（REF allele），1表示和样本序列一致（ALT allele），双等位基因只有0和1，0&#x2F;1和0|1表示杂合，1&#x2F;1和1|1表示纯和。“|”和“&#x2F;”区别是前者是phased genotype，就是知道REF&#x2F;ALT allele是来自于父本还是母本，在这里对我这个植物基因组没有什么意义，全都统计进杂合和纯和SNP个数就行。</li><li>AD：REF和ALT allele的覆盖度，在二倍体是是用逗号分割的两个值表示，前一个代表参考基因组的基因型，后者代表样本基因型。</li><li>DP：样本中该位点覆盖度，AD两个数字的和。</li></ul><h3 id="3-1-杂合率统计"><a href="#3-1-杂合率统计" class="headerlink" title="3.1 杂合率统计"></a>3.1 杂合率统计</h3><p>分别统计SNP和INDEL文件中杂合单碱基变异的个数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zcat final.luobuma_SNP.vcf.gz | grep -c &quot;0/1&quot;</span><br><span class="line">zcat final.luobuma_SNP.vcf.gz | grep -c &quot;0|1&quot;</span><br><span class="line">zcat final.luobuma_INDEL.vcf.gz | grep -c &quot;0/1&quot;</span><br><span class="line">zcat final.luobuma_INDEL.vcf.gz | grep -c &quot;0|1&quot;</span><br></pre></td></tr></table></figure><p><strong>杂合率 &#x3D; (杂合SNP数 + 杂合INDEL数) &#x2F; 基因组大小</strong></p><table><thead><tr><th>杂合SNP数(Hetero SNP)</th><th>杂合INDEL数(Hetero Indel)</th><th>基因组大小(bp)</th><th>杂合率</th></tr></thead><tbody><tr><td>1,233,471</td><td>287,207</td><td>230,888,863</td><td>0.66%</td></tr></tbody></table><p>此处计算的杂合率可以和前面做的基因组Survey做个比较，说明基因组Survey的可靠性。</p><h3 id="3-2-单碱基准确度计算"><a href="#3-2-单碱基准确度计算" class="headerlink" title="3.2 单碱基准确度计算"></a>3.2 单碱基准确度计算</h3><p>我们知道测序过程中不可避免地存在错误，三代测序数据单碱基变异的来源，包括<u>真实的单碱基变异</u>和<u>测序错误导致的单碱基变异</u>。<strong>当测序错误导致的单碱基变异存在于参考基因组上时，利用二代测序数据进行单碱基变异的检测时，会将其识别为纯合单碱基变异</strong>。因此，可以将三代数据组装的最终版基因组作为参考基因组，利用二代数据将纯合子单碱基变异率作为组装结果的错误率，即:</p><p><strong>组装结果的准确率 &#x3D; 1 - 纯合子单碱基变异率</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zcat final.luobuma_SNP.vcf.gz | grep -c &quot;1/1&quot;</span><br><span class="line">zcat final.luobuma_SNP.vcf.gz | grep -c &quot;1|1&quot;</span><br><span class="line">zcat final.luobuma_INDEL.vcf.gz | grep -c &quot;1/1&quot;</span><br><span class="line">zcat final.luobuma_INDEL.vcf.gz | grep -c &quot;1|1&quot;</span><br></pre></td></tr></table></figure><table><thead><tr><th>纯和SNP数(Homo SNP)</th><th>纯和INDEL数(Homo Indel)</th><th>基因组大小(bp)</th><th>纯和子单碱基变异率</th><th>组装结果准确率</th></tr></thead><tbody><tr><td>4,176</td><td>8,580</td><td>230,888,863</td><td>0.005525%</td><td>99.994475%</td></tr></tbody></table><p>这种单碱基准确度的计算结果也可以作为基因组组装质量的评估指标之一，即<strong>序列一致性评估</strong>——利用高质量的二代测序数据来评估三代测序数据组装结果在单碱基水平上的准确性。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;基因组组装完成之后，我们就可以对基因组进行变异分析了。这里主要介绍由 &lt;a href=&quot;http://www.broadinstitute.org/&quot;&gt;Broad Institute&lt;/a&gt;开发的一款基因组分析工具GATK，这款工具设计之初是用于处理分析Illumina二代测序技术产生的人类全外显子和全基因组数据，经过多个版本的优化迭代，GATK集合了多种高通量测序数据处理和质控的软件，如今GATK可以说是对DNA和RNA-seq数据检测SNP和Indel的标准。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="GATK" scheme="http://www.shelven.com/tags/GATK/"/>
    
  </entry>
  
  <entry>
    <title>0基础学习基因组三代测序组装（8）——基因组组装质量评估（QUAST）</title>
    <link href="http://www.shelven.com/2023/03/02/a.html"/>
    <id>http://www.shelven.com/2023/03/02/a.html</id>
    <published>2023-03-02T15:24:41.000Z</published>
    <updated>2023-03-04T02:58:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>接上一篇博客，这一篇博客继续介绍一个常用的评估基因组组装质量的软件——<strong>QUAST</strong></p><span id="more"></span><h2 id="1-QUAST介绍"><a href="#1-QUAST介绍" class="headerlink" title="1. QUAST介绍"></a>1. QUAST介绍</h2><div class="story post-story"><p>QUAST（Quality Assessment Tool for Genome Assemblies）是一个比较综合的评估基因组组装质量的软件，主要包括四种分析工具：</p><ul><li>QUAST：常规基因组组装质量评估</li><li>MetaQUAST：宏基因组（元基因组）组装质量评估</li><li>QUAST-LG：大型基因组组装质量评估</li><li>Icarus：Contig比对可视化工具（类似IGV浏览器的感觉）</li></ul><p>QUAST用到的软件如下（参考自<a href="https://nmdc.cn/static/pdf/web/viewer.html?file=/static/file/analysis/QUAST.pdf">国家微生物科学数据中心</a>）：</p><blockquote><p>序列比对：Minimap2</p><p>基因和功能：GeneMarkS、GeneMark-ES、GlimmerHMM、Barrnap和BUSCO</p><p>查找结构变异：BWA、Sambamba</p><p>覆盖度计算：bedtools</p><p>MetaQUAST：MetaGeneMark、Krona tools、BLAST和SILVA数据库</p><p>QUAST-LG：KMC和Red</p></blockquote><p>这个软件优点是可以使用参考基因组或者<strong>无参考基因组</strong>情况对组装的基因组进行评估，可以快速进行<strong>大批量的基因组组装质量比较</strong>，最终的结果有图表、excel和latex等多种表现形式，也有个可以<strong>交互的网页结果</strong>，非常直观和方便。</p></div><h2 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h2><div class="story post-story"><p>如果从官网下载的话，需要安装非常多的依赖软件，好消息是：<strong>可以conda安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda install -c bioconda quast</span><br><span class="line"></span><br><span class="line">quast-download-busco</span><br><span class="line">quast-download-gridss# 检测基因组重排的软件</span><br><span class="line">quast-download-silva# 著名的16s数据库，提供最新的核糖体大小亚基rRNA注释信息</span><br></pre></td></tr></table></figure><p>截至2023年3月2日，最新版本为5.2.0</p><p>后续需要安装什么软件都可以<code>conda search</code>一下，能省好多功夫。注意一下conda安装之后会提醒缺两个工具和一个数据库，直接运行命令下载即可。</p></div><h2 id="3-运行实例"><a href="#3-运行实例" class="headerlink" title="3. 运行实例"></a>3. 运行实例</h2><div class="story post-story"><p>以我的植物基因组跑一个常规基因组组装质量评估的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"></span><br><span class="line">quast -t 50 -o quast_baima -1 /public/home/wlxie/clean_data/1.fq -2 /public/home/wlxie/2.fq /public/home/wlxie/NextPolish/baima_rundir/genome.nextpolish.fasta</span><br></pre></td></tr></table></figure><p>QUAST输入文件只有组装的基因组是必须的，同时也支持三代测序<code>--pacbio</code>、<code>--nanopore</code>数据，也支持二代数据输入。我这里同时输入了二代数据，因此结果文件中有组装基因组的质量评估，也有二代数据回贴组装基因组的分析数据。</p></div><h2 id="4-结果展示"><a href="#4-结果展示" class="headerlink" title="4. 结果展示"></a>4. 结果展示</h2><div class="story post-story"><p>运行结束后的输出日志如下：</p><p><img src="https://www.shelven.com/tuchuang/20230303/1111.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230303/1111.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>最终生成图表结果可以在report.pdf中找到，也可以看report.html，一次运行时常大约为6小时：</p><p><img src="https://www.shelven.com/tuchuang/20230303/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230303/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>左边红框框起来的部分就是二代数据回比基因组的结果，mapping率高于100%说明有多比对，<strong>完美比对率</strong>（配对reads中两条序列比对上同一个参考基因组序列的比例，Properly Paired）<strong>93.45%<strong>，</strong>覆盖度（coverage）98.63%<strong>。</strong>这个比对率说明二代测序reads与组装的基因组有较高的一致性（Properly paired 90%以上，coverage 95%以上）</strong>，可以进行后续的分析。</p><p>右边是contig长度累积图，横坐标从左到右contig长度依次减小，曲线越陡表明大片段越长、数量越多，也可以看到基因组组装的连续性良好。</p><p>左上角contig的具体数据，以及N50、GC含量可以在<code>transposed_report.txt</code>中查看，同时也提供了latex和excel格式的结果文件，非常贴心~或者可以在<code>basic_stats</code>文件夹中查看相应的pdf图表：</p><p><img src="https://www.shelven.com/tuchuang/20230303/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230303/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><img src="https://www.shelven.com/tuchuang/20230303/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230303/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Nx图横轴是Nx百分比，比如50就是N50；纵轴是contig长度。这张图也可以反映组装结果的连续性。</p><p><img src="https://www.shelven.com/tuchuang/20230303/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230303/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>最后是icarus网页结果，前面说这个界面有点像IGV。。。总之就是将各个contig从长到短组装情况可视化的工具，可以拖动底下的黄色框左右移动来查看对应的contig情况。</p><p>在基因组组装质量评估方面，<strong>这个软件就可以一次给出序列一致性、组装完整性和测序覆盖均匀性评估</strong>，还是非常方便的~当然，如果你有参考基因组的话，就可以得到更多有效的评估信息。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;接上一篇博客，这一篇博客继续介绍一个常用的评估基因组组装质量的软件——&lt;strong&gt;QUAST&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="QUAST" scheme="http://www.shelven.com/tags/QUAST/"/>
    
  </entry>
  
  <entry>
    <title>0基础学习基因组三代测序组装（7）——基因组组装质量评估（BUSCO、LAI指数）</title>
    <link href="http://www.shelven.com/2023/03/01/a.html"/>
    <id>http://www.shelven.com/2023/03/01/a.html</id>
    <published>2023-03-01T12:39:05.000Z</published>
    <updated>2023-03-03T06:30:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>通过前面的纠错和校正步骤，我们得到了组装完成的基因组序列，接下来就是进行基因组的组装质量评估。质量评估的软件和方法比较多，这里分两篇博客记录，本篇主要演示如何用BUSCO和LAI指数评价基因组组装质量。</p><span id="more"></span><p>复习一下前面说到的contig N50，按照contig从短到长的顺序依次相加，当相加的长度达到Contig总长度的一半，最后一个Contig长度即为<strong>contig N50</strong>.</p><p>contig N50是基因组组装质量的第一指标，一般来说越高越好，但是contig N50不能完全代表一个基因组组装质量的高低，比如reads的错误连接也会使contig N50变高。接下来介绍几个现在常用的评估基因组组装质量的软件和方法。</p><h2 id="1-保守型基因评估"><a href="#1-保守型基因评估" class="headerlink" title="1. 保守型基因评估"></a>1. 保守型基因评估</h2><div class="story post-story"><p>BUSCO（Benchmarking Universal Single-Copy Orthologs）评估是在基因含量层面上评估基因组完整性。简单来说，通过已有的直系同源数据库进行基因组比对，同源的生物之间有保守基因序列，能比对上的基因数越多说明组装的结果越靠谱。</p><p>安装过程：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 源码安装（需要安装前置软件）</span></span><br><span class="line">git clone https://gitlab.com/ezlab/busco.git</span><br><span class="line">cd busco/</span><br><span class="line">python setup.py install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">前置软件：</span></span><br><span class="line">https://biopython.org/</span><br><span class="line">https://pandas.pydata.org/</span><br><span class="line">https://jgi.doe.gov/data-and-tools/software-tools/bbtools/</span><br><span class="line">https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST</span><br><span class="line">http://bioinf.uni-greifswald.de/augustus/</span><br><span class="line">https://github.com/soedinglab/metaeuk</span><br><span class="line">https://github.com/hyattpd/Prodigal</span><br><span class="line">http://hmmer.org/</span><br><span class="line">https://github.com/smirarab/sepp/</span><br><span class="line">https://www.r-project.org/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. conda安装（推荐）</span></span><br><span class="line">conda install -c conda-forge -c bioconda busco=5.3.2</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>conda安装可能会比较慢，需要多试几次。实在不行就源码下载编译，不过需要下载非常多的前置软件，不同软件可能会有环境冲突问题、gcc版本问题等等<del>（我花了大半天时间在折腾环境）</del>。安装之后通过<code>busco -h</code>查看是否安装成功，如果提示缺什么软件就用conda补上（我当前环境中没有安装pandas就会有提示）。</p><p>通过<code>busco --list-datasets</code>可以查看当前有哪些物种的数据库，我的植物是双子叶龙胆目，这里的数据库只有<strong>真双子叶植物（eudicots）</strong>分支离的最近，因此选择这个数据库，v5版本所有单拷贝直系同源数据库网址<a href="https://busco-data.ezlab.org/v5/data/lineages/">https://busco-data.ezlab.org/v5/data/lineages/</a></p><p><img src="https://www.shelven.com/tuchuang/20230228/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230228/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>下载的数据库放在<code>busco_downloads</code>文件夹中，解压即可使用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup wget https://busco-data.ezlab.org/v5/data/lineages/eudicots_odb10.2020-09-10.tar.gz &amp;</span><br><span class="line">tar -zxvf eudicots_odb10.2020-09-10.tar.gz</span><br></pre></td></tr></table></figure><p>busco的详细参数可以看官网的user guide <a href="https://busco.ezlab.org/busco_userguide.html">User guide BUSCO v5.4.4 (ezlab.org)</a></p><p>简单讲一讲格式和能用到的参数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">主要参数：</span><br><span class="line"> -i序列文件位置</span><br><span class="line"> -l下载的同源物种保守基因数据库位置</span><br><span class="line"> -o输出文件名</span><br><span class="line"> -m模式，分为genome,proteins,transcriptome三种</span><br><span class="line"> 其他参数：</span><br><span class="line"> --cpu设置cpu数量</span><br><span class="line"> --download在线下载数据库，根据分类有&quot;all&quot;、&quot;prokaryota&quot;、&quot;eukaryota&quot;和&quot;virus&quot; （不推荐，速度慢）</span><br><span class="line"> --offline离线模式，不会更新数据库</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure><p>以下是我跑的程序，大约用了1个小时：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">busco -i /public/home/wlxie/NextPolish/01_rundir/genome.nextpolish.fasta -l /public/home/wlxie/busco_soft/busco/test_data/eukaryota/busco_downloads/lineages/eudicots_odb10 -o baima -m genome --cpu 8 --offline</span><br></pre></td></tr></table></figure><p>截至2023&#x2F;02&#x2F;28，<strong>真双子叶植物库有2326个保守BUSCO基因序列</strong>，比对结果文件在short_summary.specific.xxx.xxx.txt中，如下：</p><p><img src="https://www.shelven.com/tuchuang/20230228/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230228/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>Complete BUSCOs (C)    多少个基因完全比对上BUSCOs</li><li>Complete and single-copy BUSCOs (S)    多少个基因比对上单拷贝的BUSCOs</li><li>Complete and duplicated BUSCOs (D)    多少个基因比对上多拷贝的BUSCOs</li><li>Fragmented BUSCOs (F)    多少个基因部分比对上BUSCOs，可能基因只是部分存在</li><li>Missing BUSCOs (M)    多少个基因没有比对上BUSCOs，可能这些直系同源基因是缺失的</li></ul><p>从上面的数据看，组装结果还是不错的。从中也可以看到BUSCO运行的<strong>两个步骤</strong>：<strong>用metaeuk进行基因预测</strong>（真核生物可以用tBLASTn与对应的BUSCO数据库序列进行比对从而确定候选区域，然后使用 Augustus 软件进行基因结构预测，两个软件可以替代metaeuk，详细参数见官网），以及<strong>HMMER进行同源基因的比对</strong>，从而评估基因组组装的完整性。</p><p>官方还提供了相应的python程序绘制结果图（调用了R包ggplot2），先将BUSCO结果文件放到新建的文件夹，运行相应的py程序，指定工作目录即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir summaries</span><br><span class="line"></span><br><span class="line">cp baima/short_summary.specific.eudicots_odb10.baima.txt summaries</span><br><span class="line"></span><br><span class="line">generate_plot.py -wd summaries</span><br></pre></td></tr></table></figure><p>结果图如下：</p><p><img src="https://www.shelven.com/tuchuang/20230228/3.png" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230228/3.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>当然，有结果数据就可以自己做更好看的图了，不一定要用官方的。</p></div><h2 id="2-长末端重复序列评估"><a href="#2-长末端重复序列评估" class="headerlink" title="2. 长末端重复序列评估"></a>2. 长末端重复序列评估</h2><div class="story post-story"><p>2018年发表在Nucleic Acids Research上的一篇文章<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6265445/">Assessing genome assembly quality using the LTR Assembly Index (LAI)</a>，研究者提出了一种对长末端重复序列（long terminal repeats,LTRs）评估从而评价基因组完整度的方法，并且开发了对应的分析工具<code>LTR_retriever</code></p><p>具体的LTR注释我会在后续的基因组注释笔记中更新，这里暂时跳过原理和背景部分，介绍下文章中提出的评估核心——LAI指数（LTR Assembly Index，LAI），也就是长末端重复序列组装指数。<code>raw LAI = (完整LTR-RTs长度/总LTR长度)*100</code>，修正后，<code>LAI = raw LAI + 2.8138 × (94 – 整个基因组LTR identity)</code>。</p><p>以下是一个完整的LTR-RTs的结构示意图：</p><p><img src="https://www.shelven.com/tuchuang/20230228/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230228/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>文章还阐明LAI独立于基因组大小、LTR-RT含量以及基因空间评估指标（如BUSCO和CEGMA）等参数，可以用于鉴定低质量的基因组区域。使用这个指标要求**基因组中完整的LTR-RTs应至少占基因组0.1%且总LTR-RTs长度至少占5%**。</p><p>文章最后给出了LAI评价基因组完整度的三个指标：</p><table><thead><tr><th>分类</th><th>LAI</th><th>举例</th></tr></thead><tbody><tr><td>Draft</td><td>0 ≤ LAI &lt; 10</td><td>Apple (v1.0), Cacao (v1.0)</td></tr><tr><td>Reference</td><td>10 ≤ LAI &lt; 20</td><td>Arabidopsis (TAIR10), Grape (12X)</td></tr><tr><td>Gold</td><td>20 ≤ LAI</td><td>Rice (MSUv7), Maize (B73 v4)</td></tr></tbody></table><h3 id="2-1-LTR序列预测"><a href="#2-1-LTR序列预测" class="headerlink" title="2.1 LTR序列预测"></a>2.1 LTR序列预测</h3><p><code>LTR_retriever</code>需要以<code>LTR_finder</code>和&#x2F;或<code>ltrharvest</code>的LTR预测结果文件为输入，也可以整合两个软件的预测结果作为输入（或者其他符合格式的LTR结果文件），因此需要先安装并运行以上软件，我这里以文章中提到的软件和参数运行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">LTR_finder、ltrharvest和LTR_retriever安装（ltrharvest是genometools软件的一部分）</span></span><br><span class="line"></span><br><span class="line">conda install -c bioconda ltr_finder</span><br><span class="line">conda install -c bioconda genometools-genometools</span><br><span class="line">conda install -c bioconda ltr_retriever</span><br></pre></td></tr></table></figure><p><strong>LTR_finder</strong>预测LTR序列（参数均由作者给出，只有文件是自己的）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 10</span></span><br><span class="line"></span><br><span class="line">ltr_finder -D 15000 -d 1000 -L 7000 -l 100 -p 20 -C -M 0.85 /public/home/wlxie/NextPolish/01_rundir/genome.nextpolish.fasta &gt; baima_ltrfinder.scn</span><br></pre></td></tr></table></figure><blockquote><p>参数解释：</p><p>-D NUM     Max distance between 5’&amp;3’LTR, default is 20000# 5’和3’LTR之间的最大距离</p><p>-d NUM     Min distance between 5’&amp;3’LTR, default is 1000</p><p>-L NUM     Max length of 5’&amp;3’LTR, default is 3500# 5’和3’LTR最大长度</p><p>-l NUM     Min length of 5’&amp;3’LTR, default is 100</p><p>-p NUM     min length of exact match pair, default is 20# 完全匹配最小长度</p><p>-C         detect Centriole, delete highly repeat regions# 检测中心粒，删除高度重复区域</p><p>-M NUM     min LTR similarity threshold, default is 0.00, [0,1]#最小LTR相似度</p></blockquote><p><strong>ltrharvest</strong>预测LTR序列（ltrharvest参数均由作者给出，只有文件是自己的）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 10</span></span><br><span class="line"></span><br><span class="line">mkdir index</span><br><span class="line"></span><br><span class="line">gt suffixerator -db /public/home/wlxie/NextPolish/01_rundir/genome.nextpolish.fasta -indexname index/baima -tis -suf -lcp -des -ssp -sds -dna</span><br><span class="line"></span><br><span class="line">gt ltrharvest -index index/baima -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -motif TGCA -motifmis 1 -similar 85 -vic 10 -seed 20 -seqids yes &gt; baima_ltrharvest.scn</span><br></pre></td></tr></table></figure><p>这里要注意下要先使用genome tools里的suffixerator<strong>创建基因组索引文件</strong>，然后才可以使用ltrharvest进行LTR预测。</p><blockquote><p>创建基因组索引的参数不做解释了，可以 gt suffixerator -help 查看。稍微记录下ltrharvest参数：</p><p>-minlenltr  specify minimum length for each LTR，default: 100</p><p>-mintsd     specify minimum length for each TSD，default: 4</p><p>-motif      specify 2 nucleotides startmotif + 2 nucleotides endmotif: ****</p><p>-motifmis   specify maximum number of mismatches in motif [0,3]，default: 4</p><p>-similar    specify similaritythreshold in range [1..100%]，default: 85.00</p><p>-vic        specify the number of nucleotides (to the left and to the right) that will be searched for TSDs and&#x2F;or motifs around 5’ and 3’boundary of predicted LTR retrotransposons, default: 60</p><p>-seed       specify minimum seed length for exact repeats，default: 30</p><p>-seqids     use sequence descriptions instead of sequence numbers in GFF3 output，default: no</p></blockquote><p>以上两个软件以同样的LTR最小相似度0.85预测LTR，得到两个结果文件<code>baima_ltrfinder.scn</code>和<code>baima_ltrharvest.scn</code>。</p><h3 id="2-2-LAI指数计算"><a href="#2-2-LAI指数计算" class="headerlink" title="2.2 LAI指数计算"></a>2.2 LAI指数计算</h3><p>用上一步的输出的两个结果文件，运行<code>LTR_retriever</code>鉴定LTR和计算LAI指数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 20</span></span><br><span class="line"></span><br><span class="line">LTR_retriever -genome /public/home/wlxie/NextPolish/01_rundir/genome.nextpolish.fasta -inharvest baima_ltrharvest.scn -infinder baima_ltrfinder.scn -threads 20</span><br></pre></td></tr></table></figure><p>这一步运行结果如下：</p><p><img src="https://www.shelven.com/tuchuang/20230228/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230228/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>其他文件可以后续做LTR分析用到</strong>，这里我们只要看最后一个LAI的计算结果文件：</p><p><img src="https://www.shelven.com/tuchuang/20230228/6.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230228/6.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>可以看到这个结果文件中包含了整个genome和各个contig的raw LAI和LAI指数，这里就只看整个genome的LAI指数15.37，根据上面文章作者提到的分类，属于Reference级别，也就是说可以认为达到参考基因组级别。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;通过前面的纠错和校正步骤，我们得到了组装完成的基因组序列，接下来就是进行基因组的组装质量评估。质量评估的软件和方法比较多，这里分两篇博客记录，本篇主要演示如何用BUSCO和LAI指数评价基因组组装质量。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="BUSCO" scheme="http://www.shelven.com/tags/BUSCO/"/>
    
    <category term="LAI" scheme="http://www.shelven.com/tags/LAI/"/>
    
  </entry>
  
  <entry>
    <title>0基础学习基因组三代测序组装（6）——基因组polish</title>
    <link href="http://www.shelven.com/2023/02/27/a.html"/>
    <id>http://www.shelven.com/2023/02/27/a.html</id>
    <published>2023-02-27T03:02:16.000Z</published>
    <updated>2023-02-27T03:05:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>三代基因组de novo组装后得到一系列contig，由于三代测序的错误率较高，我们需要对组装结果进行打磨（以下均用polish表示）以提高基因组的拼接指标如Contig N50，Scaffold N50。</p><span id="more"></span><p>常用软件主要有Pilon、Racon，针对PacBio的有Quiver &amp; Arrow，针对Nanopore的有NanoPolish，以及武汉希望组为NextDenovo配套开发的NextPolish等等。<strong>要注意下先进行三代测序数据矫正，再进行二代测序数据矫正，顺序不能反</strong>，因为三代数据读长长准确率低，二代读长短准确率高，利用二代测序测序数据对三代测序数据进行纠错可以将三代测序错误率降低到二代测序的水平。如果不先进行三代序列纠错，由于基因组上存在过高错误率，导致二代序列的错误比对，影响最终polish效果。</p><p>这里以前面用NextDenovo组装的植物三代基因组为例，介绍下Racon和NextPolish用法。</p><h2 id="1-Racon"><a href="#1-Racon" class="headerlink" title="1. Racon"></a>1. Racon</h2><div class="story post-story"><p>racon的基本用法如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">racon [options ...] &lt;sequences&gt; &lt;overlaps&gt; &lt;target sequences&gt;</span><br></pre></td></tr></table></figure><p>需要用到三种输入文件：sequences是指用来纠错的三代基因组测序数据（后面以原始数据称呼）；target sequences指<strong>需要校正的组装后的基因组数据</strong>（后面以组装基因组称呼）；overlaps指回比到组装基因组的原始数据文件，其中包含了所有的overlaps，其文件格式为MHAP&#x2F;PAF&#x2F;SAM三种之一。</p><p>因此在使用Racon之前需要使用其他比对工具将三代数据回贴到组装基因组上，在<a href="https://www.shelven.com/2022/04/15/a.html">转录组分析笔记</a>中有介绍过相关软件，我这里用minimap2进行比对，这是专门针对三代测序数据开发的比对工具，运行速度较快。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">minimap2 -a -t 20 &lt;target sequences&gt; &lt;sequences&gt; &gt; minimap_1.sam</span><br></pre></td></tr></table></figure><p><code>-a</code>表示结果为sam格式，<code>&lt;target sequences&gt;</code>处传入组装基因组的绝对路径，<code>&lt;sequences&gt;</code>处传入原始数据的绝对路径，比对结果的sam文件命名为minimap_1.sam</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">racon -t 50 &lt;sequences&gt; minimap_1.sam &lt;target sequences&gt; &gt; racon_minimap_1.fasta</span><br></pre></td></tr></table></figure><p>如上一次循环下来（大约3小时），得到的racon_minimap_1.fasta就是经过一次三代数据校正的组装基因组。</p><p>一般要用三代数据polish 2-4次，之后用二代数据继续校正4次左右，可以写脚本循环，需要注意<strong>racon因为要一次读入三代原始数据和回比的sam数据，内存需求量非常大</strong>，申请的内核数需要自己计算一下，否则会报内存溢出的错误（220Mb的基因组，100X测序深度，申请50个核才能跑动）。</p><p>脚本文件racon.sh如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">minimap2 -a -t 50 $1 $2 &gt; minimap_1.sam</span><br><span class="line">racon -t 50 $2 minimap_1.sam $1 &gt; racon_minimap_1.fasta</span><br><span class="line"></span><br><span class="line">minimap2 -a -t 50 racon_minimap_1.fasta $2 &gt; minimap_2.sam</span><br><span class="line">racon -t 50 $2 minimap_2.sam racon_minimap_1.fasta &gt; racon_minimap_2.fasta</span><br></pre></td></tr></table></figure><p>recon.slurm：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -J recon</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -N 1</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">date</span><br><span class="line">bash racon.sh /public/home/wlxie/NextDenovo/03_rundir/03.ctg_graph/nd.asm.fasta /public/home/wlxie/luobuma/luobuma/baima_rawdata/Third_generation_sequencing/clean_filter.fq</span><br><span class="line">date</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbatch recon.slurm</span><br></pre></td></tr></table></figure><p>可以从输出日志中看到，racon运行主要分两步，分别是校准overlap和生成共有序列（也就是去重），<strong>在生成共有序列（consensus sequence）之后再进行二代数据的纠错</strong>。</p><p>这一步的Racon检测出两个contig可能是嵌合体（chimeric），所谓嵌合contig，该contig的某段区域可能可以比对上不同的染色体，或者头尾部分可能分别属于不同的染色体。第一遍racon的时候没有检测到，第二遍racon才出现这个提示，我不确定这两个contig是否真的是嵌合体，最终还是需要Hi-C数据来验证。</p><p><img src="https://www.shelven.com/tuchuang/20230227/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230227/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>我这里两次循环得到polish的结果文件<code>racon_minimap_2.fasta</code>，接下来用NextPolish软件继续用二代数据polish。</p></div><h2 id="2-NextPolish"><a href="#2-NextPolish" class="headerlink" title="2. NextPolish"></a>2. NextPolish</h2><div class="story post-story"><p>NextPolish是武汉那希望组开发的与NextDenovo配套的基因组polish软件，支持二代短读长、三代长读长和HiFi数据进行纠错。</p><p>和之前的NextDenovo操作方法类似，首先需要准备一个input文件，写入二代数据的绝对路径到sgs.fofn：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">realpath ./1.fq ./2.fq &gt; sgs.fofn</span><br></pre></td></tr></table></figure><p>从doc文件夹中copy一份配置文件run.cfg，修改参数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[General]</span><br><span class="line">job_type = slurm# local, slurm, sge, pbs, lsf塔大学校集群选择slurm</span><br><span class="line">job_prefix = nextPolish</span><br><span class="line">task = best# all, default, best, 1, 2, 5, 12, 1212…  1，2是两个不同的短读长算法模块，5是长读长算法模块，默认best</span><br><span class="line">rewrite = yes</span><br><span class="line">deltmp = yes# 删除临时结果文件</span><br><span class="line">rerun = 3# 重复执行polish次数</span><br><span class="line">parallel_jobs = 20# 每个job线程数</span><br><span class="line">multithread_jobs = 5# job数</span><br><span class="line">genome = /public/home/wlxie/baima_polish/racon_minimap_2.fasta</span><br><span class="line">genome_size = auto</span><br><span class="line">workdir = ./01_rundir</span><br><span class="line">polish_options = -p &#123;multithread_jobs&#125;</span><br><span class="line"></span><br><span class="line">[sgs_option] #optional</span><br><span class="line">sgs_fofn = ./sgs.fofn# 输入文件位置（一行一条）</span><br><span class="line">sgs_options = -max_depth 100 -bwa# 使用bwa进行比对</span><br></pre></td></tr></table></figure><p>长reads和HiFi的两段配置信息删除，<strong>只留下短读长sgs_options</strong>。</p><p>这个软件的优点是速度快（<strong>100线程，4次polish，220Mb的基因组，72G的二代数据量仅仅用了8小时</strong>），而且只需要提供配置和输入文件就可以到polish结束出结果，经过4次Polish结果的迭代，最终结果如下:</p><p><img src="https://www.shelven.com/tuchuang/20230227/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230227/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Contig N50比一开始NextDenovo组装结果大，也就是组装效果更好。</p><p><img src="https://www.shelven.com/tuchuang/20230227/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230227/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;三代基因组de novo组装后得到一系列contig，由于三代测序的错误率较高，我们需要对组装结果进行打磨（以下均用polish表示）以提高基因组的拼接指标如Contig N50，Scaffold N50。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="NextPolish" scheme="http://www.shelven.com/tags/NextPolish/"/>
    
    <category term="Racon" scheme="http://www.shelven.com/tags/Racon/"/>
    
  </entry>
  
  <entry>
    <title>0基础学习基因组三代测序组装（5）——三代数据组装</title>
    <link href="http://www.shelven.com/2023/02/23/a.html"/>
    <id>http://www.shelven.com/2023/02/23/a.html</id>
    <published>2023-02-23T14:22:00.000Z</published>
    <updated>2023-02-28T13:07:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间比较忙，现在继续整理基因组测序组装系列的学习笔记。<a href="https://www.shelven.com/2022/07/03/a.html">第四篇笔记</a>写的二代测序基因组组装，主要是演示二代测序数据组装的主流工具SOAPdenovo 2.0是如何应用的。我这里有了二代和三代的测序数据，后续组装还是以<strong>三代数据为主</strong>，这里就继续记录下几款三代测序数据组装的主流工具和用法。</p><span id="more"></span><p>现在主流的三代测序公司是Pacbio和Nanopore，两家测序公司测序原理不同，产生的数据类型也有区别。</p><h2 id="1-主流三代测序平台"><a href="#1-主流三代测序平台" class="headerlink" title="1. 主流三代测序平台"></a>1. 主流三代测序平台</h2><div class="story post-story"><h3 id="1-1-Pacbio测序平台"><a href="#1-1-Pacbio测序平台" class="headerlink" title="1.1 Pacbio测序平台"></a>1.1 Pacbio测序平台</h3><p>Pacbio测序平台是单分子实时测序（single molecule real time sequencing，SMRT），原理是当DNA与聚合酶形成的复合物被ZMW（零模波导孔）捕获后，4种不同荧光标记的dNTP随机进入检测区域并与聚合酶结合，与模板匹配的碱基生成化学键并激发荧光，生成化学键激发的荧光存在的时间远远长于其他碱基被激发荧光的时间，从而实现单碱基的实时检测。</p><p><img src="https://www.shelven.com/tuchuang/20230223/1.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230223/1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>现在Pacbio有两种测序模式，一种是<strong>CLR测序模式</strong>（超长测序模式），产生数据基于单循环测序结果；一种是<strong>HiFi测序模式</strong>，也就是高保真测序模式，产生数据基于滚环一致序列（Circular Consensus Sequencing ，CCS）。具体原理就不说了，两种测序模式中HiFi数据相对来说准确率会高一些，所以不同软件对两种测序模式的数据也会有不同的处理。 </p><h3 id="1-2-Nanopore测序平台"><a href="#1-2-Nanopore测序平台" class="headerlink" title="1.2 Nanopore测序平台"></a>1.2 Nanopore测序平台</h3><p>Nanopore测序平台前面第一篇博客介绍过了，可以<a href="https://www.shelven.com/2022/06/17/b.html">点击这里</a>。需要了解ONT测序平台测序产生的原始数据是<strong>电信号</strong>，经过basecalling之后才可以转化成我们要的测序数据。</p></div><h2 id="2-三代基因组测序组装软件"><a href="#2-三代基因组测序组装软件" class="headerlink" title="2. 三代基因组测序组装软件"></a>2. 三代基因组测序组装软件</h2><div class="story post-story"><h3 id="2-1-NextDenovo"><a href="#2-1-NextDenovo" class="headerlink" title="2.1 NextDenovo"></a>2.1 NextDenovo</h3><p>NextDenovo是武汉希望组开发的集校正、比对和组装一体的，基于字符串图（string graph-based）的三代测序基因组组装软件。它的实现过程和另一款经典的三代基因组组装软件Canu类似，经过长读长数据的纠错校正后再进行组装。</p><p>官网上介绍原来可以对CLR、HiFi和ONT数据都可以组装，HiFi数据可以跳过数据的自我纠错过程，如今HiFi数据被划掉了，也许已经不再适用，但是对Pabio的CLR和Nanopore的ONT测序数据仍有较好的组装效果，其介绍是组装的准确率有98%-99.8%。</p><p>NextDenovo主要有两个核心模块 <strong>NextCorrect</strong>和<strong>NextGraph</strong>。NextCorrect用于原始数据纠错，NextGraph用于纠错后数据的组装。据作者介绍，与其他工具相比，NextDenovo在装配一致性和单碱基装配精度方面表现出较高的水平。我个人用起来是觉得这个软件<strong>运行时间相对Canu较短</strong>，需要的算力资源较小，可以很快地组装出结果（后面可以进行比较）。</p><p>安装并测试通过后，我们就可以开始使用这个工具了。</p><p>首先准备input文件，将前面质控后的三代测序数据的绝对路径写在<strong>input.fofn</strong>文件里：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/public/home/wlxie/luobuma/luobuma/baima_rawdata/Third_generation_sequencing/clean_filter.fq</span><br></pre></td></tr></table></figure><p>接下来也是最重要的，修改配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[General]</span><br><span class="line">job_type = slurm # local, slurm, sge, pbs, lsf塔大学校集群选择slurm</span><br><span class="line">job_prefix = nextDenovo</span><br><span class="line">task = all # all, correct, assemble选择只进行correct还是只进行assemble，或者两者都进行，基因组小的话可以直接all</span><br><span class="line">rewrite = yes # yes/no覆写</span><br><span class="line">deltmp = yes </span><br><span class="line">parallel_jobs = 20 # number of tasks used to run in parallel线程数，咱学校的集群20勉强够</span><br><span class="line">input_type = raw # raw, corrected输入的数据情况</span><br><span class="line">read_type = ont # clr, ont, hifi数据类型</span><br><span class="line">input_fofn = input.fofn# 输入数据的位置信息</span><br><span class="line">workdir = 03_rundir# 输出的文件夹名字</span><br><span class="line"></span><br><span class="line">[correct_option]</span><br><span class="line">read_cutoff = 1k# 进行correct的时候截取的最小read</span><br><span class="line">genome_size = 230m # estimated genome size预估的基因组大小</span><br><span class="line">sort_options = -m 20g -t 15</span><br><span class="line">minimap2_options_raw = -t 8</span><br><span class="line">pa_correction = 3 # number of corrected tasks used to run in parallel, each corrected task requires ~TOTAL_INPUT_BASES/4 bytes of memory usage.</span><br><span class="line">correction_options = -p 15 -dbuf# 非常重要！-dbuf让每一步作业释放内存，防止节点卡死！</span><br><span class="line"></span><br><span class="line">[assemble_option]</span><br><span class="line">minimap2_options_cns = -t 8 </span><br><span class="line">nextgraph_options = -a 1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以上是我的配置文件信息，<strong>中文标注的地方都很重要</strong>，根据情况修改。其他参数可以用默认。其中预估的基因大小也是很有必要的，前面在做基因组Survey的时候预测过，这里就直接写预测的基因组大小。</p><p>其他参数的设定和使用可以参考这篇博客<a href="https://blog.csdn.net/u012110870/article/details/102660023">使用NextDenovo组装Nanopore数据</a>，以及官方的参数说明手册<a href="https://nextdenovo.readthedocs.io/en/latest/OPTION.html">NextDenovo Parameter Reference — NextDenovo latest documentation</a></p><p>需要强调一点，<code>correction_options = -p 15 -dbuf</code>这项参数是我在华农的集群平台手册上看到的，之前确实一直会<strong>卡死</strong>在某一步直到24h后台强杀这个进程，目前未知原因，加上之后运行正常。以我的数据来看，一个200多Mb的植物基因组，测序深度100X左右，一次组装运行结束需要12小时左右，<strong>已经非常快了</strong>。</p><p>最后是运行程序，我写了一个run.slurm文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 40</span></span><br><span class="line"></span><br><span class="line">./nextDenovo run.cfg</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbatch run.slurm</span><br></pre></td></tr></table></figure><p><strong>基因组比较大的话，建议分步运行，先correct，再assemble。</strong></p><p>因为是在集群中运行，所有输出都会在slurm-xxxx.out的文件夹中显示，打开以后可以看到每个时间节点完成了什么任务，当有任务卡住几个小时都没动的时候，就要检查是否是配置文件是否正确。</p><p><img src="https://www.shelven.com/tuchuang/20230223/2.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230223/2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>最后组装的基因组在03.ctg_graph目录下，文件名称nd.asm.fasta。最底下输出了组装结果概况，contig N50为9Mb，总共组装出225Mb的基因组序列，contig总数为59，组装结果还算不错。</p><h3 id="2-2-Canu"><a href="#2-2-Canu" class="headerlink" title="2.2 Canu"></a>2.2 Canu</h3><p>Canu是三代测序数据组装的经典工具，也是主要用于Pacbio和Nanopore公司的测序结果组装。</p><p>这个软件在安装过程中有点曲折，从官网下数据包，最后一步编译的过程会报错。目前我暂时没办法解决，但是可以用conda安装（虽然官网不建议这么做）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge -c bioconda -c defaults canu</span><br></pre></td></tr></table></figure><p>如果报错动态库出问题，可以参考<a href="https://www.shelven.com/2022/07/02/a.html">第三篇博客</a>中的方法，寻找根目录下的动态库中是否有对应的版本文件，如果有，<strong>直接修改软链接到对应的动态库下</strong>。</p><p>Canu运行分为三个步骤：<strong>纠错（Correct）、修剪（Trim）和组装（Assemble）</strong>。可以每一个步骤分开跑，比如纠错修剪之后的数据可以放到别的软件中组装，或者用别的软件纠错之后作为输入到Canu中组装。考虑到塔大集群24小时自动杀程序，保险起见还是三个步骤分开跑比较安全。</p><p>下面是官方的帮助文档，写的非常详细：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">usage:   canu [-version] [-citation] \</span><br><span class="line">              [-haplotype | -correct | -trim | -assemble | -trim-assemble] \</span><br><span class="line">              [-s &lt;assembly-specifications-file&gt;] \</span><br><span class="line">               -p &lt;assembly-prefix&gt; \# 输出文件前缀</span><br><span class="line">               -d &lt;assembly-directory&gt; \# 输出目录</span><br><span class="line">               genomeSize=&lt;number&gt;[g|m|k] \# 预测基因组大小</span><br><span class="line">              [other-options] \</span><br><span class="line">              [-haplotype&#123;NAME&#125; illumina.fastq.gz] \</span><br><span class="line">              [-corrected] \</span><br><span class="line">              [-trimmed] \</span><br><span class="line">              [-pacbio |</span><br><span class="line">               -nanopore |</span><br><span class="line">               -pacbio-hifi] file1 file2 ...</span><br><span class="line"></span><br><span class="line">example: canu -d run1 -p godzilla genomeSize=1g -nanopore-raw reads/*.fasta.gz </span><br><span class="line"></span><br><span class="line">  To restrict canu to only a specific stage, use:# 描述canu要执行的主程序</span><br><span class="line">    -haplotype     - generate haplotype-specific reads</span><br><span class="line">    -correct       - generate corrected reads</span><br><span class="line">    -trim          - generate trimmed reads</span><br><span class="line">    -assemble      - generate an assembly</span><br><span class="line">    -trim-assemble - generate trimmed reads and then assemble them</span><br><span class="line"></span><br><span class="line">  Reads can be either FASTA or FASTQ format, uncompressed, or compressed with gz, bz2 or xz.</span><br><span class="line"></span><br><span class="line">  Reads are specified by the technology they were generated with, and any processing performed.</span><br><span class="line"></span><br><span class="line">  [processing]# 描述reads状态</span><br><span class="line">    -corrected</span><br><span class="line">    -trimmed</span><br><span class="line"></span><br><span class="line">  [technology]# 描述测序平台（数据类型）</span><br><span class="line">    -pacbio      &lt;files&gt;</span><br><span class="line">    -nanopore    &lt;files&gt;</span><br><span class="line">    -pacbio-hifi &lt;files&gt;</span><br><span class="line">    </span><br><span class="line">  Some common options:</span><br><span class="line">    useGrid=string</span><br><span class="line">      - Run under grid control (true), locally (false), or set up for grid control</span><br><span class="line">        but don&#x27;t submit any jobs (remote)</span><br><span class="line">    rawErrorRate=fraction-error# 降低这个参数会提高第一步的速度</span><br><span class="line">      - The allowed difference in an overlap between two raw uncorrected reads.  For lower</span><br><span class="line">        quality reads, use a higher number.  The defaults are 0.300 for PacBio reads and</span><br><span class="line">        0.500 for Nanopore reads.  </span><br><span class="line">    correctedErrorRate=fraction-error# 降低这个参数可以提高组装效率</span><br><span class="line">      - The allowed difference in an overlap between two corrected reads.  Assemblies of</span><br><span class="line">        low coverage or data with biological differences will benefit from a slight increase</span><br><span class="line">        in this.  Defaults are 0.045 for PacBio reads and 0.144 for Nanopore reads.</span><br><span class="line">    gridOptions=string</span><br><span class="line">      - Pass string to the command used to submit jobs to the grid.  Can be used to set</span><br><span class="line">        maximum run time limits.  Should NOT be used to set memory limits; Canu will do</span><br><span class="line">        that for you.</span><br><span class="line">    minReadLength=number</span><br><span class="line">      - Ignore reads shorter than &#x27;number&#x27; bases long.  Default: 1000.</span><br><span class="line">    minOverlapLength=number</span><br><span class="line">      - Ignore read-to-read overlaps shorter than &#x27;number&#x27; bases long.  Default: 500.</span><br><span class="line">  A full list of options can be printed with &#x27;-options&#x27;.  All options can be supplied in</span><br><span class="line">  an optional sepc file with the -s option.# 可以用-s来提供自己修改的参数文件</span><br><span class="line"></span><br><span class="line">Complete documentation at http://canu.readthedocs.org/en/latest/</span><br></pre></td></tr></table></figure><p>也可以<a href="https://canu.readthedocs.io/en/latest/quick-start.html#">点击这里</a>，进官方手册看原文。下面用我自己的三代数据跑一个案例。</p><h4 id="2-2-1-纠错（Correct）"><a href="#2-2-1-纠错（Correct）" class="headerlink" title="2.2.1 纠错（Correct）"></a>2.2.1 纠错（Correct）</h4><p>因为三代测序数据错误率较高，纠错的步骤是通过序列之间的一致性比较获得高可信的碱基。</p><p>创建一个canu的空文件夹，写入以下内容到correct.slurm:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -N 1</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 40</span></span><br><span class="line"></span><br><span class="line">canu -correct -p baima -d baima_nanopore genomeSize=230m -nanopore-raw /public/home/wlxie/luobuma/luobuma/baima_rawdata/Third_generation_sequencing/pass.fq</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbatch correct.slurm</span><br></pre></td></tr></table></figure><p>主要就是注意下参数，<code>-p</code>是输出文件的前缀，<code>-d</code>是输出文件的目录名，需要声明这个数据是什么平台测的，以及数据是什么状态。虽然我这里只申请了40个核，但是<strong>canu会自动提交作业直到你能申请的核数上限</strong>……在塔大集群我的权限是200个核，通过scontrol show job 可以查到，我这边一次性提交了136个作业，排队100多个任务，占用192个核…..</p><p><strong>纠错、修整和组装每一个步骤会依次进行以下各个阶段</strong>，需要的内存和核数挺高的，所以推荐在集群中运行。</p><p><img src="https://www.shelven.com/tuchuang/20230223/3.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230223/3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>如果运行时间很长，<strong>建议到设置的输出文件夹目录下查看canu.out文件</strong>，详细记载了正在执行哪一步以及花了多少时间。如果不确定程序是否卡死，直接通过<code>scontrol show job</code>命令查看状态为RUNNING的作业，进入作业的输出目录，如果文件夹中的内容一直到最近的时间点都有更新，则可以放心地继续运行。</p><p><strong>仅仅这一个步骤花了30个小时。</strong>并且这一步会将<strong>100X的测序数据量降到40X（默认，可以调整，见官方<a href="https://canu.readthedocs.io/en/latest/parameter-reference.html#readsamplingcoverage">readSampleingCoverage</a>参数介绍）</strong>。最后生成文件<code>baima.correctedReads.fasta.gz</code>，我为了方便复制到了前一个文件夹，修改文件权限为0755。</p><h4 id="2-2-2-修整（trim）"><a href="#2-2-2-修整（trim）" class="headerlink" title="2.2.2 修整（trim）"></a>2.2.2 修整（trim）</h4><p>修整是在上一步纠错的基础上，再对reads进行修剪，删去可疑区域。</p><p>这一步经历的步骤与上一步是一样的，虽然上一步纠错已经将数据量降了一大半，对于我的基因组，<strong>这一步依然要跑32小时.</strong></p><p>同样在canu文件夹写入如下内容到trim.slurm：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 7200</span></span><br><span class="line"></span><br><span class="line">canu -trim -p baima -d baima_trim genomeSize=230m -corrected -nanopore /public/home/wlxie/canu/baima.correctedReads.fasta.gz</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbatch trim.slurm</span><br></pre></td></tr></table></figure><p>注意修改参数以及reads所处的状态。</p><p>在canu.out输出文件中，可以找到trim步骤用了什么参数，处理了哪些类型的reads：</p><p><img src="https://www.shelven.com/tuchuang/20230223/4.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230223/4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>生成的结果文件在baima_trim文件夹中，名称为<code>baima.trimmedReads.fasta.gz</code>，同样修改文件权限，移到前一个文件夹方便操作。</p><h4 id="2-2-3-组装（Assemble）"><a href="#2-2-3-组装（Assemble）" class="headerlink" title="2.2.3 组装（Assemble）"></a>2.2.3 组装（Assemble）</h4><p>经过前两步的数据纠错和修整，这一步才是正式组装基因组。</p><p>在canu文件夹写入如下内容到assemble.slurm：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -n 50</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH -t 10800</span></span><br><span class="line"></span><br><span class="line">canu -assemble -p baima -d baima_assemble genomeSize=230m correctedErrorRate=0.144 -trimmed -corrected -nanopore /public/home/wlxie/canu/baima.trimmedReads.fasta.gz</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbatch assemble.slurm</span><br></pre></td></tr></table></figure><p>在官方的介绍中，correctedErrorRate这个参数可以根据前面纠错和修整的reads质量做修改的，<strong>默认是Pacbio数据0.045，Nanopore数据0.144</strong>，降低这个参数值可以加快组装的效率，但是存在遗漏overlap和组装片段断裂的风险。低于30X测序深度以下的数据，官方建议可以略微提高这个值，对于60X测序深度以上的数据可以略微降低这个值，<strong>每次改变1%左右比较合适</strong>。</p><p>我这里就用默认参数了，组装时间可能会比较长，就将作业的时间调整为7天。</p><p>实际运行时间为30小时，最终组装结果如下：</p><p><img src="https://www.shelven.com/tuchuang/20230223/5.jpg" class="lazyload" data-srcset="https://www.shelven.com/tuchuang/20230223/5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这个工具组装出的结果比预期大很多，<strong>前面基因组survey预测的基因组大小为230Mbp，实际通过canu组装出有276Mbp</strong>，且contig数明显比NextDenovo多，导致contig N50指标低。我觉得可能是<code>correctedErrorRate</code>这个值比较高，可以适当调低一些，过于严格的纠错标准可能导致组装的contig比较碎。</p><p>因为前面的NextDenovo组装的效果已经比较理想，因此这一步我也就不再细调参数了。以NextDenovo组装出的基因组继续后面的分析。以目前我的植物基因组来看，用NextDenovo组装三代基因组的效率和质量都比Canu高。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间比较忙，现在继续整理基因组测序组装系列的学习笔记。&lt;a href=&quot;https://www.shelven.com/2022/07/03/a.html&quot;&gt;第四篇笔记&lt;/a&gt;写的二代测序基因组组装，主要是演示二代测序数据组装的主流工具SOAPdenovo 2.0是如何应用的。我这里有了二代和三代的测序数据，后续组装还是以&lt;strong&gt;三代数据为主&lt;/strong&gt;，这里就继续记录下几款三代测序数据组装的主流工具和用法。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="基因组三代测序分析" scheme="http://www.shelven.com/categories/%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%89%E4%BB%A3%E6%B5%8B%E5%BA%8F%E5%88%86%E6%9E%90/"/>
    
    
    <category term="NextDenovo" scheme="http://www.shelven.com/tags/NextDenovo/"/>
    
    <category term="Canu" scheme="http://www.shelven.com/tags/Canu/"/>
    
  </entry>
  
</feed>
