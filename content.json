{"meta":{"title":"我的小破站","subtitle":"","description":"","author":null,"url":"http://www.shelven.com","root":"/"},"pages":[{"title":"","date":"2022-04-09T14:14:36.602Z","updated":"2022-04-09T14:14:36.598Z","comments":true,"path":"404.html","permalink":"http://www.shelven.com/404.html","excerpt":"","text":"404 访问的页面走丢了！(⊙_⊙) 可能是输入地址有误或该地址已被删除 如果确认地址无误，请踢我一脚马上来改 TAT"},{"title":"","date":"2022-04-13T13:37:18.783Z","updated":"2022-04-13T13:37:18.770Z","comments":true,"path":"about/index.html","permalink":"http://www.shelven.com/about/index.html","excerpt":"","text":"感谢小伙伴的来访！ 小破站尚在搭建中，有好的想法请留言~ 本站成立的初衷是记录本人学习笔记，以及整合各种有用的生信网站和工具，方便查阅和学习。本人是前端小白指bug越修越多,如果本站有bug请留言，非常感谢!各位dalao高抬贵手，请不要DDOS攻击_(:з」∠)_"},{"title":"所有分类","date":"2022-04-13T09:37:32.168Z","updated":"2022-04-13T09:37:32.164Z","comments":true,"path":"categories/index.html","permalink":"http://www.shelven.com/categories/index.html","excerpt":"","text":"没有你感兴趣的？0.0 请留言提出你的宝贵意见~"},{"title":"","date":"2022-04-14T07:16:21.855Z","updated":"2022-04-14T07:16:21.851Z","comments":true,"path":"friends/index.html","permalink":"http://www.shelven.com/friends/index.html","excerpt":"相关网站","text":"相关网站 交换友链请参照下列格式并留言 名字|name: Phantom链接地址|link: http://www.shelven.com/头像地址|avatar: https://cdn.jsdelivr.net/gh/Phantom-Aria/image/avatar.jpg描述|desc: 博学而笃志，切问而近思"},{"title":"","date":"2022-04-17T18:19:00.757Z","updated":"2022-04-17T18:19:00.754Z","comments":false,"path":"history/index.html","permalink":"http://www.shelven.com/history/index.html","excerpt":"","text":"2022-04-17 发表日志 发表日志：转录组数据分析笔记（5）——stringtie转录本组装和定量 发表日志：转录组数据分析笔记（6）——HTseq计数定量 2022-04-16 更新日志：看板娘优化 看板娘模块显示优化 发表日志：转录组数据分析笔记（3）——samtools用法小结 发表日志：转录组数据分析笔记（4）——IGV基因组浏览器安装和解读 2022-04-15 更新日志：页面优化 发表日志：转录组数据分析笔记（2）——使用Hisat2比对参考基因组 网站页脚优化 2022-04-14 更新日志：bug修复 修复文章永久链接中文乱码bug，已更改永久链接格式 修复部分页面强制重新加载bug，修改了部分pjax代码 修复aplayer播放器切换页面后中断播放bug，同上 发表日志：转录组数据分析笔记（1）——如何用fastqc和trim-galore做测序数据质控 2022-04-13 更新日志：bug修复和CDN加速 修复主页轮播图片空白bug，修改了部分parallax代码，已优化图片加载方式 本站已加入又拍云联盟，站点已进行CDN加速 发表日志：小破站正式对外开放啦！ 2022-04-12 更新日志：服务器迁移 服务器迁移至本地 本站已绑定www.shelven.com域名 本站已安装SSL安全证书 2022-04-11 更新日志：界面优化 添加pjax插件，优化部分页面加载速度 百度统计维护，5月31日恢复接入 bug:暂时无法全站无刷新加载 2022-04-10 更新日志：功能添加 添加rss订阅功能 新增结绳栏目 新增站内搜索功能 接入百度统计 2022-04-09 更新日志：功能添加 新增live2D看板娘模块 接入腾讯云开发和twikoo评论系统 启用MFA，新增留言提醒和QQ邮箱头像抓取功能 2022-04-08 更新日志：页面美化 更改鼠标样式 更改侧边栏配置 新增网页加载条 2022-04-07 更新日志：页面美化和功能更新 重设导航栏 重设封面 更改右键菜单功能 2022-04-06 更新日志：功能添加 添加背景音乐功能，接入aplayer播放器 添加网站统计访客数功能，接入LeanCloud 添加文章字数统计功能 2022-04-05 更新日志：页面美化 导航栏设计和美化 卡片添加透明度 优化主题背景图片 2022-04-04 更新日志：小破站成立啦！ 使用Hexo框架，volantis主题搭建网站 github建库，代码托管 建立图床，使用jsDelivr进行CDN加速"},{"title":"","date":"2022-04-17T12:56:16.792Z","updated":"2022-04-17T12:56:16.792Z","comments":true,"path":"more/404.html","permalink":"http://www.shelven.com/more/404.html","excerpt":"","text":"404 访问的页面走丢了！(⊙_⊙) 可能是输入地址有误或该地址已被删除 如果确认地址无误，请踢我一脚马上来改 TAT"},{"title":"","date":"2022-04-13T07:44:09.805Z","updated":"2022-04-13T07:44:09.801Z","comments":true,"path":"mylist/index.html","permalink":"http://www.shelven.com/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-04-13T09:37:59.531Z","updated":"2022-04-13T09:37:59.527Z","comments":true,"path":"tags/index.html","permalink":"http://www.shelven.com/tags/index.html","excerpt":"","text":"没有你感兴趣的？0.0 请留言提出你的宝贵意见~"}],"posts":[{"title":"转录组数据分析笔记（7）——DESeq2差异分析","slug":"转录组数据分析笔记（7）——R包DESeq2基因差异表达分析","date":"2022-04-18T07:49:20.000Z","updated":"2022-04-18T15:32:11.286Z","comments":true,"path":"2022/04/18/a.html","link":"","permalink":"http://www.shelven.com/2022/04/18/a.html","excerpt":"","text":"1. 代码示范前面处理好raw count定量表达矩阵，建立样本列表矩阵后，我们就可以在rstudio里运行DESeq2包进行差异基因筛选了。代码如下。 1234567891011121314151617181920212223library(&quot;DESeq2&quot;)mycounts &lt;- read.csv(&quot;transcript_count_matrix.csv&quot;,row.names = 1)mycounts_1 &lt;- mycounts[rowSums(mycounts) != 0,] # 重新定义数据集，过滤mapping数为0的基因mymeta &lt;- read.csv(&quot;sample_list.csv&quot;,stringsAsFactors = T) # 载入样本分组文件，遇到字符串将其转化为因子colnames(mycounts_1) == mymeta$id # 检查导入的两个数据集是否匹配，返回值为F需要重新匹配mymeta$index &lt;- factor(mymeta$index,levels = c(&quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;)) # 把样本分组文件的分组列转换到因子，不然会报错dds &lt;- DESeqDataSetFromMatrix(countData = mycounts_1, colData = mymeta, design = ~index) #构造用于差异表达分析的数据集dds &lt;- DESeq(dds)res &lt;- results(dds)res_1 &lt;- data.frame(res) # 结果res不是常规的数据，需要转化成数据框library(&quot;dplyr&quot;)res_1 %&gt;% # dplyr给数据集增加新列 mutate(group = case_when( log2FoldChange &gt;=1 &amp; padj &lt;=0.05 ~ &quot;UP&quot;, log2FoldChange &lt;=-1 &amp; padj &lt;=0.05 ~ &quot;DOWN&quot;, TRUE ~ &quot;NOT_CHANGE&quot; )) -&gt; res_2table(res_2$group)write.csv(res_2,file = &quot;all.csv&quot;, quote = F) # 输出文件 2. 代码详解详细解释一下过程： 在R里运行程序或者写代码，首先要确定好工作目录在哪里，将之前Stringtie转化的定量表达矩阵和样本列表矩阵全都放在工作目录下，这里我的表达量矩阵是transcript_count_matrix.csv，分组列表矩阵是sample_list.csv。getwd()可以查看当前工作目录，在全局设置里可以更改工作目录。 library(&quot;DESeq2&quot;) # 加载DESeq2这个R包 mycounts &lt;- read.csv(&quot;transcript_count_matrix.csv&quot;,row.names = 1) # 载入raw count矩阵，以第一行数据作为行名，读取的矩阵命名为mycounts mycounts_1 &lt;- mycounts[rowSums(mycounts) != 0,] # 过滤每一行mapping总数为0的基因，将数据集整理命名为mycounts_1 mymeta &lt;- read.csv(&quot;sample_list.csv&quot;,stringsAsFactors = T) # 载入样品列表，遇到字符串将其转化为一个因子 colnames(mycounts_1) == mymeta$id # 检查raw count矩阵第一行是否与样品列表的id列是否一致（如下）。这个很重要，不一致跑DESeq2会报错。如果显示false就要调整 mymeta$index &lt;- factor(mymeta$index,levels = c(&quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;)) # 这一步同样重要，把样本分组文件的分组列转换到因子，不然会报错。我这里的分组是第0天，第1天，第2天和第3天 123dds &lt;- DESeqDataSetFromMatrix(countData = mycounts_1, colData = mymeta, design = ~index) # 中间那一长串是DESeq2包里的函数，countData是raw count定量矩阵，colData是样品列表，design是分组信息，这步是为了构造用于差异表达分析的数据集，并将数据集命名为dds dds &lt;- DESeq(dds) # 分析的核心DESeq程序 res &lt;- results(dds) # 将结果输出至res数据集 res_1 &lt;- data.frame(res) # res不是常规的数据，我们可以用head和class命令查看一下（如下图），需要转化成常规的数据框格式才可以对其进行加减列等操作，转换格式后的数据集名字为res_1 library(&quot;dplyr&quot;) # 加载这个包是为了对数据框进行操作，我是要增加新的一列统计差异表达情况 123456res_1 %&gt;% mutate(group = case_when( log2FoldChange &gt;=1 &amp; padj &lt;=0.05 ~ &quot;UP&quot;, log2FoldChange &lt;=-1 &amp; padj &lt;=0.05 ~ &quot;DOWN&quot;, TRUE ~ &quot;NOT_CHANGE&quot; )) -&gt; res_2 # 调用dplyr包给数据集增加新的一列group，log2FoldChange &gt;&#x3D;1，padj &lt;&#x3D;0.05，判断这个基因表达为上调，在log2FoldChange &lt;&#x3D;-1，padj &lt;&#x3D;0.05时判断这个基因表达为下调，其余情况为该基因表达情况不变。将结果输出到res_2数据集。 FoldChange表示两样品间表达量比值，是倍数变化，差异表达基因分析里，log2 fold change绝对值大于1为差异基因筛选标准。padj是调整后的p值，在p检验里，p值小于0.05是有显著差异的标志。 table(res_2$group) # 查看差异基因表达的结果，上调基因多少，下调基因有多少，不变的有多少 write.csv(res_2,file = &quot;all.csv&quot;, quote = F) # 输出和生成all.csv文件，即为结果文件 我分别对转录本和基因都运行了DESeq2包做差异分析， 转录本差异分析如下： 基因差异分析如下： 基因差异表达情况可以看到，有173个基因表达下调，259个基因表达上调；转录本差异表达情况可以看到，336个上调表达，458个下调表达，数量不一致的情况是因为一个基因中存在多个转录本。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"DESeq2","slug":"DESeq2","permalink":"http://www.shelven.com/tags/DESeq2/"}]},{"title":"转录组数据分析笔记（6）——HTseq计数定量","slug":"转录组数据分析笔记（6）——HTseq计数定量","date":"2022-04-17T15:49:37.000Z","updated":"2022-04-18T08:58:17.435Z","comments":true,"path":"2022/04/17/b.html","link":"","permalink":"http://www.shelven.com/2022/04/17/b.html","excerpt":"","text":"HTseq也是对有参考基因组转录数据进行表达量分析的，主要用于reads计数。这个软件功能就比较专一，不像stringtie还需要运行prepDE.py脚本进行数据转化，直接一步到位。那为什么我一开始不用HTseq呢？因为我遇到一个bug 主要还是运算速度的问题，我比较了两种定量方式，HTseq定量虽然只有一步，但是速度远不如stringtie，也可能是我的问题，下面会说到。 1. HTseq定量获得raw countvim一个新脚本，输入如下命令： 12345678#! bin/bashfor i in `seq 194 209`do htseq-count -f bam -s no \\ /media/sf_/data/fastq/bam/ERR1698&quot;$i&quot;.bam \\ # 输入bam文件 /media/sf_/data/ref/Arabidopis_thaliana.gtf # 参考基因组注释文件 &gt; /media/sf_/data/fastq/count/ERR1698&quot;$i&quot;.count # 自定义输出文件done 参数详解-f # 设置输入文件格式，可以是bam或者sam-s # 设置是否是链特异性测序，设置no每一条reads都会和正义链和反义链进行比较 保存运行以后发现这个程序只能分配一个线程（也可能是我没找到分线程的方法），所以可以根据电脑内核数分几个批处理一起运行会快很多（不然就等着干瞪眼&#x3D; &#x3D;）。 还有一点非常重要！bam文件需要提前按照名称排序，不然会出现绝大部分reads mapping不到参考基因组，这种情况会在屏幕上输出提示信息，但是程序还是会继续跑……这时候就别犹豫了赶紧kill这个程序，就算跑完了数据都不能用。可以用samtools sort -n对bam文件进行名称排序，但是排序之后无法再用samtools index建立索引文件，这会导致HTseq运行速度比蜗牛还慢。暂时没找到更好的办法 摊手。 经过漫长长长长长的时间等待，我们可以看看结果文件的head和tail（这里就放一张图吧）： 前面记录了基因名称和mapping上的reads数，最后5行对应不同的mapping情况，在不同的模式下意义不同，官网给出的区别如下图，默认是union模式： 计数结果也可以用multiqc合并，生成在线报告，这里可以直观地看到每个样品比对上的reads数百分比，这里16个样品的比对率都超过80%，说明计数结果都还不错。 2. HTseq结果文件处理HTseq计数定量后得到的是每一个样品的每个基因reads数，我们需要合并每个样品定量数据，手动修改成DESeq2能识别的raw count表达矩阵，还需要再准备一个样本列表矩阵，才能进行后续的DESeq分析。参考一下stringtie最后生成的表达量矩阵文件，我们也需要将HTseq定量结果整理成csv格式（逗号作为分隔符），第一列是基因名，后面是按照样品序列的排序，中间是表达矩阵。 再来看一看HTseq定量生成的文件详情，同样第一列是基因名，后面是raw count数量，^I 表示两列数据是以制表符tab键分隔的，$为换行符。 我的方法比较笨比，除第一个ERR1698194.count文件保留外，其他所有count文件第一列删去并命名为cut.count，然后合并ERR1698194.count和其他所有cut.count文件，再将所有的制表符替换为逗号，最后加上第一行行名和改文件名。 用awk命令删除第一列，写入到新的cut.count文件中： 1234for i in `seq 195 209`do cat ERR1698&quot;$i&quot;.count | awk &#x27;&#123;$1 = &quot;&quot;; print $0&#125;&#x27; &gt; ERR1698&quot;$i&quot;cut.countdone paste组合ERR1698194样品和其他cut.count文件到alldata.count: $ paste ERR1698194.count *cut.count &gt; alldata.count 看看alldata.count的数据格式，列数没有问题，但是awk删除列产生了空格： 用sed命令删除所有空格，替换所有制表符为逗号（两步可以合一步）： $ sed &#39;s/ //g&#39; alldata.count &gt; alldata1.count $ sed &#39;s/\\t/,/g&#39; alldata1.count &gt; alldata2.count 这样就手动生成符合csv格式的文件了，只需加上第一行： 这里样本量比较少，我直接vim复制粘贴的方法加了第一行，重命名一下文件就完成了表达矩阵的制作，可以用于DESeq2分析了！ 因为本人比较小白，上面处理过程就有些啰嗦了，总的思路就是改成csv格式文件的样式就可以。 样本列表矩阵的制作过程和stringtie一模一样，点击这里查看，本篇不再赘述。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"HTseq","slug":"HTseq","permalink":"http://www.shelven.com/tags/HTseq/"}]},{"title":"转录组数据分析笔记（5）——stringtie转录本组装和定量","slug":"转录组数据分析笔记（5）——stringtie转录本组装和定量","date":"2022-04-17T15:14:21.000Z","updated":"2022-04-18T13:17:51.305Z","comments":true,"path":"2022/04/17/a.html","link":"","permalink":"http://www.shelven.com/2022/04/17/a.html","excerpt":"","text":"stringtie转录本组装和定量1 转录本组装Stringtie是一个基因和转录本组装定量的软件，stringtie的输入文件有两个，一个是经过排序的bam文件，排序可以用前面说到的samtools sort命令完成，还有一个是参考基因组的注释文件（gff或gtf格式）。 在使用Stringtie进行基因或者转录本组装定量的过程中，有一个非常重要的参数 - e，我之前跑了一遍流程没有加参数-e，结果组装的结果非常差，还有大量的未注释的基因。我请教了度娘，网上的教程攻略也都是抄来抄去的没解决什么问题，官网只有这么一句解释： -e this option directs StringTie to operate in expression estimation mode; this limits the processing of read alignments to estimating the coverage of the transcripts given with the -G option (hence this option requires -G). 对于加了参数-e之后如何做的比对和组装处理还是不明了，不知道表达评估模式的原理是什么，只能自己做个大概的总结（不知正确与否）： 如果我们研究的样本没有很好的注释信息，研究的人少，现有的注释信息都不完善，那么我们就需要重建转录本进行注释，这个时候就不需要加参数-e。如果样品的注释信息非常完整，比如拟南芥这种模式生物，我们不需要重建新的转录本进行注释，只对现有的参考基因组注释文件就足够了，那就要用-e参数，不需要预测新的转录本。 -e参数还有个比较重要的地方，只有用了-e参数后，才可以运行prepDE.py3脚本得到read count矩阵（也就是进行定量），这个脚本后面会说。 我们首先创建一个shell脚本进行转录本组装： 12345678#! bin/bashfor i in `seq 194 209`do stringtie -p 4 -e \\ -G /media/sf_/data/ref/Arabidopis_thaliana.gtf \\ # 参考基因组注释文件 -o /media/sf_/data/fastq/gtf/ERR1698&quot;$i&quot;.gtf \\ # 自定义输出文件 /media/sf_/data/fastq/bam/ERR1698&quot;$i&quot;.bam # 输入的bam文件done 保存，运行，我们可以得到.gtf格式文件，less一下查看里面的内容： 我们这里因为加了参数-e，不会有新的基因和转录本，可以看到每个read比对上的基因的信息。（不加参数-e会组装新基因和转录本，默认采用STRG加数字编号进行区分）。每行数据会给出coverage，FPKM和TPM三个信息，后两者都可以用来定量。FPKM和TPM都是对read counts数目进行的标准化，如果是单端测序数据可以用RPKM进行标准化，不进行数据标准化的比较是没有意义的。 2 合并转录本(重构转录本才需要)这一步要注意下，如果需要重构转录本才需要合并所有的转录本的组装结果，得到一个非冗余的转录本合集，也就是获得跨多个RNA-seq样品的全局的转录本。这里需要分两步： $ ls *.gtf &gt; mergelist.txt # 将所有组装的转录本文件名合并到一个文件 $ stringtie --merge -p 4 -G /media/sf_/data/ref/Arabidopis_thaliana.gtf -o merge.gtf ./mergelist.txt #这一步是用--merge指令将所有转录本合并输出到merge.gtf文件中 我们最后得到的merge.gtf就是全局的转录本。这里只是记录一下这步操作，我们只关注参考基因组的注释结果就不需要merge。 3 获得定量表达矩阵DESeq2要求输入的定量结果为raw count形式，raw count是根据mapping到基因或转录本的reads数计算得到，而stringtie只提供了转录本水平的表达量，定量方式包括TPM和FPKM值两种。为了进行raw count定量，stringtie官方提供了prepDE.py脚本（两个版本，我选择的python 3版本，在我base环境下不会冲突），可以计算出raw count的表达量。 下载这个python脚本，如果你用的是windows浏览器，在官网找到脚本直接右键复制链接，用wget直接下到linux系统里，千万不要在windows上直接复制粘贴代码过去。因为windows的换行符和linux的不一样，两个系统间直接粘贴代码会出现错行和莫名其妙的缩进导致程序报错（可以用cat -A看两个系统换行符的区别，血的教训，排查了老半天才发现）推荐用prepDE.py3，不用再切python 2 的环境了。 官方给出的prepDE.py脚本有两种运行方式（如下图所示），一种是建立Ballgown能识别的目录结构，一种是建立sample_lst文件并指定所有样品数据的路径。两种方法都可行，Ballgown现在用的比较少，比较主流的还是Stringtie+DESeq2的分析方法。演示一下如何创建sample_lst和解释一下这个文件要求的格式。 3.1 sample_lst文件准备简单来说，sample_lst.txt要求第一列为样品编号，第二列为对应编号的样品gtf文件所在路径，中间用制表符tab隔开，如下图（命名不一定要完全一样，注意格式，后面要导入prepDE脚本，能找到就行）： 这个文件准备工作比较简单，不再赘述 3.2 运行prepDE.py3将prepDE.py3脚本放在上面gtf文件的目录下，运行以下命令： $ python prepDE.py3 -i sample_lst.txt -g gene_count_matrix.csv -t transcript_count_matrix.csv 解释一下： 参数含义-i # 输入文件，就是前面做的sample_lst.txt-g # 自定义基因组表达矩阵名字，默认也是gene_count_matrix.csv-t # 自定义转录本表达矩阵名字，默认也是transcript_count_matrix.csv 得到的这两个文件就是基因和转录水平的raw count表达量矩阵，我们都可以用于后面的DESeq2分析。 4. 制作样本列表矩阵这里需要和前面为了运行prepDE.py脚本而制作的sample_lst文件区分开，要做下一步DESeq2差异基因分析，我们需要自己手动创建一个DESeq2能识别的样本列表矩阵，包含两列信息：一列是样本名称，一列是样本分组。样本分组信息我们可以直接从下载样本数据的地方（EBI官网）得到，只需要自己改一下格式。 下载之后发现第一行标题特别长，稍微处理下制表符替换成换行符，将第一行标题拆分成每个字段一行的格式，找一下不同天数处理的分组信息关键字“time”，发现我们要的分组信息在第36行（也就是原来文件的第36列）： $ head -n1 E-MTAB-5130.sdrf.txt | tr &#39;\\t&#39; &#39;\\n&#39; | nl | grep &quot;time&quot; 同样的方法找样本信息所在列是32列： $ head -n1 E-MTAB-5130.sdrf.txt | tr &#39;\\t&#39; &#39;\\n&#39; | nl | grep &quot;ENA&quot; 所以我们需要提取第32列和第36列，用cut命令切割并重定向到新的文件sample_list: $ cut -f 32,36 E-MTAB-5130.sdrf.txt &gt; sample_list.csv 发现相邻数据有重复，uniq删除重复行，再用sed替换制表符为逗号（因为csv文件就是以逗号作为分隔符），将原来的sample_list.csv覆盖，vim手动修改一下第一行名字，完成后就可以用于DESeq2分析了！ $ uniq sample_list.csv &gt; sample_list1.csv # uniq删除重复行 $ sed &#39;s/\\t/,/g&#39; sample_list1.csv &gt; sample_list .csv # 替换制表符为逗号 手动修改sample_list .csv第一行内容，修改之后如下即可","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"stringtie","slug":"stringtie","permalink":"http://www.shelven.com/tags/stringtie/"},{"name":"prepDE.py3","slug":"prepDE-py3","permalink":"http://www.shelven.com/tags/prepDE-py3/"}]},{"title":"转录组数据分析笔记（4）——IGV基因组浏览器安装和解读","slug":"转录组数据分析笔记（4）——IGV基因组浏览器安装和解读","date":"2022-04-16T11:32:50.000Z","updated":"2022-04-16T11:37:33.011Z","comments":true,"path":"2022/04/16/b.html","link":"","permalink":"http://www.shelven.com/2022/04/16/b.html","excerpt":"","text":"1. IGV软件下载IGV（Integrative Genomics Viewer）是一个非常方便的比对软件，在使用前只需要将参考基因组和bam文件分别建立索引（即建立fai和bai文件）并载入，就可以对转录组测序数据进行可视化浏览。对比samtools tview功能，这个软件有交互式操作界面，对萌新非常友好。 直接上百度搜就能找到IGV官网，选择linux版本或者windows版本都行，这里用linux版本为例，IGV只支持JAVA11版本，不用担心这个问题，下载的安装包里直接有JAVA11，解压就可以用，就是国外网站下载有点慢（科学上网）。 直接在虚拟机里解压打开，运行igv.sh，会自动准备好JAVA11的运行环境，成功弹出交互式界面（终于告别了黑漆漆的命令行 ）。 2. 导入文件Genomes菜单栏上传建立索引的参考基因组.fa和.fai文件： File菜单栏上传排序并建立索引的.bam和.bai文件： 如果有参考基因组注释文件，同样可以导入进去，同样导入前需要sort排序和建立index，可以用菜单栏里的igvtools直接sort和index： 3. 界面解读我导入了5组bam数据，所有文件导入后可以看到如下界面，简单介绍一下各个区域和功能： 主页面获得的信息有限，我们选取第3条染色体为例，将其放大： 中间的界面可以通过左右拖动鼠标，或者按左右方向键来浏览染色体上的比对情况。我们在搜索框中直接搜基因名字进行染色体定位，比如CIPK家族中的CIPK7基因，回车后双击最后一栏基因注释文件中的基因名称CIPK7，可以得到详细的CIPK7基因信息（这里注意下，如果双击弹出来多个可供选择的片段的话，代表这个基因存在可变剪切）: 在基因注释区右键，选择expanded，可以将CIPK7基因的所有转录本显示出来。 放大到一定程度后，我们可以看到基因注释区上方出现了核苷酸序列和氨基酸序列，我们可以点击sequence旁边的箭头，切换到另一条链的序列。 点击核苷酸，会出现三行，分别表示不同起始位点的核苷酸翻译结果，绿色为起始密码子，红色的星号表示终止密码子。 再来看看放大后的tracks区域，bam文件在载入后会默认生成两个tracks，一个显示测序深度（Coverage track，可以对比下samtools depth），一个显示比对情况（Alignment track），我们放大其中一个样本的数据信息。 Coverage track区域灰色代表质量好，如果reads中某核苷酸与参考序列超过20%不一致的时候，IGV会根据四个碱基的计数对coverage的条形图进行着色。这里可以看到该位点处有20个reads覆盖到，8条reads测的是C核苷酸，12条reads测的是T核苷酸。如果某个位置coverage条形图只有一种颜色，即该位点测的核苷酸和参考序列完全不一样，那说明该位点是SNP位点。 Alignment tracks柱形图是和bam文件中的数据一一对应的，举个例子，我在IGV软件的ERR1698206.bam可以看到在第3条染色体位置8173028有3条reads。虚拟机中找到这个bam文件，直接samtools view查看并grep这个位置，可以找到3条定位的reads（还有三条是配对的另一条链）。 如果一条reads中间有缺失，IGV会用黑色横杠表示，中间数字表示缺失几个核苷酸。 IGV还用不同颜色标记异常的插入片段大小的reads，这里做的是RNA-seq数据比对，不用看reads颜色，有些reads还在质控的时候被裁短了，变成蓝色很正常（因为比预期短，个人理解是这样，有待考证？）。以下是官网的默认着色方案：","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"IGV","slug":"IGV","permalink":"http://www.shelven.com/tags/IGV/"}]},{"title":"转录组数据分析笔记（3）——samtools用法小结","slug":"转录组数据分析笔记（3）——samtools用法小结","date":"2022-04-16T10:41:24.000Z","updated":"2022-04-16T10:49:01.465Z","comments":true,"path":"2022/04/16/a.html","link":"","permalink":"http://www.shelven.com/2022/04/16/a.html","excerpt":"","text":"1. sam文件转化bambam文件是二进制文件，占用磁盘空间小，运算速度快，samtools操作是针对bam文件的，所以我们要进行数据转化。samtools sort指令可以将bam文件进行排序，这个指令同时也可以将sam文件转化成bam文件： 12345#! bin/bashls *.sam | while read iddo samtools sort -0 -@ 5 -o $(basename $id &quot;.sam&quot;).bam $id # 指定输出文件，改后缀.bamdone 运行脚本，将当前目录的sam文件全转换成bam文件并排序（这里的排序不是按名称，用HTseq还要再按照read名称排序，使用参数-n）。 samtools sort # 对bam文件进行排序（sam文件排序不会变） -0 # 设置输出文件压缩等级，0-9，0是不压缩,9是最高等级压缩 -@ # 设置线程数 -o # 设置排序后输出的文件名 最后接输入的bam或者sam格式文件 2. 构建索引文件2.1 构建bam文件索引在bam文件目录下，排序后的bam文件可以建立索引： $ ls *.bam | xargs -i samtools index &#123;&#125; 注意下xargs -i的用法，和管道不一样，是传递参数给后一个命令的花括号中，后一个命令中不存在歧义的时候可省略参数-i和花括号。 如图生成的bai文件就是索引文件。其实到了这一步，前面的sam文件就可以删除（节省电脑空间），只留下bam文件就行，bam文件无法直接查看，可以通过samtools view命令查看bam文件。 2.2 构建参考基因组fa文件索引在参考基因组文件目录下，对参考基因组的fa文件建立索引： $ samtools faidx Arabidopsis_thaliana.dna.genome.fa 参考基因组文件名注意改成自己的，生成的索引文件是.fai结尾的 3. bam文件qc质控samtools转化生成的bam文件需要进行质控，看看比对情况如何。在bam文件目录下，我们创建一个samtools自带qc质控指令samtools flagstat运行脚本： 12345#! bin/bashls *.bam | while read iddo samtools flastat -@ 4 $id &gt; $(basename $id &quot;.bam&quot;).flagstat # 自定义输出文件done $ samtools flagstat bam文件 &gt; 输出文件 # 这种格式，其他参数都一样 运行脚本文件可以获得16个.flagstat质控文件，和fastqc一样，我们还可以做完后用multiqc命令集合成一个html格式的总的qc报告网页。和fastqc不同之处是，fastqc是做下机数据质控，samtools是做比对参考基因组的质控。如下图所示，可以比较直观地看出大部分reads都是map上的。 生成的每一个flagstat文件我们也可以直接点开。 每一行统计数据都是以通过QC的reads数量和未通过QC的reads数量组成，以我点开的这个文件为例，主要信息有以下几个： 13992629个reads都是合格的 12328290个reads只比对到参考基因组一个位置上 13988737个reads比对到参考基因组（99.97%） 12332182个reads是成对的 12201338个reads可以正确配对（98.94%） 2846条reads成对但只有一条能比对上参考基因组 12398个配对的reads可以比对到别的染色体上 可以自己将所有的flagstat运行结束后的文件放在一个目录下，运用paste命令全部按列粘贴在一起，用cut或者awk提取所需的列数据自己做比对情况表格，这里不再赘述。 4. samtools其他指令简单介绍一下： $ samtools view ERR1698194.bam #查看bam文件（不能直接cat查看二进制文件） $ samtools tview ERR1698194.bam #类似于IGV这种基因组浏览器，但是非交互式界面（下图）不直观，我们一般都是用IGV查看基因组 其他还有samtools merge（合并所有bam文件到一个文件），samtools depth（得到每个碱基位点或者区域的测序深度,并输出到标准输出）等等，不是特别常用，这里就不介绍了。 在步骤2中构建的索引文件可以导入IGV中，对转录组每个read mapping情况进行可视化浏览，下个笔记将介绍IGV的用法。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"samtools","slug":"samtools","permalink":"http://www.shelven.com/tags/samtools/"}]},{"title":"转录组数据分析笔记（2）——使用Hisat2比对参考基因组","slug":"转录组数据分析笔记（2）——使用Hisat2比对参考基因组","date":"2022-04-15T08:53:41.000Z","updated":"2022-04-16T10:49:41.130Z","comments":true,"path":"2022/04/15/a.html","link":"","permalink":"http://www.shelven.com/2022/04/15/a.html","excerpt":"","text":"1. 建立参考基因组索引在进行clean data与参考基因组比对之前，我们需要先建立参考基因组索引。进入下载好参考基因组的文件目录下，运行命令： $ hisat2-build Arabidopsis_thaliana.dna.genome.fa genome -p # 以几个线程运行，与电脑核数或者分配虚拟机的核数有关genome # 命名的索引文件名，可以改成自己能找到的 就可以在当前目录建立参考基因组索引文件，hisat2固定会生成8个以.ht2做后缀名的索引文件，如下所示： 需要注意的一点，比对软件除了hiasat2以外，还有subjunk、bwa、bowtie2等等，各个比对软件生成的索引文件是不同的，不能相互混用，命名的时候注意区分各种比对工具。 2. clean data与参考基因组比对比对的意思是将每一个read与参考基因组序列进行对比，目的是得到每一个read在参考基因组上的位置信息，有了这个基础的位置信息才可以进行后续基因或者转录本的定量，最终由定量结果做差异表达矩阵，分析上调或者下调的基因数量。 新建一个shell脚本输入下面的代码 12345678#！ bin/bashfor i in `seq 194 209`do hisat2 -p 4 -x /media/sf_example/data/ref/genome \\ #索引文件绝对路径 -1 /media/sf_example/data/clean_data/ERR1698&quot;$i&quot;_1.fq.gz \\ -2 /media/sf_example/data/clean_data/ERR1698&quot;$i&quot;_2.fq.gz \\ -S /media/sf_example/data/hisat2_sam/ERR1698&quot;$i&quot;.sam #注意大写的Sdone 参数解释： -p # 同样是配置线程数-x # 指定索引文件，需要定义索引文件名称，不能加后缀，不能只定义到索引文件所在目录-1 # 第一端测序数据文件-2 # 第二端测序数据文件-S # 指定输出目录和文件，不指定会刷屏，注意是大写的S 输出到屏幕的结果如下，我们选取其中一个进行解读： 共有6166091对测序数据，都是双侧测序数据，其中： read1 和 read2 没有合理比对上参考基因组序列的有65259对，占1.06% read1 和 read2 只有一条比对上参考基因组序列的有5698903对，占92.42%，这部分reads数需要占测序reads的绝大多数才正常 read1 和 read2 可以同时比对到多个地方的有401929对，占6.52% 65259对没有合理比对上的序列中，55871对可以不合理地比对上一次 最后一块是对两条链拆开比对的结果，这个一般用不到，本来测序的两条reads就应该比对到同一个染色体同一个基因附近，拆开比对到不同染色体没有意义。我们要看的是最后一句话，总比对率为99.97%，通常比对率大于90%说明比对情况较好，与参考基因组基本吻合。 3. sam文件解读比对结果除了有屏幕上输出的总体报告外，还有记录详细比对结果的sam文件。双端测序的比对会将两个测序文件进行整合和比较，最后只生成一个sam文件，因此这个sam文件非常大，hisat2比对生成的sam文件可以直接打开。我们可以选取一部分进行解读。 @HD VN:1.0 SO:unsorted （排序类型） VN是格式版本；SO表示比对排序的类型，有unknown，unsorted，queryname和coordinate几种。samtools软件在进行行排序后不能自动更新sam文件的SO值。 @SQ SN:1 LN:30427671 （序列ID及长度） 参考序列名，这些参考序列决定了比对结果sort的顺序，SN是参考序列名；LN是参考序列长度；每个参考序列为一行。这里表示拟南芥有5条染色体，对应长度都在后面，Mt是线粒体基因，Pt是叶绿体基因。 @PG ID:hisat2 PN:hisat2 VN:2.2.1 （比对所使用的软件及版本） 这里包括了路径，方法，以及我质控后的序列长度（50-100）等详细信息。 接下来每行都是一长串，显示的是比对结果部分，11个字段（列） 第一列：QNAME：测序出来的reads序列数据名，ERR1698194.2 第二列：FLAG：表明比对类型：paring，strand，mate strand等 第三列：RNAME：参考基因组的染色体名，我这里是第1条染色体 第四列：POS：比对到这个染色的具体位置，4969 第五列：MAPQ：比对质量，是一个衡量比对好坏的打分结果，60最好 第六列：CIGAR：简要比对信息表达式，1S100M是第1个碱基切除，100个匹配 第七列：RNEXT：另一个序列比对上的参考序列编号，没有另外的片段是*，同一个片段&#x3D; 第八列：MPOS：另一个序列匹配的染色体具体位置，这里一样也是4969 第九列：TLEN：配对片段长度，最左边的为正，最右边的为负 第十列：SEQ：和参考序列在同一个链上比对的序列 第十一列：QUAL：比对序列的质量和reads碱基质量值 后面提供额外的信息，一般不重要，了解一下就行。因为sam文件太大（往往有10G以上），也不适合电脑进行后续处理，所以我们会用到samtools，将sam文件转化为更适合电脑处理的二进制bam文件。这个后面会讲。 4. 其他比对软件以下4种软件均用于序列比对，用法稍有不同，做个记录 $ hisat2 -p 4 -x 索引目录 -1 单端测序数据文件 -2 另一端测序数据文件 -S 输出文件 $ subjunk -T 4 -i 索引目录 -r 单端测序数据文件 -R 另一端测序数据文件 -o 输出文件 $ bowtie2 -p 4 -x 索引目录 -1 单端测序数据文件 -2 另一端测序数据文件 -S 输出文件 $ bwa mem -t 4 -M 索引目录 单端测序数据文件 另一端测序数据文件 &gt; 输出文件","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"hisat2","slug":"hisat2","permalink":"http://www.shelven.com/tags/hisat2/"}]},{"title":"转录组数据分析笔记（1）——如何用fastqc和trim-galore做测序数据质控","slug":"转录组数据分析笔记（1）——如何用fastqc和trim-galore做测序数据质控","date":"2022-04-14T13:13:35.000Z","updated":"2022-04-14T13:48:53.356Z","comments":true,"path":"2022/04/14/a.html","link":"","permalink":"http://www.shelven.com/2022/04/14/a.html","excerpt":"","text":"本系列学习笔记数据均来自”Temporal dynamics of gene expression and histone marks at the Arabidopsis shoot meristem during flowering“，原文用RNA-Seq的方式研究开花阶段，芽分生组织不同时期的基因表达量变化，4个时间段（0, 1, 2, 3），4个重复，共有16个样品。点击这里获取文献 1. 读文章获得RNA-Seq数据从文章末尾我们可以获得一些测序数据信息： Data availability. ChIP-seq and RNA-seq data have been deposited with ArrayExpress database (www.ebi.ac.uk/arrayexpress), accession numbers E-MTAB-4680, E-MTAB-4684 and E-MTAB-5130. 可以看到作者将CHIP-seq和RNA-seq数据上传到ArrayExpress这个数据库中，这个数据库是欧洲生物信息研究所（European Bioinformatics Institute, EBI）旗下的公共数据库，主要用于存放芯片和高通量测序数据，我们可以直接从该数据库中下载我们需要的RNA-seq数据，自己动手分析。 顺便介绍一下，欧洲EBI旗下的ENA数据库，美国NCBI旗下的GenBank，以及日本的DDBJ三大巨头组成了国际核酸序列数据库合作联盟（INSDC），这三大数据库收录了世界上报道的所有序列数据。 EBI数据库可以直接下载fastq数据，不需要做SRA数据转换（NCBI数据库中下载sra数据则需要转换，需要用工具fastq-dump），这是EBI数据库下载高通量测序数据的优点，但是这个数据库经常网络连接不稳定，用aspera或者prefetch这种高速下载软件也不一定能稳定下载 最好的方法是科学上网。我们可以从ArrayExpress数据库中输入索引号E-MTAB-5130，直接获得样本信息和测序信息。 2. 测序数据质控我们可以看到，下载的数据是双端测序产生的。我们不能直接用下载的raw data做后续分析，必须要进行质控查看测序质量如何。 2.1 使用fastqc对测序数据生成质控报告下载好的fastq文件可以直接用fastqc工具做测序数据质控，输入以下命令一次生成所有qc报告： $ fastqc *.fastq.gz -o ./ #在当前目录下对所有.fastq.gz文件生成qc报告，-o参数定义输出目录 运行结束后我们可以得到.html文件和.zip压缩包，这个就是质控报告。在虚拟机里，我们可以直接点开.html后缀的网页文件查看质控报告（和压缩包的内容是一致的）。 顺便介绍一个非常好用的工具multiqc，可以通过conda install直接安装，这个工具可以将批量生成的qc报告合并为一个，看起来更加直观。在生成qc报告的当前目录下，运行代码： $ multiqc ./ 2.2 质控报告解读2.2.1 基本信息绿色表示通过，黄色表示不太好，红色表示不通过。RNA-seq一般在Sequence Duplication Levels上结果会不好，一个基因可能会大量表达，测到好多遍。 2.2.2 核苷酸测序质量箱式图这里测序质量（纵坐标）用Q值表示，p为出错率，Q值计算式为Q&#x3D;-10*lg（p）。每一个核苷酸的测序质量可以从fastq文件第四行一一对应上，这里只是做了统计和可视化。我们可以看到每个位点的核苷酸测序质量Q值都在30以上，意味着每个位点的测序正确率都在99.9%以上，可以认为测序质量比较好。 箱式图解读：黄色箱子(25%和75%的分数线)，红色线(中位数)，蓝线是平均数，下面和上面的触须分别表示10%和90%的点。 2.2.3 测序泳道质量图纵坐标为tile编号，这张图代表每次荧光扫描的质量。蓝色背景表明测序质量良好，白色和红色的背景表示测序过程中可能有小气泡或者测序泳道上有污染。直接的体现就是部分测序数据中出现连续的N，也就是不能读取，可能是任何一个核苷酸。 2.2.4 reads质量得分可以看到平均质量在38，质量比较高。如果最高峰所对应的横坐标质量值小于27（错误率0.2%） 则会显示“警告”，如果最高峰的质量值小于20（错误率1%）则会显示“不合格”。 2.2.5 每条reads各个测序位点上各碱基出现概率图上看得出比较稳定，测序刚开始的时候波动会大一点，这里的GC含量和AT含量不一致。如果任何一个位置上的A和T之间或者G和C之间的比例相差10%以上则报“警告”，任何一个位置上的A和T之间或者G和C之间的比例相差20%以上则报“不合格”。 2.2.6 GC含量和理论分布可以看出GC含量在43%左右，与理论分布（也就是正态分布）比较吻合，中心峰值与所测转录组的GC含量一致。如果有不正常的尖峰，可能是测序文库有污染，接头的污染还会在过表达序列中体现。 2.2.7 每条reads的含N碱基数不能识别的碱基会被读成N，这里没有N，测序质量非常好。横坐标表示reads的位置，纵坐标表示N的比例。如果任何一个位置N的比例大于5%则报“警告”，大于20%则报“失败”。 2.2.8 测序长度分布这个测序仪一次测量长度是101bp。测序仪出来的原始reads通常是均一长度的，经过质控软件处理过的reads长度则不一样，这里说明测序结果较好。 2.2.9 重复序列水平可以看到重复水平较低。图中横轴代表reads的重复次数，大于10次重复后则按不同的重复次数合并显示。纵坐标表示各重复次数下的reads数占总reads的百分比；蓝线展示所有reads的重复情况，红线表示在去掉重复以后，原重复水平下的reads占去重后reads总数的百分比；如果非unique的reads占总reads数的20%以上则报 ”警告“，占总read数的50%以上则报 ”不合格“。这项变黄是正常的。 2.2.10 过表达序列和接头序列过表达的序列很可能是一些测序的接头序列，这里两种序列都看不到，说明质量良好。过表达序列是显示同一条reads出现次数超过总测序reads数的0.1%的统计情况，超过0.1%则报“警告”，超过1%则报“不合格”，会列出可能的接头序列。接头序列正常情况下含量接近于0。 2.3 trim-galore测序数据质控过滤质控的目的使为了除去下机数据raw data中的接头序列和质量比较差的测序数据，Q&lt;20，正确率小于99%，如果这样的核苷酸超过read长度的20%，则考虑将该read丢弃（只是建议，不是强制，根据需要可以自定义过滤条件）。 trim-galore也可以用conda install安装，非常方便，这是一个自动检测adaptor的软件，可以一个命令自动找出主流的测序接头并去除，还可以设置参数对测序数据质控。简单介绍一下trim-galore的一些参数： -q # 设定Phred quality score阈值，默认为20；-phred33 # 测序平台衡量测序质量的方法，有33和64，不影响；-length # 设定输出reads长度阈值，小于设定值会被抛弃，根据需要设计;-stringency # 设定可以忍受的前后adapter重叠的碱基数，默认为1（非常苛刻）;-paired # 用于分析双端测序数据结果；-o # 输出目录 因为是双端测序，16个样本每个都有_1和_2两个文件，可以写个脚本批量运行： 12345678#! bin/bashfor i in `seq 194 209` do trim_galore -q 25 -phred33 -length 50 -stringency 3 -paired \\ -0 /media/sf_/example/data/clean_data \\ /media/sf_/example/data/raw_data/ERR1698&quot;$i&quot;_1.fastq.gz \\ #一端测序数据 /media/sf_/example/data/raw_data/ERR1698&quot;$i&quot;_2.fastq.gz #另一端测序数据done 保存退出，运行，最后生成的_triming_report.txt文件就是生成的质控报告，_val_1.fq.gz就是过滤后瘦身的clean data，我们可以看到大小比原来小了10M左右，这个clean data才可以用于后续的分析流程 我截取了其中一个数据的质控结果，拉到最底下，可以看到两端测序数据中都有AGATCGGAAGAGC这个序列，在一个样本测序数据中出现240027次经过网上查找，AGATCGGAAGAGC这个序列确实是Illumina公司测序时的接头序列（点击这里查看），可以和上面fastqc质控报告中的测序平台Illumina相互验证。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"fastqc","slug":"fastqc","permalink":"http://www.shelven.com/tags/fastqc/"},{"name":"multiqc","slug":"multiqc","permalink":"http://www.shelven.com/tags/multiqc/"},{"name":"trim-galore","slug":"trim-galore","permalink":"http://www.shelven.com/tags/trim-galore/"}]},{"title":"小破站正式对外开放啦！","slug":"小破站正式对外开放啦！","date":"2022-04-13T14:29:14.000Z","updated":"2022-04-18T15:17:02.573Z","comments":true,"path":"2022/04/13/a.html","link":"","permalink":"http://www.shelven.com/2022/04/13/a.html","excerpt":"","text":"前言咳咳，经过10天左右紧张地准备，小站今天正式对外开放啦！作为第一次运行个人网站的小白，看着网站从零开始在自己手上慢慢展现一个个页面，实现一个个功能，这种成就感和激动感，让我感觉这几天的熬夜狂肝还是值得的呜呜呜我的头发。 建站过程为什么建站说是从零开始，其实也是站在前人搭建好的框架上才能顺利进行的。我很早之前就萌发了搭建个人网站的想法，自从这个学期开始学习生物信息学，我也慢慢对linux系统有了更深入的理解。一开始只是在虚拟机上跑跑程序，后来就想着不如买一个云服务器装linux玩玩，既然买了服务器了，那就再绑个域名吧，既然两个都有了，不如就再建个网站吧（滑稽）。于是趁着腾讯云的轻量级应用服务器打折的机会，一次性买了3年…然后又在阿里云买了个域名，了解到需要备案后才能解析域名，行，又办理各种手续在工信部备了案。不得不说，在各大云服务器商内卷搞活动的时候，有个学生认证还是相当香的。至于怎么用服务器，那就是后面考虑的事了。 备案和备案期间的学习我在腾讯云买的服务器，通过接入商腾讯云协助，腾讯云先审核我的材料，通过以后再提交工信部备案，备案还是相当快的，3天时间就办下来了。备案期间也没闲着，作为一个前端小白的我，又去恶补了一些前端知识，比如什么是css、js、ejs、html文件，这些文件的格式是怎么样的，java的一些基本语法等等。学习的折磨程度不亚于刚开始学R语言和linux操作系统，不过有了一些shell脚本的语法知识以后，还是能感觉到这些语言之间还是有共同的判断方式和逻辑在里面的（纯小白发言，不知道对不对）。在慢慢摸索的过程中痛并快乐着，先是照着别人给的js文件魔改，再是自己调试遇到的问题和bug，尤其在发现bug最后解决bug的时候，那种成就感能给我带来莫大的快乐。 建站历程建站的过程是痛苦的，踩了非常多的坑，我觉得我甚至可以写好几篇攻略出来。我一开始的想法是在github建库搭建个人网站，从安装nodejs和npm这种最基础的开始，配置环境，用hexo框架搭建一个本地静态博客，然后部署到github空间，这样就可以用github仓库名访问我的网站。但是有一个非常大的问题，github从国内访问会有DNS污染，连接速度那叫一个绝望。我自己是可以科学上网，但是总不能让别人浏览我网页的时候也科学上网吧？我也不太相信有很多人会用改host的办法来访问github，于是我就萌生了将买的云服务器用来搭建网站的想法（我知道这是一种资源浪费），github就可以当做网站的备份，以后即使我的云服务器过期了，我也可以依旧正常访问搭建在github里的静态博客。所以我的部署过程有点绕，就是本地生成静态博客，先部署到github仓库，再同步部署到我的云服务器。这样我就可以用备案后的二级域名解析到云服务器，在通过安装httpd服务来开启外部的访问了。 可以访问我的网站还是第一步，还要做好安全防护，申请SSL安全证书才能开启https连接。免费申请方式也很多，我申请了一年的apache上的SSL安全证书，然后安装到自己服务器上。还想吐槽一下，腾讯云有一键部署SSL安全证书通道，要90块钱，只要有点linux文本操作基础，自己按照教程部署一下半小时左右就能完成，这钱真好赚。SSL证书安装做好以后，就可以上别的云服务商找找免费的CDN加速了，有CDN加速一是可以加快网站的加载速度，二是隐藏自己服务器的ip地址，能起到一定的网站安全防护作用。吹一波又拍云，只要在网站底下加上他们的标志，启用他们的CDN加速，就能申请加入又拍云联盟，有免费一年的CDN加速和云储存服务，还可以查看访问记录等等 学生党薅羊毛的利器23333 。因为我的网页图片比较多，所以就应用了网页图片加速。 后记具体过程比如怎么接入第三方各种网站，用什么主题，怎么美化页面等等，就不详细说了，说多了肝疼，以后有想法再更新如何从零开始搭建自己的博客吧！至少没有服务器和域名也是完全可以实现的。建立这个小破站也主要是为了上传自己的学习笔记，整理生信网站和工具合集（相应的栏目还在建设中 新建文件夹了 ），督促自己学习hhhhh 本人技术实力有限，也不想搞地太花里胡哨，之后可能会有一些简单的小功能接入，还有移动端浏览小破站的优化（现在移动端浏览这个小破站简直是灾难，我都看不下去了），太费心思的东西就暂时放放了，主要专注于内容的创作，这几天会把一些学习笔记陆续上传。本人也是第一次用markdown语法写东西，排版一直搞不定段首的两个空格，先这样吧。 开摆","categories":[{"name":"个人主页","slug":"个人主页","permalink":"http://www.shelven.com/categories/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/"}],"tags":[{"name":"建站","slug":"建站","permalink":"http://www.shelven.com/tags/%E5%BB%BA%E7%AB%99/"}]}],"categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://www.shelven.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"转录组数据分析","slug":"转录组数据分析","permalink":"http://www.shelven.com/categories/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"个人主页","slug":"个人主页","permalink":"http://www.shelven.com/categories/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/"}],"tags":[{"name":"DESeq2","slug":"DESeq2","permalink":"http://www.shelven.com/tags/DESeq2/"},{"name":"HTseq","slug":"HTseq","permalink":"http://www.shelven.com/tags/HTseq/"},{"name":"stringtie","slug":"stringtie","permalink":"http://www.shelven.com/tags/stringtie/"},{"name":"prepDE.py3","slug":"prepDE-py3","permalink":"http://www.shelven.com/tags/prepDE-py3/"},{"name":"IGV","slug":"IGV","permalink":"http://www.shelven.com/tags/IGV/"},{"name":"samtools","slug":"samtools","permalink":"http://www.shelven.com/tags/samtools/"},{"name":"hisat2","slug":"hisat2","permalink":"http://www.shelven.com/tags/hisat2/"},{"name":"fastqc","slug":"fastqc","permalink":"http://www.shelven.com/tags/fastqc/"},{"name":"multiqc","slug":"multiqc","permalink":"http://www.shelven.com/tags/multiqc/"},{"name":"trim-galore","slug":"trim-galore","permalink":"http://www.shelven.com/tags/trim-galore/"},{"name":"建站","slug":"建站","permalink":"http://www.shelven.com/tags/%E5%BB%BA%E7%AB%99/"}]}